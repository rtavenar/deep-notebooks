{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb76fb5fef92490eabccbe7f31d7a262",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Neural Networks for Time Series\n",
    "\n",
    "In this notebook, we'll cover topics related to learning from time series and sequential data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2d3210fdee8646a2b2aa29cf62c64e2f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Preamble\n",
    "\n",
    "This lab session deals with the use of neural networks for time series classification and forecasting.\n",
    "Two kinds of architectures are considered here: convolutional and recurrent models. An illustration of attention-based models is provided at the end of the lab.\n",
    "\n",
    "## Time Series Classification using convolutional models (ConvNets)\n",
    "\n",
    "For a start, you will download and load the \"Trace\" dataset using the cells below.\n",
    "\n",
    "**Question #1.** What are the dimensions of the training data (`X_train`)? And what does each dimension correspond to (number of series, number of timestamps, number of features, ...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/rtavenar/ml-datasets/releases/download/Trace/Trace.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.load(\"Trace.npz\")\n",
    "X_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "X_test,  y_test  = dataset[\"x_test\"],  dataset[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b1ec9d6bb1f4698b4857a2b60328708",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #2.** In the following, you will be implementing a ConvNet using keras' [`Conv1D`](https://keras.io/api/layers/convolution_layers/convolution1d/) layers.\n",
    "What value should be passed to the `data_format` parameter to match `tslearn` format? Is it the default value?\n",
    "\n",
    "**Your Answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dceb1bf5722e40ab9cd95032758c0507",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #3.** `keras` has a `Sequential` model class that allows to build models by stacking layers.\n",
    "Define a model that is made of the following layers (use ReLU activation wherever it makes sense):\n",
    "\n",
    "* a convolution layer made of 10 filters of size 3\n",
    "* a pooling layer of pool size 2\n",
    "* a flatten layer (that converts a time series of features into a flattened array that is suited to feed fully-connected layers)\n",
    "* a fully-connected layer that has as many neurons as the number of classes in the \"Trace\" problem, and an adequate activation function.\n",
    "\n",
    "Compile your model (use \"Adam\" optimizer) and fit it for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "986a1a9144e84fadb31729e71692a784",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1869,
    "execution_start": 1643388899518,
    "output_cleared": true,
    "source_hash": "4ac327ac",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-10 14:31:47.303370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 216ms/step - loss: 1.3898 - accuracy: 0.3800 - val_loss: 1.3037 - val_accuracy: 0.3500\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.2072 - accuracy: 0.5000 - val_loss: 1.1564 - val_accuracy: 0.4100\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0715 - accuracy: 0.5400 - val_loss: 1.0433 - val_accuracy: 0.4200\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.9701 - accuracy: 0.5500 - val_loss: 0.9475 - val_accuracy: 0.4400\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8867 - accuracy: 0.5900 - val_loss: 0.8787 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.8234 - accuracy: 0.6100 - val_loss: 0.8319 - val_accuracy: 0.5200\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.7755 - accuracy: 0.6200 - val_loss: 0.7971 - val_accuracy: 0.4900\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7383 - accuracy: 0.6100 - val_loss: 0.7700 - val_accuracy: 0.4700\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7081 - accuracy: 0.6000 - val_loss: 0.7484 - val_accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6843 - accuracy: 0.6200 - val_loss: 0.7342 - val_accuracy: 0.5500\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv1D, MaxPool1D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(275, 1)),\n",
    "    Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "eb7b06ceddee4e479a36bb3a9495229a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #4.** Plot the evolution of accuracy through epochs on both training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "2da15a19e0cc4f379eb30b1708ce6c33",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1484,
    "execution_start": 1643388901250,
    "output_cleared": true,
    "source_hash": "abb80127",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history[\"accuracy\"], label=\"Train acc.\")\n",
    "plt.plot(h.history[\"val_accuracy\"], label=\"Val. acc.\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6cb7b7407934e2cb1a917bed0cd64da",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #5.** Ten epochs of training might not be sufficient, yet we do not know how many epochs would be necessary for a decent training. Set up early stopping (cf. [this callback](https://keras.io/api/callbacks/early_stopping/)) and see how long it takes before the model stops training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "fc03a35f7df04656bf23a6212266a4fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1523,
    "execution_start": 1643388902754,
    "output_cleared": true,
    "source_hash": "b57f1438",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 499ms/step - loss: 1.4964 - accuracy: 0.1400 - val_loss: 1.3709 - val_accuracy: 0.4000\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.2943 - accuracy: 0.5200 - val_loss: 1.2200 - val_accuracy: 0.4600\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 1.1488 - accuracy: 0.6100 - val_loss: 1.1041 - val_accuracy: 0.4500\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0321 - accuracy: 0.6600 - val_loss: 1.0113 - val_accuracy: 0.4700\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.9430 - accuracy: 0.6600 - val_loss: 0.9333 - val_accuracy: 0.4700\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 122ms/step - loss: 0.8713 - accuracy: 0.6500 - val_loss: 0.8668 - val_accuracy: 0.4800\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 135ms/step - loss: 0.8140 - accuracy: 0.6600 - val_loss: 0.8166 - val_accuracy: 0.4700\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.7701 - accuracy: 0.6600 - val_loss: 0.7790 - val_accuracy: 0.4600\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.7350 - accuracy: 0.6700 - val_loss: 0.7543 - val_accuracy: 0.4700\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.7062 - accuracy: 0.6400 - val_loss: 0.7415 - val_accuracy: 0.4700\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.6823 - accuracy: 0.6400 - val_loss: 0.7344 - val_accuracy: 0.4700\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6627 - accuracy: 0.6400 - val_loss: 0.7325 - val_accuracy: 0.4700\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6474 - accuracy: 0.6500 - val_loss: 0.7290 - val_accuracy: 0.4800\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.6348 - accuracy: 0.6600 - val_loss: 0.7171 - val_accuracy: 0.5700\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6207 - accuracy: 0.7100 - val_loss: 0.7127 - val_accuracy: 0.5900\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.6099 - accuracy: 0.7500 - val_loss: 0.7043 - val_accuracy: 0.5900\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5982 - accuracy: 0.7400 - val_loss: 0.6987 - val_accuracy: 0.5900\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 220ms/step - loss: 0.5899 - accuracy: 0.7000 - val_loss: 0.6915 - val_accuracy: 0.5800\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5798 - accuracy: 0.7300 - val_loss: 0.6841 - val_accuracy: 0.5900\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.5733 - accuracy: 0.7900 - val_loss: 0.6797 - val_accuracy: 0.5800\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.5651 - accuracy: 0.8100 - val_loss: 0.6755 - val_accuracy: 0.5800\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5578 - accuracy: 0.8100 - val_loss: 0.6750 - val_accuracy: 0.5800\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5505 - accuracy: 0.8100 - val_loss: 0.6793 - val_accuracy: 0.5700\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5442 - accuracy: 0.8100 - val_loss: 0.6857 - val_accuracy: 0.5900\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.5376 - accuracy: 0.7700 - val_loss: 0.6864 - val_accuracy: 0.6000\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.5316 - accuracy: 0.7600 - val_loss: 0.6817 - val_accuracy: 0.6000\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5253 - accuracy: 0.7900 - val_loss: 0.6718 - val_accuracy: 0.5900\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5205 - accuracy: 0.8200 - val_loss: 0.6601 - val_accuracy: 0.5700\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5138 - accuracy: 0.8000 - val_loss: 0.6600 - val_accuracy: 0.5600\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5070 - accuracy: 0.8500 - val_loss: 0.6651 - val_accuracy: 0.6300\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5009 - accuracy: 0.8100 - val_loss: 0.6664 - val_accuracy: 0.6200\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.4964 - accuracy: 0.8000 - val_loss: 0.6629 - val_accuracy: 0.6200\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4916 - accuracy: 0.8000 - val_loss: 0.6547 - val_accuracy: 0.6200\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 145ms/step - loss: 0.4858 - accuracy: 0.8100 - val_loss: 0.6414 - val_accuracy: 0.5900\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4802 - accuracy: 0.8300 - val_loss: 0.6360 - val_accuracy: 0.6000\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 175ms/step - loss: 0.4759 - accuracy: 0.8300 - val_loss: 0.6395 - val_accuracy: 0.6100\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 109ms/step - loss: 0.4732 - accuracy: 0.8300 - val_loss: 0.6394 - val_accuracy: 0.6100\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.4673 - accuracy: 0.8200 - val_loss: 0.6313 - val_accuracy: 0.6100\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4618 - accuracy: 0.8300 - val_loss: 0.6236 - val_accuracy: 0.5900\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 156ms/step - loss: 0.4565 - accuracy: 0.8300 - val_loss: 0.6283 - val_accuracy: 0.6000\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 92ms/step - loss: 0.4502 - accuracy: 0.8400 - val_loss: 0.6339 - val_accuracy: 0.6100\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.4461 - accuracy: 0.8400 - val_loss: 0.6407 - val_accuracy: 0.6400\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 130ms/step - loss: 0.4440 - accuracy: 0.8300 - val_loss: 0.6391 - val_accuracy: 0.6400\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 84ms/step - loss: 0.4372 - accuracy: 0.8300 - val_loss: 0.6372 - val_accuracy: 0.6600\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4329 - accuracy: 0.8300 - val_loss: 0.6343 - val_accuracy: 0.6400\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.4300 - accuracy: 0.8300 - val_loss: 0.6238 - val_accuracy: 0.6100\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4256 - accuracy: 0.8400 - val_loss: 0.6048 - val_accuracy: 0.6200\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.4245 - accuracy: 0.8100 - val_loss: 0.6043 - val_accuracy: 0.6100\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4207 - accuracy: 0.8300 - val_loss: 0.6226 - val_accuracy: 0.6200\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4124 - accuracy: 0.8500 - val_loss: 0.6281 - val_accuracy: 0.6200\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.4095 - accuracy: 0.8400 - val_loss: 0.6366 - val_accuracy: 0.6300\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.4064 - accuracy: 0.8300 - val_loss: 0.6231 - val_accuracy: 0.6200\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.3999 - accuracy: 0.8500 - val_loss: 0.6050 - val_accuracy: 0.5900\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4007 - accuracy: 0.8400 - val_loss: 0.5976 - val_accuracy: 0.5900\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.3958 - accuracy: 0.8400 - val_loss: 0.6095 - val_accuracy: 0.5900\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3913 - accuracy: 0.8600 - val_loss: 0.6170 - val_accuracy: 0.6200\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.3865 - accuracy: 0.8600 - val_loss: 0.6092 - val_accuracy: 0.6200\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3864 - accuracy: 0.8300 - val_loss: 0.6006 - val_accuracy: 0.6100\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3841 - accuracy: 0.8500 - val_loss: 0.6074 - val_accuracy: 0.6200\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3786 - accuracy: 0.8600 - val_loss: 0.5995 - val_accuracy: 0.6200\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3744 - accuracy: 0.8600 - val_loss: 0.6042 - val_accuracy: 0.6200\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3733 - accuracy: 0.8600 - val_loss: 0.6129 - val_accuracy: 0.6400\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3692 - accuracy: 0.8700 - val_loss: 0.6030 - val_accuracy: 0.6200\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3651 - accuracy: 0.8600 - val_loss: 0.5864 - val_accuracy: 0.6100\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3662 - accuracy: 0.8500 - val_loss: 0.5829 - val_accuracy: 0.6200\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3609 - accuracy: 0.8500 - val_loss: 0.6004 - val_accuracy: 0.6400\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.3572 - accuracy: 0.8600 - val_loss: 0.6165 - val_accuracy: 0.6800\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 203ms/step - loss: 0.3609 - accuracy: 0.8500 - val_loss: 0.6187 - val_accuracy: 0.6700\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3546 - accuracy: 0.8600 - val_loss: 0.5908 - val_accuracy: 0.6400\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3513 - accuracy: 0.8700 - val_loss: 0.5733 - val_accuracy: 0.6400\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3518 - accuracy: 0.8500 - val_loss: 0.5765 - val_accuracy: 0.6300\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3485 - accuracy: 0.8500 - val_loss: 0.5935 - val_accuracy: 0.6400\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.3411 - accuracy: 0.8700 - val_loss: 0.6318 - val_accuracy: 0.6800\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3503 - accuracy: 0.8500 - val_loss: 0.6450 - val_accuracy: 0.6800\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3486 - accuracy: 0.8400 - val_loss: 0.6095 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.3386 - accuracy: 0.8700 - val_loss: 0.5738 - val_accuracy: 0.6300\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.3381 - accuracy: 0.8500 - val_loss: 0.5659 - val_accuracy: 0.6500\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3389 - accuracy: 0.8400 - val_loss: 0.5786 - val_accuracy: 0.6300\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3340 - accuracy: 0.8600 - val_loss: 0.6067 - val_accuracy: 0.6700\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.3306 - accuracy: 0.8700 - val_loss: 0.6153 - val_accuracy: 0.7000\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.3322 - accuracy: 0.8500 - val_loss: 0.6044 - val_accuracy: 0.6800\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3264 - accuracy: 0.8700 - val_loss: 0.6009 - val_accuracy: 0.6800\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3278 - accuracy: 0.8600 - val_loss: 0.5906 - val_accuracy: 0.6700\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3234 - accuracy: 0.8700 - val_loss: 0.5970 - val_accuracy: 0.6800\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.3202 - accuracy: 0.8700 - val_loss: 0.6125 - val_accuracy: 0.7000\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3221 - accuracy: 0.8600 - val_loss: 0.6174 - val_accuracy: 0.6900\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3202 - accuracy: 0.8700 - val_loss: 0.5936 - val_accuracy: 0.6800\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cb = EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(275, 1)),\n",
    "    Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "23a6010e38704d70931b751dc92f6378",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Recurrent neural nets\n",
    "\n",
    "For this new part of the lab, we will use the data generated from the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "7d66e1d72ce647f5aacf7a52058efbde",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 497,
    "execution_start": 1643388908680,
    "source_hash": "613c393b",
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_sines(n_series_per_class, length, length_padding=0):\n",
    "    t = np.linspace(0, 2 * np.pi, num=length)\n",
    "    X0 = .005 * np.random.randn(n_series_per_class, length + length_padding)\n",
    "    X0[:, :length] = np.sin(t).reshape((1, -1))\n",
    "    X0[:, length:] = np.sin(np.linspace(0, 2 * np.pi, num=length_padding))\n",
    "    \n",
    "    X1 = .005 * np.random.randn(n_series_per_class, length + length_padding)\n",
    "    X1[:, :length] = np.sin(-t).reshape((1, -1))\n",
    "    X1[:, length:] = np.sin(np.linspace(0, 2 * np.pi, num=length_padding))\n",
    "\n",
    "    dataset = np.array([X0, X1]).reshape((2 * n_series_per_class, length + length_padding, 1))\n",
    "    y = np.array([0] * n_series_per_class + [1] * n_series_per_class)\n",
    "\n",
    "    indices = np.random.permutation(2 * n_series_per_class)\n",
    "    return dataset[indices], y[indices]\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, y_train = make_sines(100, 50, length_padding=5)\n",
    "X_test, y_test = make_sines(100, 50, length_padding=5)\n",
    "\n",
    "plt.figure()\n",
    "colors = [\"r\", \"b\"]\n",
    "for ts, yi in zip(X_train, y_train):\n",
    "    plt.plot(ts.ravel(), color=colors[yi])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "99ca95a36a3f45aeade6cc9565c6db94",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #7.** Implement your own recurrent layer (_cf._ formulas in the course) using the skeleton below and train a network\n",
    "made of a single recurrent unit with a 8-dimensional hidden state followed by a fully connected layer, and evaluate its classification \n",
    "performance on the dataset provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "c8aa837080c744d8bc92d0e81b8945f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1643388909180,
    "source_hash": "2aab574a",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.ops import tanh, zeros\n",
    "\n",
    "class CustomRecurrentUnit(Layer):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # List sets of parameters here\n",
    "        self.w_h = self.add_weight(\n",
    "            shape=(hidden_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_h = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "        self.w_i = self.add_weight(\n",
    "            shape=(input_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_i = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def linear_hidden(self, h_t):\n",
    "        return h_t @ self.w_h + self.b_h\n",
    "    \n",
    "    def linear_input(self, x_t):\n",
    "        return x_t @ self.w_i + self.b_i\n",
    "    \n",
    "    def call(self, x):\n",
    "        n_timestamps = x.shape[1]\n",
    "        # Initialize h to [0, ..., 0]\n",
    "        # h = zeros((1, ???))\n",
    "        for t in range(n_timestamps):\n",
    "            # Update h\n",
    "            # h = tanh(???)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.ops import tanh, zeros\n",
    "\n",
    "class CustomRecurrentUnit(Layer):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # List sets of parameters here\n",
    "        self.w_h = self.add_weight(\n",
    "            shape=(hidden_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_h = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "        self.w_i = self.add_weight(\n",
    "            shape=(input_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_i = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def linear_hidden(self, h_t):\n",
    "        return h_t @ self.w_h + self.b_h\n",
    "    \n",
    "    def linear_input(self, x_t):\n",
    "        return x_t @ self.w_i + self.b_i\n",
    "    \n",
    "    def call(self, x):\n",
    "        n_timestamps = x.shape[1]\n",
    "        h = zeros((1, self.hidden_dim))  # Initialize h to [0, ..., 0]\n",
    "        for t in range(n_timestamps):\n",
    "            h = tanh(self.linear_hidden(h) + self.linear_input(x[:, t, :]))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22e3c8897c91438d93e01354657534f7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #8.** Implement a network made of a `CustomRecurrentUnit` followed by a fully-connected layer\n",
    "for the classification task introduced above.\n",
    "Evaluate this model both in terms of training loss and test-set accuracy (you can use the above callback to limit the amount of logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "b040773d7c16484e8a1ea1ab4a516996",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 8s 205ms/step - loss: 0.6957 - accuracy: 0.5000 - val_loss: 0.6935 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.4300 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6931 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 57ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 73ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.6932 - accuracy: 0.4300 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6932 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6934 - accuracy: 0.4700 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6933 - accuracy: 0.4800 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 20ms/step - loss: 0.6932 - accuracy: 0.4700 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 0.4800 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136a2d610>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    CustomRecurrentUnit(input_dim=1, hidden_dim=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "592d8ae6887f4bb9a7639bea3dfa6280",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #9.** Update your dataset so that it includes a final padding of 15 timestamps (_cf._ signature of the `make_sines` function)\n",
    "and see how it impacts performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "64253c69ae52450d913535407c8f0dc2",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, y_train = make_sines(100, 50, length_padding=15)\n",
    "X_test, y_test = make_sines(100, 50, length_padding=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8c515a15d64240d6b29af74010d8d52b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #10.** Build GRU (resp. LSTM) counterparts of the RNN-based model above.\n",
    "How do they compare experimentally to the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "1e0462b0f9d6459782e117794c51ef4f",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 106ms/step - loss: 0.6951 - accuracy: 0.4700 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6933 - accuracy: 0.4900 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 64ms/step - loss: 0.6932 - accuracy: 0.4900 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 74ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.6937 - accuracy: 0.4500 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6939 - accuracy: 0.5550 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.6936 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 59ms/step - loss: 0.6937 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6938 - accuracy: 0.5000 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6934 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.6935 - accuracy: 0.5000 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.6931 - accuracy: 0.5000 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.6935 - accuracy: 0.5700 - val_loss: 0.6930 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.6930 - accuracy: 0.5000 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 58ms/step - loss: 0.6928 - accuracy: 0.5000 - val_loss: 0.6925 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.6920 - accuracy: 0.5000 - val_loss: 0.6902 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6853 - accuracy: 0.6000 - val_loss: 0.6623 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.6013 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.3629 - accuracy: 1.0000 - val_loss: 0.1887 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.1194 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0343 - accuracy: 1.0000 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 54ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 66ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 62ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 61ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.8898e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 9.7871e-04 - accuracy: 1.0000 - val_loss: 9.6188e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 9.5214e-04 - accuracy: 1.0000 - val_loss: 9.3618e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 9.2688e-04 - accuracy: 1.0000 - val_loss: 9.1166e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 9.0278e-04 - accuracy: 1.0000 - val_loss: 8.8828e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 8.7975e-04 - accuracy: 1.0000 - val_loss: 8.6587e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 8.5771e-04 - accuracy: 1.0000 - val_loss: 8.4446e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 8.3669e-04 - accuracy: 1.0000 - val_loss: 8.2397e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 48ms/step - loss: 8.1661e-04 - accuracy: 1.0000 - val_loss: 8.0448e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 7.9737e-04 - accuracy: 1.0000 - val_loss: 7.8565e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 7.7887e-04 - accuracy: 1.0000 - val_loss: 7.6758e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 7.6104e-04 - accuracy: 1.0000 - val_loss: 7.5027e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 56ms/step - loss: 7.4395e-04 - accuracy: 1.0000 - val_loss: 7.3363e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 7.2751e-04 - accuracy: 1.0000 - val_loss: 7.1750e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 7.1160e-04 - accuracy: 1.0000 - val_loss: 7.0194e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 43ms/step - loss: 6.9630e-04 - accuracy: 1.0000 - val_loss: 6.8698e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 47ms/step - loss: 6.8153e-04 - accuracy: 1.0000 - val_loss: 6.7257e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 67ms/step - loss: 6.6729e-04 - accuracy: 1.0000 - val_loss: 6.5865e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 6.5351e-04 - accuracy: 1.0000 - val_loss: 6.4521e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 6.4028e-04 - accuracy: 1.0000 - val_loss: 6.3223e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1354d8dc0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(units=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 3s 111ms/step - loss: 0.6938 - accuracy: 0.4150 - val_loss: 0.6881 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.6833 - accuracy: 0.7500 - val_loss: 0.6717 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.6566 - accuracy: 1.0000 - val_loss: 0.6176 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.5698 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.4314 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.2956 - accuracy: 1.0000 - val_loss: 0.2254 - val_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.1925 - accuracy: 1.0000 - val_loss: 0.1452 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 38ms/step - loss: 0.1261 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 45ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 1s 76ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 49ms/step - loss: 0.0497 - accuracy: 1.0000 - val_loss: 0.0429 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 60ms/step - loss: 0.0327 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 51ms/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 46ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 53ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 65ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 44ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 42ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 9.9790e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 9.8962e-04 - accuracy: 1.0000 - val_loss: 9.7618e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 9.6830e-04 - accuracy: 1.0000 - val_loss: 9.5516e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 9.4747e-04 - accuracy: 1.0000 - val_loss: 9.3493e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 9.2748e-04 - accuracy: 1.0000 - val_loss: 9.1530e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 34ms/step - loss: 9.0810e-04 - accuracy: 1.0000 - val_loss: 8.9633e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 8.8944e-04 - accuracy: 1.0000 - val_loss: 8.7792e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 8.7119e-04 - accuracy: 1.0000 - val_loss: 8.6017e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 8.5366e-04 - accuracy: 1.0000 - val_loss: 8.4299e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 40ms/step - loss: 8.3666e-04 - accuracy: 1.0000 - val_loss: 8.2633e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 8.2018e-04 - accuracy: 1.0000 - val_loss: 8.1018e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 8.0422e-04 - accuracy: 1.0000 - val_loss: 7.9448e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 32ms/step - loss: 7.8870e-04 - accuracy: 1.0000 - val_loss: 7.7929e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 7.7367e-04 - accuracy: 1.0000 - val_loss: 7.6454e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 7.5914e-04 - accuracy: 1.0000 - val_loss: 7.5023e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 7.4500e-04 - accuracy: 1.0000 - val_loss: 7.3634e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 41ms/step - loss: 7.3126e-04 - accuracy: 1.0000 - val_loss: 7.2291e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 39ms/step - loss: 7.1798e-04 - accuracy: 1.0000 - val_loss: 7.0987e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 7.0504e-04 - accuracy: 1.0000 - val_loss: 6.9717e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 33ms/step - loss: 6.9248e-04 - accuracy: 1.0000 - val_loss: 6.8482e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 6.8035e-04 - accuracy: 1.0000 - val_loss: 6.7274e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 35ms/step - loss: 6.6830e-04 - accuracy: 1.0000 - val_loss: 6.6101e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 6.5670e-04 - accuracy: 1.0000 - val_loss: 6.4964e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 36ms/step - loss: 6.4544e-04 - accuracy: 1.0000 - val_loss: 6.3855e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137987c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    CustomRecurrentUnit(input_dim=1, hidden_dim=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9a3e4c2e84c041f7a18f34c6fb35cdb5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Recap\n",
    "\n",
    "**Question #11.** Come back to the \"Trace\" dataset used above and design a fair comparison between several convolutional and recurrent architectures to decide which one to choose for the problem at hand (feel free to play with the depth of the nets, as well as hidden representation dimensionality, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_id": "3020b8693ec140de8384108efb3d753e",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 275, 1)\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.8124 - accuracy: 0.5500\n",
      "Conv_1layer [0.8123898506164551, 0.550000011920929]\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6100\n",
      "Conv_2layers [0.6361228823661804, 0.6100000143051147]\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.5800\n",
      "Conv_3layers [0.6881691217422485, 0.5799999833106995]\n",
      "4/4 [==============================] - 1s 38ms/step - loss: 0.8049 - accuracy: 0.4700\n",
      "LSTM_1layer [0.8049086928367615, 0.4699999988079071]\n",
      "4/4 [==============================] - 1s 39ms/step - loss: 0.8502 - accuracy: 0.4800\n",
      "LSTM_2layers [0.8501598238945007, 0.47999998927116394]\n",
      "4/4 [==============================] - 1s 65ms/step - loss: 0.6810 - accuracy: 0.5000\n",
      "LSTM_3layers [0.6810304522514343, 0.5]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"Trace.npz\")\n",
    "X_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "X_test,  y_test  = dataset[\"x_test\"],  dataset[\"y_test\"]\n",
    "\n",
    "\n",
    "feature_extractors = {\n",
    "    \"Conv_1layer\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\")\n",
    "    ]),\n",
    "    \"Conv_2layers\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "    ]),\n",
    "    \"Conv_3layers\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "    ]),\n",
    "    \"LSTM_1layer\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True)\n",
    "    ]),\n",
    "    \"LSTM_2layers\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "    ]),\n",
    "    \"LSTM_3layers\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "for name, f in feature_extractors.items():\n",
    "    model = Sequential([\n",
    "        f,\n",
    "        Flatten(),\n",
    "        Dense(units=4, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    h = model.fit(X_train, y_train, epochs=10, verbose=False)\n",
    "    print(name, model.evaluate(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "25ccbef48c0041259097a232f5d6522e",
  "kernelspec": {
   "display_name": "py38_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "vscode": {
   "interpreter": {
    "hash": "25f9a3951446179f6c2016b22a60b44495fe90f43bda7f3caedfe2c1a9cd31f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

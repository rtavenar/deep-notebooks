{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-08753959-3ccf-49fa-9e6c-789a22d0baf8",
    "deepnote_cell_type": "markdown",
    "id": "MTDStjAJrLT-"
   },
   "source": [
    "# Images and convolutional networks\n",
    "\n",
    "In this notebook, we'll cover the use of convolutional neural networks for image classification. \n",
    "Since these networks widely benefit from computations on GPU (which Deepnote does not offer at the time), \n",
    "you could use Google Colab and [activate GPU](https://colab.research.google.com/notebooks/gpu.ipynb) if you want \n",
    "to experience smaller training times.\n",
    "\n",
    "## LeNet and variants (shallow CNNs)\n",
    "\n",
    "You will first experiments with rather shallow networks to get used to typical layers used in CNNs.\n",
    "\n",
    "\n",
    "**Question 1.** Import the MNIST dataset and make sure it has the correct shape to feed a CNN (i.e. the dataset should \n",
    "have dimensions $(n, w, h, c)$ where $n$ is the number of images in the set, $w$ and $h$ are the width and height of an \n",
    "image and $c$ its number of channels: 1 for black & white images and 3 for RGB ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00001-8f1fb72b-8284-4b4a-bc70-bf21556ec46e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "deepnote_cell_type": "code",
    "execution_millis": 496,
    "execution_start": 1606744103197,
    "id": "eZHk0xOhqUH6",
    "outputId": "39552619-cae6-44e7-bbc4-acaf800af98f",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def prepare_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "    x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "    x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-01168da6-b0c5-46a9-9d7d-d3210b958f60",
    "deepnote_cell_type": "markdown",
    "id": "kYSVWWgLryss"
   },
   "source": [
    "To define a CNN, you will need (at least) the following layers:\n",
    "* [`Conv2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)\n",
    "* [`MaxPool2D`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D)\n",
    "* [`Flatten`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten)\n",
    "\n",
    "**Question 2.** Implement a CNN with a single convolutional layer followed by a max-pooling and a fully-connected layer. Show the number of parameters of these networks and evaluate its performance on MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-46cbd7ca-38ec-4b30-aaa1-5001aa40aa8e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "deepnote_cell_type": "code",
    "execution_millis": 183869,
    "execution_start": 1606744338698,
    "id": "ug40MwR-uD0X",
    "outputId": "0683554f-22d6-4b3d-c5f0-ba80a33b13ef",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    # ...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-5ad942d1-c9e4-4f52-bcc6-304d0da5620f",
    "deepnote_cell_type": "markdown",
    "id": "uJkImztXuEmX"
   },
   "source": [
    "**Question 3.** Implement the following network (leNet), in which you just change the input image size (but keep the same \n",
    "hyper-parameters for convolution, pooling and dense layers):\n",
    "\n",
    "![leNet model](https://rtavenar.github.io/assets/images/lenet.png)\n",
    "\n",
    "Compare its performance to that of a fully connected model with the same number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00006-6bcab523-3647-4b23-b95c-535ba5bb44cc",
    "deepnote_cell_type": "code",
    "execution_millis": 281316,
    "execution_start": 1606746924685,
    "id": "MHaX-IatxEIM",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # ...\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c568dade-ea13-4ba7-9054-5769d9e529ca",
    "deepnote_cell_type": "markdown",
    "id": "XY4xF7XySH0B"
   },
   "source": [
    "## Image classification with ResNet models\n",
    "\n",
    "A very efficient way to perform real-world image classification is to rely on a pretrained model.\n",
    "`keras` provides models trained on ImageNet.\n",
    "In this section, you will use `ResNet50` to classify images you will provide.\n",
    "\n",
    "**Question 4.** Adapt the following code (that comes from [`keras` docs](https://keras.io/applications/#usage-examples-for-image-classification-models)) to classify a kangaroo image that you will first upload in the notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-b30f1bc6-b36a-4ff5-8cb6-32f5973f3f22",
    "deepnote_cell_type": "code",
    "execution_millis": 2416,
    "execution_start": 1606829450233,
    "id": "Fg5IjBicThZK",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'kangaroo.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00009-34589927-39ac-4d7f-910f-9bcd5e389b87",
    "deepnote_cell_type": "code",
    "execution_millis": 235,
    "execution_start": 1606825861999,
    "id": "VSgVfsSIvhWN",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x[0] / 255.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-c5df59f7-dc58-48f4-8a5a-e68bdd7fa1d4",
    "deepnote_cell_type": "markdown",
    "id": "0YRJ6isnVBpl"
   },
   "source": [
    "## Fine-tuning a model to your data\n",
    "\n",
    "Very often, however, your image classification problem will not match ImageNet classes.\n",
    "In such cases, a typical strategy consists in fine-tuning an existing model to your problem.\n",
    "This is done by learning only the fully connected layers at the ouput of the model and keep other layers freezed.\n",
    "\n",
    "When loading weights from a pretrained model, `keras` offers an option to remove the classification layers and freeze weights of the convolutional layers:\n",
    "\n",
    "```python\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "```\n",
    "\n",
    "Note that here, we provide the image shape when re-building the `ResNet50` model so that, if that shape is not the one of ImageNet images, `keras` will still be able to compute all tensor shapes in the network automatically.\n",
    "\n",
    "From that point, `base_model` can be used in a `Sequential` model as if it were a single layer, which makes it feasible to plug new layers at the output of the `ResNet50` convolutions.\n",
    "\n",
    "### The dataset\n",
    "\n",
    "In this notebook, you will work with a new dataset that cannot be loaded via `keras.datasets` module.\n",
    "The images should be [downloaded](https://drive.google.com/drive/folders/1_hs6-moToZkCgiub7eXyJmAm7zVT2tNo?usp=sharing) and stored in a subfolder named `./cats_and_dogs/`.\n",
    "\n",
    "Check that you can access the data by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00011-ac87b5c7-d725-4fb9-b4ca-1726257e3b1f",
    "deepnote_cell_type": "code",
    "id": "B27defToX455"
   },
   "outputs": [],
   "source": [
    "!ls './cats_and_dogs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-f0f7bcca-753a-4906-9a2c-50bf9f98f7eb",
    "deepnote_cell_type": "markdown",
    "id": "YU6dp42ILrFy"
   },
   "source": [
    "The last line of the output above should be:\n",
    "```\n",
    "test_catdog  train_catdog\n",
    "```\n",
    "\n",
    "Then the data should be loaded using the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00013-92762a1c-18b4-47f3-a999-0a763e88a0ca",
    "deepnote_cell_type": "code",
    "execution_millis": 2898,
    "execution_start": 1606829612818,
    "id": "H90B7fAss1te",
    "output_cleared": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_cats_and_dogs_folder(path, target_size=None, verbose=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    for fname in os.listdir(path):\n",
    "        if 'cat' in fname:\n",
    "            X.append(\n",
    "                np.array(image.load_img(path+fname, target_size=target_size))\n",
    "            )\n",
    "            y.append(0)\n",
    "        elif 'dog' in fname:\n",
    "            X.append(\n",
    "                np.array(image.load_img(path+fname, target_size=target_size))\n",
    "            )\n",
    "            y.append(1)\n",
    "        i+=1\n",
    "        if verbose and i % 50 == 0:\n",
    "            print('{0:.2f} % loaded'.format(100*(i/len(os.listdir(path)))))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def load_preprocessed_cats_and_dogs(base_folder, target_size=None, \n",
    "                                    verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Loading training set\")\n",
    "    X_train, y_train = load_cats_and_dogs_folder(base_folder + \"/train_catdog/\", \n",
    "                                                 target_size=target_size,\n",
    "                                                 verbose=verbose)\n",
    "    X_train = preprocess_input(X_train)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Loading test set\")\n",
    "    X_test, y_test = load_cats_and_dogs_folder(base_folder + \"/test_catdog/\", \n",
    "                                               target_size=target_size,\n",
    "                                               verbose=verbose)\n",
    "    X_test = preprocess_input(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# The call is here:\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_cats_and_dogs(\n",
    "    './cats_and_dogs/', target_size=(200, 200)\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-3f165cc8-2d88-4aa5-8c7b-541192998506",
    "deepnote_cell_type": "markdown",
    "id": "MYkREM4wamJ2"
   },
   "source": [
    "### The model\n",
    "\n",
    "**Question 5.** Now you will:\n",
    "\n",
    "1. use convolution layers from a pre-trained `ResNet50` model and freeze them;\n",
    "2. plug an additional logistic regression layer;\n",
    "3. compile the full model;\n",
    "4. observe the performance of such a model on your Cat vs Dog problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00014-2a0206ec-4b95-4524-9551-fa76ffc7a43b",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-e2c529a5-ca64-48f7-b57b-409f10ff310a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question 6.** Starting from the model you got at the previous stage, fine-tune _all_ the weights in this model\n",
    "(even the convolution ones) using a learning rate of .00001 (1e-5). See if this improves on performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=de648b12-30d1-4278-ad83-8761337c2497' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Images & ConvNets.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6fa42d5d-b2ab-4304-970d-186663f6abae",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

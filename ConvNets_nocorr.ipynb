{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-08753959-3ccf-49fa-9e6c-789a22d0baf8",
    "deepnote_cell_type": "markdown",
    "id": "MTDStjAJrLT-",
    "tags": []
   },
   "outputs": "",
   "source": [
    "# Images and convolutional networks\n",
    "\n",
    "In this notebook, we'll cover the use of convolutional neural networks for image classification.\n",
    "\n",
    "If you are using Google Colab, you can enable GPUs for the notebook as follows:\n",
    "\n",
    "- Navigate to Editâ†’Notebook Settings\n",
    "- select GPU from the Hardware Accelerator drop-down\n",
    "\n",
    "and restart the notebook.\n",
    "\n",
    "By default, all operations in `keras` are run on GPU if a GPU is found.\n",
    "If no GPU is available, the code runs on CPU without requiring any adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUvtdiV6_vvV",
    "tags": []
   },
   "outputs": "",
   "source": [
    "## LeNet and variants (shallow CNNs)\n",
    "\n",
    "You will first experiments with rather shallow networks to get used to typical layers used in CNNs.\n",
    "\n",
    "\n",
    "**Question 1.** Import the MNIST dataset and make sure it has the correct shape to feed a CNN (i.e. the dataset should \n",
    "have dimensions $(n, w, h, c)$ where $n$ is the number of images in the set, $w$ and $h$ are the width and height of an \n",
    "image and $c$ its number of channels: 1 for black & white images and 3 for RGB ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-8f1fb72b-8284-4b4a-bc70-bf21556ec46e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "execution_millis": 496,
    "execution_start": 1606744103197,
    "id": "eZHk0xOhqUH6",
    "outputId": "dec06129-681b-48f7-c4d8-35ec08cb7c2f",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def prepare_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "    x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "    x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-01168da6-b0c5-46a9-9d7d-d3210b958f60",
    "deepnote_cell_type": "markdown",
    "id": "kYSVWWgLryss",
    "tags": []
   },
   "outputs": "",
   "source": [
    "To define a CNN, you will need (at least) the following layers:\n",
    "* [`Conv2D`](https://keras.io/api/layers/convolution_layers/convolution2d/)\n",
    "* [`MaxPooling2D`](https://keras.io/api/layers/pooling_layers/max_pooling2d/)\n",
    "* [`Flatten`](https://keras.io/api/layers/reshaping_layers/flatten/)\n",
    "\n",
    "**Question 2.** Implement a CNN with a single convolutional layer followed by a max-pooling and a fully-connected layer. Show the number of parameters of these networks and evaluate its performance on MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-46cbd7ca-38ec-4b30-aaa1-5001aa40aa8e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "execution_millis": 183869,
    "execution_start": 1606744338698,
    "id": "ug40MwR-uD0X",
    "outputId": "3511c718-0874-4998-a902-23d7fc5d9858",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KcYi81xUlDWM",
    "outputId": "af02a725-72c9-400c-ba5d-706bcc575120",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-5ad942d1-c9e4-4f52-bcc6-304d0da5620f",
    "deepnote_cell_type": "markdown",
    "id": "uJkImztXuEmX",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 3.** Implement the following network (leNet):\n",
    "\n",
    "![leNet model](https://github.com/rtavenar/deep-notebooks/raw/main/assets/convnet_fig.svg)\n",
    "\n",
    "Compare its performance to that of a fully connected model with the same number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00006-6bcab523-3647-4b23-b95c-535ba5bb44cc",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "execution_millis": 281316,
    "execution_start": 1606746924685,
    "id": "MHaX-IatxEIM",
    "outputId": "16500efb-aec6-4306-c6ad-16cdb5dd62b8",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00007-c568dade-ea13-4ba7-9054-5769d9e529ca",
    "deepnote_cell_type": "markdown",
    "id": "XY4xF7XySH0B",
    "tags": []
   },
   "outputs": "",
   "source": [
    "## Image classification with ResNet models\n",
    "\n",
    "A very efficient way to perform real-world image classification is to rely on a pretrained model.\n",
    "`keras` provides models trained on ImageNet.\n",
    "In this section, you will use `ResNet50` to classify images you will provide.\n",
    "\n",
    "**Question 4.** Adapt the following code (that comes from [`keras` docs](https://keras.io/applications/#usage-examples-for-image-classification-models)) to classify a kangaroo image that you will first upload in the notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00008-b30f1bc6-b36a-4ff5-8cb6-32f5973f3f22",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "execution_millis": 2416,
    "execution_start": 1606829450233,
    "id": "Fg5IjBicThZK",
    "outputId": "7f6910de-8f84-41a0-87f4-cd07b3b043c1",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'kangaroo.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x_input = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x_input)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00009-34589927-39ac-4d7f-910f-9bcd5e389b87",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "deepnote_cell_type": "code",
    "execution_millis": 235,
    "execution_start": 1606825861999,
    "id": "VSgVfsSIvhWN",
    "outputId": "4b42d333-11fd-4c50-9ee5-baa6022e2147",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow((x[0] - x.min()) / (x.max() - x.min()));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-c5df59f7-dc58-48f4-8a5a-e68bdd7fa1d4",
    "deepnote_cell_type": "markdown",
    "id": "0YRJ6isnVBpl",
    "tags": []
   },
   "outputs": "",
   "source": [
    "## Fine-tuning a model to your data\n",
    "\n",
    "Very often, however, your image classification problem will not match ImageNet classes.\n",
    "In such cases, a typical strategy consists in fine-tuning an existing model to your problem.\n",
    "This is done by learning only the fully connected layers at the ouput of the model and keep other layers freezed.\n",
    "\n",
    "When loading weights from a pretrained model, `keras` offers an option to remove the classification layers and freeze weights of the convolutional layers:\n",
    "\n",
    "```python\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=x_train.shape[1:])\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = False\n",
    "```\n",
    "\n",
    "Note that here, we provide the image shape when re-building the `ResNet50` model so that, if that shape is not the one of ImageNet images, `keras` will still be able to compute all tensor shapes in the network automatically.\n",
    "\n",
    "From that point, `base_model` can be used in a `Sequential` model as if it were a single layer, which makes it feasible to plug new layers at the output of the `ResNet50` convolutions.\n",
    "\n",
    "### The dataset\n",
    "\n",
    "In this notebook, you will work with a new dataset that cannot be loaded via `keras.datasets` module.\n",
    "Execute the commands below to download and extract the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "!wget https://github.com/rtavenar/ml-datasets/releases/download/cats_and_dogs/cats_and_dogs.zip && unzip cats_and_dogs.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "Now, whatever your platform, run the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "folder_data = \"./cats_and_dogs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00011-ac87b5c7-d725-4fb9-b4ca-1726257e3b1f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "id": "B27defToX455",
    "outputId": "1a6d10fd-7a1b-4560-a5c9-93a7c65de5aa",
    "tags": []
   },
   "outputs": "",
   "source": [
    "!ls {folder_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-f0f7bcca-753a-4906-9a2c-50bf9f98f7eb",
    "deepnote_cell_type": "markdown",
    "id": "YU6dp42ILrFy",
    "tags": []
   },
   "outputs": "",
   "source": [
    "The last line of the output above should be:\n",
    "```\n",
    "test_catdog  train_catdog\n",
    "```\n",
    "\n",
    "Then the data should be loaded using the following functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00013-92762a1c-18b4-47f3-a999-0a763e88a0ca",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "execution_millis": 2898,
    "execution_start": 1606829612818,
    "id": "H90B7fAss1te",
    "outputId": "9838e6a3-733f-4189-92cd-673a541d6e73",
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": [
    "import os\n",
    "\n",
    "def load_cats_and_dogs_folder(path, target_size=None, verbose=True):\n",
    "    X = []\n",
    "    y = []\n",
    "    i = 0\n",
    "    for fname in os.listdir(path):\n",
    "        if 'cat' in fname:\n",
    "            X.append(\n",
    "                np.array(image.load_img(path+fname, target_size=target_size))\n",
    "            )\n",
    "            y.append(0)\n",
    "        elif 'dog' in fname:\n",
    "            X.append(\n",
    "                np.array(image.load_img(path+fname, target_size=target_size))\n",
    "            )\n",
    "            y.append(1)\n",
    "        i+=1\n",
    "        if verbose and i % 50 == 0:\n",
    "            print('{0:.2f} % loaded'.format(100*(i/len(os.listdir(path)))))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def load_preprocessed_cats_and_dogs(base_folder, target_size=None, \n",
    "                                    verbose=True):\n",
    "    if verbose:\n",
    "        print(\"Loading training set\")\n",
    "    X_train, y_train = load_cats_and_dogs_folder(base_folder + \"/train_catdog/\", \n",
    "                                                 target_size=target_size,\n",
    "                                                 verbose=verbose)\n",
    "    X_train = preprocess_input(X_train)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Loading test set\")\n",
    "    X_test, y_test = load_cats_and_dogs_folder(base_folder + \"/test_catdog/\", \n",
    "                                               target_size=target_size,\n",
    "                                               verbose=verbose)\n",
    "    X_test = preprocess_input(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# The call is here:\n",
    "X_train, X_test, y_train, y_test = load_preprocessed_cats_and_dogs(folder_data, target_size=(200, 200))\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-3f165cc8-2d88-4aa5-8c7b-541192998506",
    "deepnote_cell_type": "markdown",
    "id": "MYkREM4wamJ2",
    "tags": []
   },
   "outputs": "",
   "source": [
    "### The model\n",
    "\n",
    "**Question 5.** Now you will:\n",
    "\n",
    "1. use convolution layers from a pre-trained `ResNet50` model and freeze them;\n",
    "2. plug an additional logistic regression layer;\n",
    "3. compile the full model;\n",
    "4. observe the performance of such a model on your Cat vs Dog problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00014-2a0206ec-4b95-4524-9551-fa76ffc7a43b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "deepnote_cell_type": "code",
    "id": "KXDJMzwz_vvk",
    "outputId": "1e786ded-7782-495b-d632-1714c33ef24e",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oiPYYqR6lUr4",
    "outputId": "d64894b4-a7f9-4737-c708-87863154c568",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-e2c529a5-ca64-48f7-b57b-409f10ff310a",
    "deepnote_cell_type": "markdown",
    "id": "MlZQrGMq_vvl",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 6.** Starting from the model you got at the previous stage, fine-tune _all_ the weights in this model\n",
    "(even the convolution ones) using a learning rate of .00001 (1e-5). See if this improves on performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nAzNjjL_vvl",
    "outputId": "bacad3dd-3caa-4469-a365-265d9f6c2ecd",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 7.** Compare performance of this fine-tuned model with that of a shallow CNN model that you would define and train from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copie de Images & ConvNets.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6fa42d5d-b2ab-4304-970d-186663f6abae",
  "kernelspec": {
   "display_name": "py3.10_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-ea174d07-c758-4288-8cb9-7516529746fa",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "# Wrap-up lab\n",
    "\n",
    "This lab goes through some of the topics seen during this course.\n",
    "More advanced topics are tackled in parts II and III.\n",
    "\n",
    "## Part I. Convolutional neural nets\n",
    "\n",
    "**Question 1.** Edit the code below to make sure CIFAR-10 image datasets are properly prepared to feed a \n",
    "convolutional neural net.\n",
    "CIFAR-10 is an image classification dataset made of 32x32 color images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "keep_corr", "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import keras_core as keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def prepare_small_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype(float)[::2]  # Subsampling the dataset: do not edit\n",
    "    x_test = x_test.astype(float)[::2]  # Subsampling the dataset: do not edit\n",
    "    \n",
    "    x_train /= 255.\n",
    "    x_test /= 255.\n",
    "    \n",
    "    y_train = to_categorical(y_train)[::2]  # Subsampling the dataset: do not edit\n",
    "    y_test = to_categorical(y_test)[::2]  # Subsampling the dataset: do not edit\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_small_cifar10()\n",
    "print(x_train.max(), x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import keras_core as keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def prepare_small_cifar10():\n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "    x_train = x_train.astype(float)[::2]  # Subsampling the dataset: do not edit\n",
    "    x_test = x_test.astype(float)[::2]  # Subsampling the dataset: do not edit\n",
    "    \n",
    "    # TODO here\n",
    "    \n",
    "    y_train = to_categorical(y_train)[::2]  # Subsampling the dataset: do not edit\n",
    "    y_test = to_categorical(y_test)[::2]  # Subsampling the dataset: do not edit\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_small_cifar10()\n",
    "print(x_train.max(), x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx in range(10):\n",
    "    plt.subplot(2, 5, idx + 1)\n",
    "    plt.imshow(x_train[idx])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-907392c5-ec5d-400c-a429-794207a63cff",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "**Question 2.** Implement the model below using `keras`. \n",
    "If some hyper-parameters are not specified, you are free to set them as you think is best.\n",
    "\n",
    "\n",
    "![leNet model](https://raw.githubusercontent.com/rtavenar/deep-notebooks/main/assets/convnet_fig.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00003-f68eecca-bed0-4fa4-94af-e93cb9b342db",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPool2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer((32, 32, 3)),\n",
    "    Conv2D(filters=6, kernel_size=(5, 5), padding=\"valid\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=64, activation=\"relu\"),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-cc91cfd4-51a5-470f-ab3d-753534d7e188",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "**Question 3.** We wonder whether the last hidden layer (made of 64 neurons) is really necessary.\n",
    "Set up a way to properly compare the previous model with a model that would not have this layer.\n",
    "What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00004-e45650f5-822a-44ba-b59c-0d4cef7c7cb2",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "smaller_model = Sequential([\n",
    "    InputLayer((32, 32, 3)),\n",
    "    Conv2D(filters=6, kernel_size=(5, 5), padding=\"valid\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "smaller_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "smaller_model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-aa3e8dbb-e405-4b58-8231-9d05a9bd8763",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "**Question 4.** You might have seen a slight overfitting with the model of question 2.\n",
    "Set up a way to prevent this overfitting and see how it impacts the generalization performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.plot(h.history[\"loss\"], label=\"Training loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00007-a65927ad-be7d-4ab2-a0ee-a0a95400218f",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer((32, 32, 3)),\n",
    "    Conv2D(filters=6, kernel_size=(5, 5), padding=\"valid\", activation=\"relu\"),\n",
    "    Dropout(rate=0.2),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(filters=32, kernel_size=(5, 5), padding=\"same\", activation=\"relu\"),\n",
    "    Dropout(rate=0.2),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=64, activation=\"relu\", kernel_regularizer=l2(1e-4)),\n",
    "    Dropout(rate=0.2),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(h.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.plot(h.history[\"loss\"], label=\"Training loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-328f4723-66e3-4401-a973-965f7775b8c3",
    "deepnote_cell_type": "markdown",
    "output_cleared": false,
    "tags": []
   },
   "source": [
    "**Question 5.** Use a ResNet50 model pre-trained on ImageNet to which you plug a single logistic \n",
    "regression layer and use it for this CIFAR-10 classification task.\n",
    "What do you observe? Can you explain it?\n",
    "What would you suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00008-b003c266-370e-4355-b255-55639910c1dd",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "x_train_processed = preprocess_input(x_train * 255)\n",
    "x_test_processed = preprocess_input(x_test * 255)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer((32, 32, 3)),\n",
    "    ResNet50(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3)), \n",
    "    Flatten(),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train_processed, y_train, validation_data=(x_test_processed, y_test), epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-5502b93e-2324-438c-8fc4-9ac70b1ef6c6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Part II. Multi-input / multi-output models\n",
    "\n",
    "It sometimes happen that one wants to either feed a model with multiple inputs (_e.g._ an image and its \n",
    "caption) or predict several aspects of a sample, for which multiple outputs will be required.\n",
    "In this context, `keras`' Sequential model cannot be used anymore, but other options exist, in what is \n",
    "called `keras`' functional API.\n",
    "\n",
    "The basic idea behind this functional API is that the model will be defined by providing placeholders\n",
    "for its inputs and outputs.\n",
    "If the outputs are defined in such a way that they are computed from the inputs, the computation graph \n",
    "will be built automatically by `keras`.\n",
    "\n",
    "For example, in the code below:\n",
    "\n",
    "```python\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "layer1 = Dense(units=20, activation=\"relu\")\n",
    "layer2 = Dense(units=30, activation=\"relu\")\n",
    "layer3 = Dense(units=1, activation=\"sigmoid\")\n",
    "\n",
    "inputs = Input(input_shape=(d, ))\n",
    "hidden1 = layer1(inputs)\n",
    "hidden2 = layer2(hidden1)\n",
    "outputs = layer3(hidden2)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "```\n",
    "\n",
    "In this piece of code, we define the layers we need and then use them as if they were simple functions.\n",
    "The model is finally defined as connecting the `inputs` to the `outputs`.\n",
    "Here, if we had several inputs, we could have provided a list of them and, similarly, if we had\n",
    "several outputs, they could be passed as a list.\n",
    "Compilation and fit of such models are very similar to what we had with the `Sequential` class, except \n",
    "that:\n",
    "* at fit time, the correct number of inputs / outputs should be passed and inputs (resp. outputs) should \n",
    "be gathered in lists just as what was done at the model definition step;\n",
    "* at compile time, if several outputs are provided, several losses should be passed, as in the following example:\n",
    "\n",
    "```python\n",
    "losses = [\"categorical_crossentropy\", \"binary_crossentropy\"]\n",
    "loss_weights = [1., 1.]\n",
    "model.compile(optimizer=\"adam\", loss=losses, loss_weights=loss_weights, metrics=[\"accuracy\"])\n",
    "```\n",
    "\n",
    "**Question 6.** The code below loads a version of the MNIST dataset in which some digits are rotated. The goal is to both recognize the digit (information stored in `y_*`) and whether or not it is rotated \n",
    "(information stored in `y_rot_*`).\n",
    "Implement a neural network that 2 blocks (convolution + pooling) that provide a joint latent \n",
    "representation for the image and for each output a single dense layer is plugged to this joint \n",
    "representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00018-9b998f8c-6b07-410f-a2fb-e289bd3d8f82",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 197,
    "execution_start": 1615824064002,
    "source_hash": "12c9525b",
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from tf.image import rot90\n",
    "\n",
    "numpy.random.seed(0)\n",
    "\n",
    "def batch_rotate(images, indices):\n",
    "    images_with_channel = images[:, :, :, numpy.newaxis]\n",
    "    images_with_channel[indices] = rot90(images_with_channel[indices])\n",
    "    return images_with_channel / 255.\n",
    "\n",
    "def prepare_mnist():\n",
    "    step = 3\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    rotate_train = numpy.random.choice(2, size=x_train.shape[0]).astype(bool)\n",
    "    rotate_test = numpy.random.choice(2, size=x_test.shape[0]).astype(bool)\n",
    "    x_train = batch_rotate(x_train, rotate_train)[::step]\n",
    "    x_test = batch_rotate(x_test, rotate_test)[::step]\n",
    "    y_train = to_categorical(y_train)[::step]\n",
    "    y_test = to_categorical(y_test)[::step]\n",
    "    rotate_train = rotate_train.reshape((-1, 1))[::step]\n",
    "    rotate_test = rotate_test.reshape((-1, 1))[::step]\n",
    "    return x_train, x_test, y_train, y_test, rotate_train, rotate_test\n",
    "  \n",
    "x_train, x_test, y_train, y_test, y_rot_train, y_rot_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "for idx in range(10):\n",
    "    plt.subplot(2, 5, idx + 1)\n",
    "    plt.imshow(x_train[idx])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-83d701bc-c008-4552-834e-ceb93a1e801d",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "model_conv = Sequential([\n",
    "    InputLayer((28, 28, 1)),\n",
    "    Conv2D(10, kernel_size=5, activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Conv2D(50, kernel_size=5, activation=\"relu\"),\n",
    "    MaxPool2D(pool_size=2),\n",
    "    Flatten()\n",
    "])\n",
    "\n",
    "classif_rot = Dense(1, activation=\"sigmoid\")\n",
    "classif_digit = Dense(10, activation=\"softmax\")\n",
    "\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "repr_latente = model_conv(inputs)\n",
    "output_rot = classif_rot(repr_latente)\n",
    "output_digit = classif_digit(repr_latente)\n",
    "\n",
    "model = Model(inputs, [output_rot, output_digit])\n",
    "\n",
    "losses = [\"binary_crossentropy\", \"categorical_crossentropy\"]\n",
    "loss_weights = [1., 1.]\n",
    "model.compile(optimizer=\"adam\", loss=losses, loss_weights=loss_weights, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, [y_rot_train, y_train], validation_data=(x_test, [y_rot_test, y_test]), epochs=10, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00019-f78ae22f-cbbf-48c9-ae2f-0954eb34025b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Use the code below to visualize your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-adc60f85-9759-4abf-ac2c-f00eab963bea",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 947,
    "execution_start": 1615824622009,
    "output_cleared": true,
    "source_hash": null,
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_rot_mnist_preds(img, pred_class, pred_rot):\n",
    "    plt.figure()\n",
    "    plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.title(\"Predicted as class %d (p=%.2f) and rotation=%.2f\" % \n",
    "        (pred_class.argmax(), pred_class[pred_class.argmax()], pred_rot)\n",
    "    )\n",
    "\n",
    "preds_rot, preds_class = model(x_test)\n",
    "list_idx = [0, 10, 20]\n",
    "for idx in list_idx:\n",
    "    plot_rot_mnist_preds(x_test[idx], preds_class[idx].numpy(), preds_rot[idx].numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-0a54e641-61b4-4f84-aac9-3c983047efba",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Part III. Setting constraints on weights\n",
    "\n",
    "It can happen that a model's parameters have some actual real-world meaning.\n",
    "In this context, it could occur that you would want to set constraints on these weights (_e.g._ non-negativity, unit-norm, etc.).\n",
    "\n",
    "To do so, `keras` layers accept a `kernel_constraint` parameter, as described \n",
    "[here](https://keras.io/api/layers/constraints/).\n",
    "\n",
    "This parameter accepts either one of the provided constraints (`NonNeg`, `UnitNorm`, etc.) or a function\n",
    "that takes a weight tensor as input and returns a transformed version that fulfills the constraint.\n",
    "\n",
    "**Question 7.** Suppose we are given a dataset for which we know the outputs are generated as a\n",
    "linear combination of the inputs in which the coefficients are positive and sum to one.\n",
    "Implement a model that could estimate these weights from input-output data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-f171ef7b-7fde-4519-9148-000e73cc19d8",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1615828458124,
    "source_hash": "496689e3",
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "def gen_data():\n",
    "    n_samples = 1000\n",
    "    d = 10\n",
    "    X = numpy.random.randn(n_samples, d)\n",
    "    secret_weights = numpy.random.uniform(size=d)\n",
    "    secret_weights /= secret_weights.sum()\n",
    "\n",
    "    print(\"Secret weights are:\")\n",
    "    print(secret_weights)\n",
    "\n",
    "    y = X.dot(secret_weights.reshape((-1, 1))) + .1 * numpy.random.randn(n_samples, 1)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = gen_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00025-93f47d7e-3de6-462b-bfb5-78c6ccd6aece",
    "deepnote_cell_type": "code",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.constraints import Constraint\n",
    "from tf.nn import relu\n",
    "from tf.math import reduce_sum\n",
    "\n",
    "\n",
    "class PosSumTo1(Constraint):\n",
    "  \"\"\"Constrains weight tensors to be positive and of unit sum.\"\"\"\n",
    "  def __call__(self, w):\n",
    "    w = relu(w)\n",
    "    return w / reduce_sum(w)\n",
    "\n",
    "model = Sequential([\n",
    "  InputLayer((10, )),\n",
    "  Dense(1, activation=\"linear\", kernel_constraint=PosSumTo1(), use_bias=False)\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "from keras.constraints import Constraint\n",
    "from tf.nn import relu\n",
    "from tf.math import reduce_sum\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "print(model.layers[0].weights)\n",
    "print(reduce_sum(model.layers[0].weights[0]))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "6da450b3-e89a-4cd1-bdbd-55737bb60b4d",
  "kernelspec": {
   "display_name": "py3.10_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{"cells":[{"cell_type":"markdown","source":"# Auto-encoders and Generative models in `keras`\n\nIn this session, you will experiment with auto-encoders and then a family of generative models called \nGenerative Adversarial Models (GANs).\n\n## Auto-encoders\n\n**Question 1.** Implement a shallow auto-encoder (with a single layer from the input to the hidden \nrepresentation in dimension 16, and a single layer from this hidden representation to the output) and \nfit it to MNIST training set.\n\n","metadata":{"tags":[],"cell_id":"ea8152c8bb734ac08cd3566c15c7daff","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, InputLayer\nfrom tensorflow.keras.models import Sequential\n\n\n(X_train, _), (X_test, _) = mnist.load_data()\n# Represent images as long vectors of pixels in [0, 1]\nX_train = X_train.reshape((X_train.shape[0], -1)) / 255.\nX_train = X_train[::2]  # Keep half of the dataset\nX_test = X_test.reshape((X_test.shape[0], -1)) / 255.\nX_test = X_test[::2]  # Keep half of the dataset\n\n# TODO\n","metadata":{"tags":[],"cell_id":"d019b657784c4106ac78669bc4406983","source_hash":null,"output_cleared":true,"execution_start":1615565925759,"execution_millis":21867,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question 2.** Use the code below to visualize the quality of reconstruction on some test samples.","metadata":{"tags":[],"cell_id":"2695518a8f1c47a5ab5ffe6bfcd9039f","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plot_reconstruction(img, reconstruction):\n    plt.figure()\n    plt.subplot(1, 2, 1)\n    plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\n    plt.title(\"Original image\")\n    plt.subplot(1, 2, 2)\n    plt.imshow(reconstruction.reshape((28, 28)), cmap=\"gray\")\n    plt.title(\"Reconstructed image\")\n\npreds = model(X_test).numpy()\nplot_reconstruction(X_test[0], preds[0])\n","metadata":{"tags":[],"cell_id":"62e0bbfaabf747a4b5d6893b83fd2924","source_hash":null,"output_cleared":true,"execution_start":1615565953682,"execution_millis":726,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question 3.** Check if adding more layers (in both the encoder and decoder, trying to keep a mirror \nstructure) helps better reconstructing the images.","metadata":{"tags":[],"cell_id":"512218cdd3b747cca2aa45d61c98d0fc","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"5e6bd8adc2d44f11b56c0d9ed100950c","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Auto-encoders are known to be good image denoisers, if trained using noisy images as inputs and clean ones as outputs.\n\n**Question 4.** Using the below-defined noisy copies of `X_train` and `X_test`, check the denoising \ncapabilities of a network with the same structure as in the previous question.","metadata":{"tags":[],"cell_id":"be47514e910d4769bd2fcdd8d5982637","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import numpy as np\n\nX_train_noisy = X_train + .1 * np.random.randn(*X_train.shape)\nX_test_noisy = X_test + .1 * np.random.randn(*X_test.shape)\n\n# TODO","metadata":{"tags":[],"cell_id":"f9fe2388f29445cfa977e5b9d999898c","source_hash":null,"output_cleared":true,"execution_start":1615565987995,"execution_millis":31916,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Generative Adversarial Networks (GAN)\n\nIn this section, you will be invited to play with two types of GAN models to generate MNIST-like data.\n\nFirst, you will find below an almost complete implementation of the original GAN model (widely inspired from <https://github.com/eriklindernoren/Keras-GAN>).\n\n**Question 5.** Fill in the blanks (TODO marks in the `train` method) to complete the code and train a model on MNIST for 1000 epochs.","metadata":{"id":"eTlBng83h1jC","cell_id":"dcc0ff85e668475f91851d0b935db1e1","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom tensorflow.keras.layers import BatchNormalization, ZeroPadding2D, LeakyReLU\nfrom tensorflow.keras.layers import UpSampling2D, Conv2D\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.optimizers import Adam\n\nimport numpy as np\n\nclass GAN():\n    def __init__(self):\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.latent_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss='binary_crossentropy',\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise as input and generates imgs\n        z = Input(shape=(self.latent_dim,))\n        img = self.generator(z)\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated images as input and determines validity\n        validity = self.discriminator(img)\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains the generator to fool the discriminator\n        self.combined = Model(z, validity)\n        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n\n    def build_generator(self):\n\n        model = Sequential()\n\n        model.add(Dense(256, input_dim=self.latent_dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n\n        noise = Input(shape=(self.latent_dim,))\n        img = model(noise)\n\n        return Model(noise, img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Flatten(input_shape=self.img_shape))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(256))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(1, activation='sigmoid'))\n\n        img = Input(shape=self.img_shape)\n        validity = model(img)\n\n        return Model(img, validity)\n\n    def train(self, epochs, batch_size=128):\n\n        # Load the dataset\n        (X_train, _), (_, _) = mnist.load_data()\n\n        # Rescale -1 to 1\n        X_train = X_train / 127.5 - 1.\n        X_train = np.expand_dims(X_train, axis=3)\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random batch of images\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs = X_train[idx]\n\n            noise = np.random.randn(batch_size, self.latent_dim)\n            \n            # Generate a batch of new images\n            gen_imgs = self.generator.predict(noise)\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch(imgs, None)  # TODO: change None to a reasonable value\n            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, None)  # TODO: change None to a reasonable value\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            noise = np.random.randn(batch_size, None)  # TODO: change None to a reasonable value\n\n            # Train the generator (to have the discriminator label samples as valid)\n            g_loss = self.combined.train_on_batch(noise, None)  # TODO: change None to a reasonable value\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\ngan = GAN()\ngan.train(epochs=10 * 1000)\n","metadata":{"id":"VCnwH1NdhuSV","colab":{"height":1000,"base_uri":"https://localhost:8080/"},"cell_id":"c5f3754ad8e447ab90acf92fb9bee85b","outputId":"7fdd5a3b-5546-41d0-96f8-969de571624f","source_hash":null,"output_cleared":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now that your model is trained, generate a few images and visualize them with the code below:","metadata":{"id":"DNbMIJvZkfnE","cell_id":"955842aed1c141b7b396f051f1623e7b","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nn_images = 3\nz = np.random.randn(n_images, None)  # TODO: change None to a reasonable value\ngen_imgs = gan.generator.predict(z)\n\n# Rescale images 0 - 1\ngen_imgs = 0.5 * gen_imgs + 0.5\nfor i in range(n_images):\n  plt.imshow(gen_imgs[i, :, :, 0], cmap='gray')\n  plt.show()","metadata":{"id":"VpCllV8ck07j","colab":{"height":761,"base_uri":"https://localhost:8080/"},"cell_id":"e055a76411cb47208547ef19d2250e67","outputId":"60ca25fc-5676-4211-ae50-7d27b28b8d7f","source_hash":null,"output_cleared":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Code for a Conditional GAN is quite similar (_cf._ below, once again widely inspired from the same GitHub repository).\n\n**Question 6.** What is the input fed to the generator to generate a fake sample?","metadata":{"id":"J3QMxvO6m37Q","cell_id":"8992156777194cabbc9e63e7dbec7755","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"from tensorflow.keras.layers import Multiply, Embedding\n\n\nclass CGAN():\n    def __init__(self):\n        # Input shape\n        self.img_rows = 28\n        self.img_cols = 28\n        self.channels = 1\n        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n        self.num_classes = 10\n        self.latent_dim = 100\n\n        optimizer = Adam(0.0002, 0.5)\n\n        # Build and compile the discriminator\n        self.discriminator = self.build_discriminator()\n        self.discriminator.compile(loss=['binary_crossentropy'],\n            optimizer=optimizer,\n            metrics=['accuracy'])\n\n        # Build the generator\n        self.generator = self.build_generator()\n\n        # The generator takes noise and the target label as input\n        # and generates the corresponding digit of that label\n        noise = Input(shape=(self.latent_dim,))\n        label = Input(shape=(1,))\n        img = self.generator([noise, label])\n\n        # For the combined model we will only train the generator\n        self.discriminator.trainable = False\n\n        # The discriminator takes generated image as input and determines validity\n        # and the label of that image\n        valid = self.discriminator([img, label])\n\n        # The combined model  (stacked generator and discriminator)\n        # Trains generator to fool discriminator\n        self.combined = Model([noise, label], valid)\n        self.combined.compile(loss=['binary_crossentropy'],\n            optimizer=optimizer)\n\n    def build_generator(self):\n\n        model = Sequential()\n\n        model.add(Dense(256, input_dim=self.latent_dim))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(1024))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(BatchNormalization(momentum=0.8))\n        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n        model.add(Reshape(self.img_shape))\n\n        noise = Input(shape=(self.latent_dim,))\n        label = Input(shape=(1,), dtype='int32')\n        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n\n        model_input = Multiply()([noise, label_embedding])\n        img = model(model_input)\n\n        return Model([noise, label], img)\n\n    def build_discriminator(self):\n\n        model = Sequential()\n\n        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(Dense(512))\n        model.add(LeakyReLU(alpha=0.2))\n        model.add(Dropout(0.4))\n        model.add(Dense(1, activation='sigmoid'))\n\n        img = Input(shape=self.img_shape)\n        label = Input(shape=(1,), dtype='int32')\n\n        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n        flat_img = Flatten()(img)\n\n        model_input = Multiply()([flat_img, label_embedding])\n\n        validity = model(model_input)\n\n        return Model([img, label], validity)\n\n    def train(self, epochs, batch_size=128, sample_interval=50):\n\n        # Load the dataset\n        (X_train, y_train), (_, _) = mnist.load_data()\n\n        # Configure input\n        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n        X_train = np.expand_dims(X_train, axis=3)\n        y_train = y_train.reshape(-1, 1)\n\n        # Adversarial ground truths\n        valid = np.ones((batch_size, 1))\n        fake = np.zeros((batch_size, 1))\n\n        for epoch in range(epochs):\n\n            # ---------------------\n            #  Train Discriminator\n            # ---------------------\n\n            # Select a random half batch of images\n            idx = np.random.randint(0, X_train.shape[0], batch_size)\n            imgs, labels = X_train[idx], y_train[idx]\n\n            # Sample noise as generator input\n            noise = np.random.normal(0, 1, (batch_size, 100))\n\n            # Generate a half batch of new images\n            gen_imgs = self.generator.predict([noise, labels])\n\n            # Train the discriminator\n            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n            # ---------------------\n            #  Train Generator\n            # ---------------------\n\n            # Condition on labels\n            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n\n            # Train the generator\n            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n\n            # Plot the progress\n            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n            \ncgan = CGAN()\ncgan.train(epochs=100)","metadata":{"id":"mRElk8HAnC6o","colab":{"height":1000,"base_uri":"https://localhost:8080/"},"cell_id":"d727132df5324762a3b723126e8f148d","outputId":"9ac309b0-9a6a-46c2-a645-359499e2355b","source_hash":null,"output_cleared":true,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Question 7.** Fit the model for 1000 epochs and, once fitted, generate a few fake \"8\" handwritten digits (take inspiration from the code above to show the generated images).","metadata":{"id":"DJRrORUsoSaP","cell_id":"7dd1bd2e861043d6b7071b80da24a62d","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"8ee10ade4866492e99af5fd8c66c28d3","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=a23cc704-2799-4fb8-965c-9376f705dd61' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generative models.ipynb","provenance":[],"collapsed_sections":[]},"deepnote":{},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","deepnote_notebook_id":"961d3cbb532d4efeb1948060ded42780","deepnote_execution_queue":[]}}
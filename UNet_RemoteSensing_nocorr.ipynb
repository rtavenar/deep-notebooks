{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "# U-Net On Vaihingen Dataset\n",
    "\n",
    "In this lab session, you will use a U-Net model to perform semantic segmentation on the Vaihingen Dataset.\n",
    "The full Vaihingen dataset is available for download [here](https://www.kaggle.com/datasets/naydex/vaihingen-cropped), but in this lab you will use a smaller version (see details below) to have affordable training times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-08T15:47:46.847688Z",
     "iopub.status.busy": "2022-11-08T15:47:46.847231Z",
     "iopub.status.idle": "2022-11-08T15:47:46.855802Z",
     "shell.execute_reply": "2022-11-08T15:47:46.854341Z",
     "shell.execute_reply.started": "2022-11-08T15:47:46.847646Z"
    },
    "tags": []
   },
   "outputs": "",
   "source": [
    "As a reminder, the U-Net architecture is defined as follows :\n",
    "\n",
    "[<img src=\"https://github.com/rtavenar/deep-notebooks/raw/telenvi/unet.png\" alt=\"drawing\" width=\"1000\">](https://github.com/milesial/Pytorch-UNet)\n",
    "\n",
    "This notebook is derived from a nice U-Net implementation in PyTorch (click the image to access it). For more information, you can take a look at the [paper](https://arxiv.org/pdf/1505.04597.pdf)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-11-09T14:04:58.353666Z",
     "iopub.status.busy": "2022-11-09T14:04:58.353302Z",
     "iopub.status.idle": "2022-11-09T14:04:58.362917Z",
     "shell.execute_reply": "2022-11-09T14:04:58.361827Z",
     "shell.execute_reply.started": "2022-11-09T14:04:58.353635Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, MaxPool2D, ReLU, Input, ZeroPadding2D\n",
    "from keras.models import Sequential, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "## The UNet Model\n",
    "\n",
    "You will start by defining the UNet architecture to be used for this session. As a helper, the following blocks are defined:\n",
    "\n",
    "* `double_conv2d`: each sequence of two consecutive convolutions in the UNet model can be replaced by such a block\n",
    "* `down_sampling_block`: each sequence of a down-sampling followed by a two convolutions can be replaced by such a block\n",
    "* `up_sampling_block`: each sequence of an up-sampling (transposed convolution) followed by two convolutions can be replaced by such a block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:04:59.060792Z",
     "iopub.status.busy": "2022-11-09T14:04:59.060109Z",
     "iopub.status.idle": "2022-11-09T14:04:59.078766Z",
     "shell.execute_reply": "2022-11-09T14:04:59.077751Z",
     "shell.execute_reply.started": "2022-11-09T14:04:59.060755Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "from keras.ops import shape, concatenate\n",
    "\n",
    "def double_conv2d(output_channels):\n",
    "    return Sequential([\n",
    "        Conv2D(filters=output_channels, kernel_size=3, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        Conv2D(filters=output_channels, kernel_size=3, padding=\"same\"),\n",
    "        BatchNormalization(),\n",
    "        ReLU()\n",
    "    ])\n",
    "\n",
    "def down_sampling_block(output_channels):\n",
    "    return Sequential([\n",
    "        MaxPool2D(pool_size=2),\n",
    "        double_conv2d(output_channels)\n",
    "    ])\n",
    "\n",
    "def up_sampling_block(output_channels, shape1, shape2):\n",
    "    x1 = Input(shape=shape1)\n",
    "    x2 = Input(shape=shape2)\n",
    "    x1_up = Conv2DTranspose(output_channels, kernel_size=2, strides=2)(x1)\n",
    "    \n",
    "    # input is HWC\n",
    "    diffY = shape(x2)[1] - shape(x1_up)[1]\n",
    "    diffX = shape(x2)[2] - shape(x1_up)[2]\n",
    "\n",
    "    x1_up = ZeroPadding2D(padding=((diffY // 2, diffY - diffY // 2), (diffX // 2, diffX - diffX // 2)))(x1_up)\n",
    "    x = concatenate([x2, x1_up], axis=-1)\n",
    "    return Model(inputs=[x1, x2], outputs=double_conv2d(output_channels)(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 1.** Using the Keras Functional API, define the UNet architecture shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "def unet_model(image_size, n_classes):\n",
    "    inputs = Input(shape=image_size + (3,))\n",
    "    x0 = double_conv2d(64)(inputs)\n",
    "    \n",
    "    x1 = down_sampling_block(128)(x0)\n",
    "    # x2 = \n",
    "    # x3 = \n",
    "    # x4 = \n",
    "    \n",
    "    x = up_sampling_block(512, shape1=x4.shape[1:], shape2=x3.shape[1:])((x4, x3))\n",
    "    # x = \n",
    "    # x = \n",
    "    # x = \n",
    "    \n",
    "    outputs = Conv2D(filters=n_classes, kernel_size=1, activation=\"softmax\")(x)\n",
    "    \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "## The data\n",
    "\n",
    "You will now download the mini-Vaihingen dataset from CURSUS and put the zip file in your working folder.\n",
    "The following command should unzip it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "!wget https://github.com/rtavenar/ml-datasets/releases/download/unet_vaihingen/mini-vaihingen.zip && unzip -o mini-vaihingen.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "Now the following code defines a loader for the training data and another one for the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class VaihingenDataset(tf.keras.utils.Sequence):\n",
    "    \"\"\"Helper to iterate over the data (as Numpy arrays).\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, folder, small_subset=False):\n",
    "        self.batch_size = batch_size\n",
    "        self.input_img_paths = sorted([\n",
    "            os.path.join(folder, fname)\n",
    "            for fname in os.listdir(folder)\n",
    "            if fname.endswith(\".png\")\n",
    "        ])\n",
    "        if small_subset:\n",
    "            self.input_img_paths = self.input_img_paths[:2 * batch_size]\n",
    "        self.normalization_means = np.array([0.4643, 0.3185, 0.3141])\n",
    "        self.normalization_stds = np.array([0.2171, 0.1561, 0.1496])\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(1, len(self.input_img_paths) // self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
    "        i = idx * self.batch_size\n",
    "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
    "        x = []\n",
    "        y = []\n",
    "        for j, path in enumerate(batch_input_img_paths):\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            x.append(np.asarray(img) / 255.)\n",
    "            y.append(np.load(path.replace(\".png\", \"_gt.npy\")))\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        x -= self.normalization_means[None, None, None, :]\n",
    "        x /= self.normalization_stds[None, None, None, :]\n",
    "        return x, y\n",
    "\n",
    "train_loader = VaihingenDataset(batch_size=10, folder=\"vaihingen-cropped-small/vaihingen_train/\")\n",
    "val_loader = VaihingenDataset(batch_size=10, folder=\"vaihingen-cropped-small/vaihingen_test/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 2.** Inspect the first batch (`train_loader[0]`) from the training set. What are the shapes of `X` and `y`? And what values can they take?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 3.** Define, compile and fit (for one or two epochs, no more) a UNet model using the `unet_model` function defined above.\n",
    "What accuracy can you reach on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 4.** Download the pre-trained model using the command-line below and load its weights using `model.load_weights(\"pretrained_unet.h5\")` and evaluate its performance on the validation set using [`model.evaluate`](https://keras.io/api/models/model_training_apis/#evaluate-method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "!wget https://github.com/rtavenar/ml-datasets/releases/download/unet_vaihingen/pretrained_unet.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "## Let's see the results !\n",
    "\n",
    "**Question 5.** Use the code below to visualize the obtained results on some of the validation samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:16:29.863663Z",
     "iopub.status.busy": "2022-11-09T14:16:29.863235Z",
     "iopub.status.idle": "2022-11-09T14:16:29.87002Z",
     "shell.execute_reply": "2022-11-09T14:16:29.868859Z",
     "shell.execute_reply.started": "2022-11-09T14:16:29.863625Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "# The color palette to colorize pixels depending on their assigned class.\n",
    "\n",
    "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
    "           1 : (0, 0, 255),     # Buildings (blue)\n",
    "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
    "           3 : (0, 255, 0),     # Trees (green)\n",
    "           4 : (255, 255, 0),   # Cars (yellow)\n",
    "           5 : (255, 0, 0),     # Clutter (red)\n",
    "           6 : (0, 0, 0)}       # Undefined (black)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:16:30.288304Z",
     "iopub.status.busy": "2022-11-09T14:16:30.2876Z",
     "iopub.status.idle": "2022-11-09T14:16:30.800803Z",
     "shell.execute_reply": "2022-11-09T14:16:30.799808Z",
     "shell.execute_reply.started": "2022-11-09T14:16:30.288267Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "# Take a validation batch !\n",
    "\n",
    "images, labels = next(iter(val_loader))\n",
    "\n",
    "pred_labels = model(images).numpy().argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:16:32.001091Z",
     "iopub.status.busy": "2022-11-09T14:16:32.000023Z",
     "iopub.status.idle": "2022-11-09T14:16:32.125553Z",
     "shell.execute_reply": "2022-11-09T14:16:32.124553Z",
     "shell.execute_reply.started": "2022-11-09T14:16:32.001033Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "# A bit technical.\n",
    "\n",
    "color_preds = np.zeros((*pred_labels.shape, 3), dtype=np.float32)\n",
    "gt_color_preds = np.zeros((*pred_labels.shape, 3), dtype=np.float32)\n",
    "\n",
    "for cls, col in palette.items():\n",
    "    for i in range(pred_labels.shape[0]):\n",
    "        color_preds[i, pred_labels[i, :] == cls,:] = col\n",
    "        gt_color_preds[i, labels[i, :] == cls,:] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:16:32.722987Z",
     "iopub.status.busy": "2022-11-09T14:16:32.722597Z",
     "iopub.status.idle": "2022-11-09T14:16:33.976595Z",
     "shell.execute_reply": "2022-11-09T14:16:33.97577Z",
     "shell.execute_reply.started": "2022-11-09T14:16:32.722952Z"
    },
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "# And now let's see it !\n",
    "\n",
    "def denormalize_image(image, mean, std):\n",
    "    \"\"\"Denormalize the image.\"\"\"\n",
    "    return image * std[None, None, :] + mean[None, None, :]\n",
    "\n",
    "fig, axes = plt.subplots(len(images), 3, figsize=(15, 5 * len(images)))\n",
    "fig.subplots_adjust(wspace=0)\n",
    "\n",
    "for i, (image, color_pred, gt_color_pred) in enumerate(zip(images, color_preds, gt_color_preds)):\n",
    "    axes[i][0].imshow(denormalize_image(image, val_loader.normalization_means, val_loader.normalization_stds))\n",
    "    axes[i][0].axis('off')\n",
    "    axes[i][0].set_title(\"Image\")\n",
    "    axes[i][1].imshow(color_pred)\n",
    "    axes[i][1].axis('off')\n",
    "    axes[i][1].set_title(\"Prediction\")\n",
    "    axes[i][2].imshow(gt_color_pred)\n",
    "    axes[i][2].axis('off')\n",
    "    axes[i][2].set_title(\"GT\")\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('py38_data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "25f9a3951446179f6c2016b22a60b44495fe90f43bda7f3caedfe2c1a9cd31f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "bb76fb5fef92490eabccbe7f31d7a262",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Neural Networks for Time Series\n",
    "\n",
    "In this notebook, we'll cover topics related to learning from time series and sequential data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "2d3210fdee8646a2b2aa29cf62c64e2f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Preamble\n",
    "\n",
    "This lab session deals with the use of neural networks for time series classification and forecasting.\n",
    "Two kinds of architectures are considered here: convolutional and recurrent models. An illustration of attention-based models is provided at the end of the lab.\n",
    "\n",
    "## Time Series Classification using convolutional models (ConvNets)\n",
    "\n",
    "For a start, you will download and load the \"Trace\" dataset using the cells below.\n",
    "\n",
    "**Question #1.** What are the dimensions of the training data (`X_train`)? And what does each dimension correspond to (number of series, number of timestamps, number of features, ...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-01-24 09:08:28--  https://github.com/rtavenar/ml-datasets/releases/download/Trace/Trace.npz\n",
      "Résolution de github.com (github.com)… 140.82.121.3\n",
      "Connexion à github.com (github.com)|140.82.121.3|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 302 Found\n",
      "Emplacement : https://objects.githubusercontent.com/github-production-release-asset-2e65be/752757641/1e0daefa-6422-4b26-96a9-fc70f1536fd5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250124T080828Z&X-Amz-Expires=300&X-Amz-Signature=349ca8aec144946b30e8d80afa70ea6703106a8062dbfdb8a8f6a88bfdf12c4f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DTrace.npz&response-content-type=application%2Foctet-stream [suivant]\n",
      "--2025-01-24 09:08:28--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/752757641/1e0daefa-6422-4b26-96a9-fc70f1536fd5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250124T080828Z&X-Amz-Expires=300&X-Amz-Signature=349ca8aec144946b30e8d80afa70ea6703106a8062dbfdb8a8f6a88bfdf12c4f&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DTrace.npz&response-content-type=application%2Foctet-stream\n",
      "Résolution de objects.githubusercontent.com (objects.githubusercontent.com)… 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
      "Connexion à objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 224982 (220K) [application/octet-stream]\n",
      "Sauvegarde en : « Trace.npz »\n",
      "\n",
      "Trace.npz           100%[===================>] 219,71K   533KB/s    ds 0,4s    \n",
      "\n",
      "2025-01-24 09:08:30 (533 KB/s) — « Trace.npz » sauvegardé [224982/224982]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/rtavenar/ml-datasets/releases/download/Trace/Trace.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dataset = np.load(\"Trace.npz\")\n",
    "X_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "X_test,  y_test  = dataset[\"x_test\"],  dataset[\"y_test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 275, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8b1ec9d6bb1f4698b4857a2b60328708",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #2.** In the following, you will be implementing a ConvNet using keras' [`Conv1D`](https://keras.io/api/layers/convolution_layers/convolution1d/) layers.\n",
    "What value should be passed to the `data_format` parameter to match `tslearn` format? Is it the default value?\n",
    "\n",
    "**Your Answer here.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "dceb1bf5722e40ab9cd95032758c0507",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #3.** `keras` has a `Sequential` model class that allows to build models by stacking layers.\n",
    "Define a model that is made of the following layers (use ReLU activation wherever it makes sense):\n",
    "\n",
    "* a convolution layer made of 10 filters of size 3\n",
    "* a pooling layer of pool size 2\n",
    "* a flatten layer (that converts a time series of features into a flattened array that is suited to feed fully-connected layers)\n",
    "* a fully-connected layer that has as many neurons as the number of classes in the \"Trace\" problem, and an adequate activation function.\n",
    "\n",
    "Compile your model (use \"Adam\" optimizer) and fit it for 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "986a1a9144e84fadb31729e71692a784",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1869,
    "execution_start": 1643388899518,
    "output_cleared": true,
    "source_hash": "4ac327ac",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtavenar/Documents/ur2/2024-2025/deep-edhec/notebooks/venv/lib/python3.10/site-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.4029 - loss: 1.4456 - val_accuracy: 0.5700 - val_loss: 1.1243\n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4681 - loss: 1.1448 - val_accuracy: 0.4500 - val_loss: 0.9894\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5779 - loss: 0.9533 - val_accuracy: 0.4200 - val_loss: 0.9309\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5556 - loss: 0.8591 - val_accuracy: 0.4100 - val_loss: 0.8959\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5519 - loss: 0.8044 - val_accuracy: 0.3900 - val_loss: 0.8584\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5860 - loss: 0.7571 - val_accuracy: 0.4300 - val_loss: 0.8187\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5860 - loss: 0.7132 - val_accuracy: 0.4500 - val_loss: 0.7734\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6046 - loss: 0.6865 - val_accuracy: 0.4300 - val_loss: 0.7330\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6454 - loss: 0.6681 - val_accuracy: 0.4500 - val_loss: 0.7095\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6958 - loss: 0.6543 - val_accuracy: 0.5100 - val_loss: 0.7013\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv1D, MaxPool1D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(275, 1)),\n",
    "    Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "eb7b06ceddee4e479a36bb3a9495229a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #4.** Plot the evolution of accuracy through epochs on both training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "2da15a19e0cc4f379eb30b1708ce6c33",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1484,
    "execution_start": 1643388901250,
    "output_cleared": true,
    "source_hash": "abb80127",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(h.history[\"accuracy\"], label=\"Train acc.\")\n",
    "plt.plot(h.history[\"val_accuracy\"], label=\"Val. acc.\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a6cb7b7407934e2cb1a917bed0cd64da",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #5.** Ten epochs of training might not be sufficient, yet we do not know how many epochs would be necessary for a decent training. Set up early stopping (cf. [this callback](https://keras.io/api/callbacks/early_stopping/)) and see how long it takes before the model stops training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "fc03a35f7df04656bf23a6212266a4fe",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1523,
    "execution_start": 1643388902754,
    "output_cleared": true,
    "source_hash": "b57f1438",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2010 - loss: 1.5776 - val_accuracy: 0.5500 - val_loss: 1.1791\n",
      "Epoch 2/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4458 - loss: 1.2526 - val_accuracy: 0.5600 - val_loss: 0.9920\n",
      "Epoch 3/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.4487 - loss: 1.0231 - val_accuracy: 0.5000 - val_loss: 0.9004\n",
      "Epoch 4/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5756 - loss: 0.8830 - val_accuracy: 0.5000 - val_loss: 0.8601\n",
      "Epoch 5/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6587 - loss: 0.8066 - val_accuracy: 0.5500 - val_loss: 0.8440\n",
      "Epoch 6/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6729 - loss: 0.7486 - val_accuracy: 0.5500 - val_loss: 0.8123\n",
      "Epoch 7/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6558 - loss: 0.7224 - val_accuracy: 0.5500 - val_loss: 0.7616\n",
      "Epoch 8/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6350 - loss: 0.6977 - val_accuracy: 0.5700 - val_loss: 0.7194\n",
      "Epoch 9/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6758 - loss: 0.6657 - val_accuracy: 0.5800 - val_loss: 0.6980\n",
      "Epoch 10/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6535 - loss: 0.6620 - val_accuracy: 0.6000 - val_loss: 0.6904\n",
      "Epoch 11/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6625 - loss: 0.6535 - val_accuracy: 0.5600 - val_loss: 0.6927\n",
      "Epoch 12/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6640 - loss: 0.6385 - val_accuracy: 0.5600 - val_loss: 0.6973\n",
      "Epoch 13/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6692 - loss: 0.6199 - val_accuracy: 0.5600 - val_loss: 0.7045\n",
      "Epoch 14/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6654 - loss: 0.6105 - val_accuracy: 0.5700 - val_loss: 0.7083\n",
      "Epoch 15/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6721 - loss: 0.6125 - val_accuracy: 0.5700 - val_loss: 0.7148\n",
      "Epoch 16/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6892 - loss: 0.5981 - val_accuracy: 0.5600 - val_loss: 0.7132\n",
      "Epoch 17/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7025 - loss: 0.5968 - val_accuracy: 0.5500 - val_loss: 0.7070\n",
      "Epoch 18/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7129 - loss: 0.5811 - val_accuracy: 0.5400 - val_loss: 0.7008\n",
      "Epoch 19/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7300 - loss: 0.5726 - val_accuracy: 0.5500 - val_loss: 0.6944\n",
      "Epoch 20/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7604 - loss: 0.5678 - val_accuracy: 0.5500 - val_loss: 0.6865\n",
      "Epoch 21/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7092 - loss: 0.5722 - val_accuracy: 0.5700 - val_loss: 0.6817\n",
      "Epoch 22/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7538 - loss: 0.5643 - val_accuracy: 0.5700 - val_loss: 0.6842\n",
      "Epoch 23/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7181 - loss: 0.5571 - val_accuracy: 0.5800 - val_loss: 0.6891\n",
      "Epoch 24/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7538 - loss: 0.5493 - val_accuracy: 0.5600 - val_loss: 0.6884\n",
      "Epoch 25/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7381 - loss: 0.5447 - val_accuracy: 0.5500 - val_loss: 0.6838\n",
      "Epoch 26/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7529 - loss: 0.5441 - val_accuracy: 0.5400 - val_loss: 0.6799\n",
      "Epoch 27/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7515 - loss: 0.5497 - val_accuracy: 0.5700 - val_loss: 0.6812\n",
      "Epoch 28/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7262 - loss: 0.5378 - val_accuracy: 0.5800 - val_loss: 0.6888\n",
      "Epoch 29/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7590 - loss: 0.5256 - val_accuracy: 0.5900 - val_loss: 0.6942\n",
      "Epoch 30/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7448 - loss: 0.5272 - val_accuracy: 0.5900 - val_loss: 0.6838\n",
      "Epoch 31/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7619 - loss: 0.5226 - val_accuracy: 0.5900 - val_loss: 0.6740\n",
      "Epoch 32/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7767 - loss: 0.5176 - val_accuracy: 0.5900 - val_loss: 0.6651\n",
      "Epoch 33/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8413 - loss: 0.5096 - val_accuracy: 0.5600 - val_loss: 0.6605\n",
      "Epoch 34/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8465 - loss: 0.5096 - val_accuracy: 0.5800 - val_loss: 0.6618\n",
      "Epoch 35/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8294 - loss: 0.5142 - val_accuracy: 0.6000 - val_loss: 0.6642\n",
      "Epoch 36/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8004 - loss: 0.5156 - val_accuracy: 0.6000 - val_loss: 0.6626\n",
      "Epoch 37/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7975 - loss: 0.5054 - val_accuracy: 0.6000 - val_loss: 0.6620\n",
      "Epoch 38/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8071 - loss: 0.5052 - val_accuracy: 0.6100 - val_loss: 0.6577\n",
      "Epoch 39/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8198 - loss: 0.4848 - val_accuracy: 0.6100 - val_loss: 0.6616\n",
      "Epoch 40/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7738 - loss: 0.4895 - val_accuracy: 0.6200 - val_loss: 0.6556\n",
      "Epoch 41/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8294 - loss: 0.4878 - val_accuracy: 0.5700 - val_loss: 0.6479\n",
      "Epoch 42/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8204 - loss: 0.4974 - val_accuracy: 0.5700 - val_loss: 0.6439\n",
      "Epoch 43/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8346 - loss: 0.4840 - val_accuracy: 0.5800 - val_loss: 0.6433\n",
      "Epoch 44/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8108 - loss: 0.4896 - val_accuracy: 0.5700 - val_loss: 0.6465\n",
      "Epoch 45/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8175 - loss: 0.4820 - val_accuracy: 0.5800 - val_loss: 0.6490\n",
      "Epoch 46/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8123 - loss: 0.4728 - val_accuracy: 0.5800 - val_loss: 0.6480\n",
      "Epoch 47/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8175 - loss: 0.4796 - val_accuracy: 0.5700 - val_loss: 0.6463\n",
      "Epoch 48/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7967 - loss: 0.4826 - val_accuracy: 0.5800 - val_loss: 0.6465\n",
      "Epoch 49/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8279 - loss: 0.4682 - val_accuracy: 0.5800 - val_loss: 0.6470\n",
      "Epoch 50/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8123 - loss: 0.4745 - val_accuracy: 0.5900 - val_loss: 0.6518\n",
      "Epoch 51/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8413 - loss: 0.4631 - val_accuracy: 0.6100 - val_loss: 0.6570\n",
      "Epoch 52/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8383 - loss: 0.4528 - val_accuracy: 0.6200 - val_loss: 0.6609\n",
      "Epoch 53/100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8123 - loss: 0.4629 - val_accuracy: 0.6100 - val_loss: 0.6527\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cb = EarlyStopping(patience=10, monitor=\"val_loss\", restore_best_weights=True)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(275, 1)),\n",
    "    Conv1D(filters=10, kernel_size=3, activation=\"relu\"),\n",
    "    MaxPool1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=4, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "23a6010e38704d70931b751dc92f6378",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Recurrent neural nets\n",
    "\n",
    "For this new part of the lab, we will use the data generated from the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "7d66e1d72ce647f5aacf7a52058efbde",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 497,
    "execution_start": 1643388908680,
    "source_hash": "613c393b",
    "tags": [
     "keep"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_sines(n_series_per_class, length, length_padding=0):\n",
    "    t = np.linspace(0, 2 * np.pi, num=length)\n",
    "    X0 = .005 * np.random.randn(n_series_per_class, length + length_padding)\n",
    "    X0[:, :length] = np.sin(t).reshape((1, -1))\n",
    "    X0[:, length:] = np.sin(np.linspace(0, 2 * np.pi, num=length_padding))\n",
    "    \n",
    "    X1 = .005 * np.random.randn(n_series_per_class, length + length_padding)\n",
    "    X1[:, :length] = np.sin(-t).reshape((1, -1))\n",
    "    X1[:, length:] = np.sin(np.linspace(0, 2 * np.pi, num=length_padding))\n",
    "\n",
    "    dataset = np.array([X0, X1]).reshape((2 * n_series_per_class, length + length_padding, 1))\n",
    "    y = np.array([0] * n_series_per_class + [1] * n_series_per_class)\n",
    "\n",
    "    indices = np.random.permutation(2 * n_series_per_class)\n",
    "    return dataset[indices], y[indices]\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, y_train = make_sines(100, 50, length_padding=5)\n",
    "X_test, y_test = make_sines(100, 50, length_padding=5)\n",
    "\n",
    "plt.figure()\n",
    "colors = [\"r\", \"b\"]\n",
    "for ts, yi in zip(X_train, y_train):\n",
    "    plt.plot(ts.ravel(), color=colors[yi])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "99ca95a36a3f45aeade6cc9565c6db94",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #7.** Implement your own recurrent layer (_cf._ formulas in the course) using the skeleton below and train a network\n",
    "made of a single recurrent unit with a 8-dimensional hidden state followed by a fully connected layer, and evaluate its classification \n",
    "performance on the dataset provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "c8aa837080c744d8bc92d0e81b8945f0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1643388909180,
    "source_hash": "2aab574a",
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "from keras.ops import tanh, zeros\n",
    "\n",
    "class CustomRecurrentUnit(Layer):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # List sets of parameters here\n",
    "        self.w_h = self.add_weight(\n",
    "            shape=(hidden_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_h = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "        self.w_i = self.add_weight(\n",
    "            shape=(input_dim, hidden_dim), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "        self.b_i = self.add_weight(shape=(hidden_dim,), initializer=\"zeros\", trainable=True)\n",
    "    \n",
    "    def linear_hidden(self, h_t):\n",
    "        return h_t @ self.w_h + self.b_h\n",
    "    \n",
    "    def linear_input(self, x_t):\n",
    "        return x_t @ self.w_i + self.b_i\n",
    "    \n",
    "    def call(self, x):\n",
    "        n_timestamps = x.shape[1]\n",
    "        h = zeros((1, self.hidden_dim))  # Initialize h to [0, ..., 0]\n",
    "        for t in range(n_timestamps):\n",
    "            h = tanh(self.linear_hidden(h) + self.linear_input(x[:, t, :]))\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "22e3c8897c91438d93e01354657534f7",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #8.** Implement a network made of a `CustomRecurrentUnit` followed by a fully-connected layer\n",
    "for the classification task introduced above.\n",
    "Evaluate this model both in terms of training loss and test-set accuracy (you can use the above callback to limit the amount of logging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "b040773d7c16484e8a1ea1ab4a516996",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 65ms/step - accuracy: 0.4863 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5327 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4877 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4520 - loss: 0.6962 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5015 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5152 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5197 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5181 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4857 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5150 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5455 - loss: 0.6915 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4870 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4798 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4697 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4898 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5084 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4889 - loss: 0.6940 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5075 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4745 - loss: 0.6946 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4951 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5342 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.4863 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.4969 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5038 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5095 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5077 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6939\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5063 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6943\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5087 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6942\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.4939 - loss: 0.6950 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5142 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5072 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4551 - loss: 0.6945 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5021 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4712 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6927\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.4747 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6907\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5092 - loss: 0.6854 - val_accuracy: 1.0000 - val_loss: 0.5765\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.5148 - val_accuracy: 1.0000 - val_loss: 0.3617\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 0.2790 - val_accuracy: 1.0000 - val_loss: 0.0835\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0689 - val_accuracy: 1.0000 - val_loss: 0.0325\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0266 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 1.0000 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 1.0000 - val_loss: 0.0034\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.8802e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.8477e-04 - val_accuracy: 1.0000 - val_loss: 9.6570e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 9.6381e-04 - val_accuracy: 1.0000 - val_loss: 9.4423e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.4179e-04 - val_accuracy: 1.0000 - val_loss: 9.2355e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 9.1757e-04 - val_accuracy: 1.0000 - val_loss: 9.0360e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 1.0000 - loss: 9.0006e-04 - val_accuracy: 1.0000 - val_loss: 8.8436e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.7943e-04 - val_accuracy: 1.0000 - val_loss: 8.6575e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.6073e-04 - val_accuracy: 1.0000 - val_loss: 8.4767e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.4523e-04 - val_accuracy: 1.0000 - val_loss: 8.3022e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 8.2364e-04 - val_accuracy: 1.0000 - val_loss: 8.1337e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 8.0910e-04 - val_accuracy: 1.0000 - val_loss: 7.9702e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.9468e-04 - val_accuracy: 1.0000 - val_loss: 7.8128e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 7.7796e-04 - val_accuracy: 1.0000 - val_loss: 7.6598e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.6307e-04 - val_accuracy: 1.0000 - val_loss: 7.5118e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 1.0000 - loss: 7.4854e-04 - val_accuracy: 1.0000 - val_loss: 7.3684e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 7.3381e-04 - val_accuracy: 1.0000 - val_loss: 7.2291e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c7bc7c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    CustomRecurrentUnit(input_dim=1, hidden_dim=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "592d8ae6887f4bb9a7639bea3dfa6280",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #9.** Update your dataset so that it includes a final padding of 15 timestamps (_cf._ signature of the `make_sines` function)\n",
    "and see how it impacts performance of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "64253c69ae52450d913535407c8f0dc2",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = make_sines(100, 50, length_padding=15)\n",
    "X_test, y_test = make_sines(100, 50, length_padding=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8c515a15d64240d6b29af74010d8d52b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "**Question #10.** Build GRU (resp. LSTM) counterparts of the RNN-based model above.\n",
    "How do they compare experimentally to the previous model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "1e0462b0f9d6459782e117794c51ef4f",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 181ms/step - accuracy: 0.4375 - loss: 0.6953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtavenar/Documents/ur2/2024-2025/deep-edhec/notebooks/venv/lib/python3.10/site-packages/keras/src/backend/torch/linalg.py:53: UserWarning: The operator 'aten::linalg_qr.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch.linalg.qr(x, mode=mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 0.4670 - loss: 0.6939 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.5164 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5145 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 0.5167 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5112 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5233 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.4826 - loss: 0.6946 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 0.4607 - loss: 0.6955 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.4819 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.5001 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.5223 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 0.4965 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5033 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.4497 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 0.4946 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5282 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 0.4197 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4861 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4574 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4137 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.5377 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4729 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6930\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 0.5057 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.5345 - loss: 0.6914 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.5227 - loss: 0.6911 - val_accuracy: 0.5000 - val_loss: 0.6919\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 0.4966 - loss: 0.6936 - val_accuracy: 1.0000 - val_loss: 0.6867\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.6813 - val_accuracy: 1.0000 - val_loss: 0.6312\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 0.9678 - loss: 0.5891 - val_accuracy: 1.0000 - val_loss: 0.4403\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.4025 - val_accuracy: 1.0000 - val_loss: 0.2570\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.2060 - val_accuracy: 1.0000 - val_loss: 0.1064\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0842 - val_accuracy: 1.0000 - val_loss: 0.0434\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 0.0229\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0131\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0121 - val_accuracy: 1.0000 - val_loss: 0.0089\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 0.0070\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 1.0000 - val_loss: 0.0057\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 1.0000 - val_loss: 0.0049\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 9.8453e-04\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 9.7795e-04 - val_accuracy: 1.0000 - val_loss: 9.5768e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 9.5161e-04 - val_accuracy: 1.0000 - val_loss: 9.3211e-04\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 9.2662e-04 - val_accuracy: 1.0000 - val_loss: 9.0777e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 9.0241e-04 - val_accuracy: 1.0000 - val_loss: 8.8448e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 8.7937e-04 - val_accuracy: 1.0000 - val_loss: 8.6217e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 8.5726e-04 - val_accuracy: 1.0000 - val_loss: 8.4081e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 8.3613e-04 - val_accuracy: 1.0000 - val_loss: 8.2047e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 8.1600e-04 - val_accuracy: 1.0000 - val_loss: 8.0087e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 7.9656e-04 - val_accuracy: 1.0000 - val_loss: 7.8214e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 7.7784e-04 - val_accuracy: 1.0000 - val_loss: 7.6416e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 7.6055e-04 - val_accuracy: 1.0000 - val_loss: 7.4686e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 7.4305e-04 - val_accuracy: 1.0000 - val_loss: 7.3024e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 7.2650e-04 - val_accuracy: 1.0000 - val_loss: 7.1423e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 7.1048e-04 - val_accuracy: 1.0000 - val_loss: 6.9890e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 6.9540e-04 - val_accuracy: 1.0000 - val_loss: 6.8405e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 139ms/step - accuracy: 1.0000 - loss: 6.8071e-04 - val_accuracy: 1.0000 - val_loss: 6.6973e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 6.6662e-04 - val_accuracy: 1.0000 - val_loss: 6.5599e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 6.5292e-04 - val_accuracy: 1.0000 - val_loss: 6.4263e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step - accuracy: 1.0000 - loss: 6.3960e-04 - val_accuracy: 1.0000 - val_loss: 6.2980e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 6.2697e-04 - val_accuracy: 1.0000 - val_loss: 6.1743e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 142ms/step - accuracy: 1.0000 - loss: 6.1465e-04 - val_accuracy: 1.0000 - val_loss: 6.0538e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 138ms/step - accuracy: 1.0000 - loss: 6.0272e-04 - val_accuracy: 1.0000 - val_loss: 5.9378e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 140ms/step - accuracy: 1.0000 - loss: 5.9122e-04 - val_accuracy: 1.0000 - val_loss: 5.8254e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - accuracy: 1.0000 - loss: 5.8001e-04 - val_accuracy: 1.0000 - val_loss: 5.7171e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 145ms/step - accuracy: 1.0000 - loss: 5.6921e-04 - val_accuracy: 1.0000 - val_loss: 5.6119e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 149ms/step - accuracy: 1.0000 - loss: 5.5886e-04 - val_accuracy: 1.0000 - val_loss: 5.5096e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 5.4861e-04 - val_accuracy: 1.0000 - val_loss: 5.4103e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143ms/step - accuracy: 1.0000 - loss: 5.3885e-04 - val_accuracy: 1.0000 - val_loss: 5.3152e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 5.2925e-04 - val_accuracy: 1.0000 - val_loss: 5.2221e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 1.0000 - loss: 5.2023e-04 - val_accuracy: 1.0000 - val_loss: 5.1315e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step - accuracy: 1.0000 - loss: 5.1104e-04 - val_accuracy: 1.0000 - val_loss: 5.0441e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 147ms/step - accuracy: 1.0000 - loss: 5.0247e-04 - val_accuracy: 1.0000 - val_loss: 4.9585e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c873370>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "model = Sequential([\n",
    "    GRU(units=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.4917 - loss: 0.6911 - val_accuracy: 0.5000 - val_loss: 0.6795\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 0.4739 - loss: 0.6765 - val_accuracy: 1.0000 - val_loss: 0.6460\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.6273 - val_accuracy: 1.0000 - val_loss: 0.5491\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.5147 - val_accuracy: 1.0000 - val_loss: 0.3956\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.3682 - val_accuracy: 1.0000 - val_loss: 0.2447\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.2151 - val_accuracy: 1.0000 - val_loss: 0.1608\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.1559 - val_accuracy: 1.0000 - val_loss: 0.1114\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.1044 - val_accuracy: 1.0000 - val_loss: 0.0798\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0779 - val_accuracy: 1.0000 - val_loss: 0.0586\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0567 - val_accuracy: 1.0000 - val_loss: 0.0445\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0416 - val_accuracy: 1.0000 - val_loss: 0.0353\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0331 - val_accuracy: 1.0000 - val_loss: 0.0288\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 1.0000 - val_loss: 0.0241\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0239 - val_accuracy: 1.0000 - val_loss: 0.0206\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 1.0000 - val_loss: 0.0179\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 1.0000 - val_loss: 0.0157\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0153 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 1.0000 - val_loss: 0.0125\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 0.0112\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 0.0102\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0093\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 0.0085\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 128ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 1.0000 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 0.0072\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 1.0000 - val_loss: 0.0067\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 1.0000 - val_loss: 0.0058\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 1.0000 - val_loss: 0.0054\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 1.0000 - val_loss: 0.0051\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 1.0000 - val_loss: 0.0045\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 1.0000 - val_loss: 0.0037\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0032 - val_accuracy: 1.0000 - val_loss: 0.0032\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 1.0000 - val_loss: 0.0030\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 1.0000 - val_loss: 0.0028\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0026 - val_accuracy: 1.0000 - val_loss: 0.0026\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0024 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0022 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 1.0000 - val_loss: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 9.9650e-04 - val_accuracy: 1.0000 - val_loss: 9.8636e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 9.8778e-04 - val_accuracy: 1.0000 - val_loss: 9.6532e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 9.6027e-04 - val_accuracy: 1.0000 - val_loss: 9.4519e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 1.0000 - loss: 9.3805e-04 - val_accuracy: 1.0000 - val_loss: 9.2562e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 9.2604e-04 - val_accuracy: 1.0000 - val_loss: 9.0671e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 8.9940e-04 - val_accuracy: 1.0000 - val_loss: 8.8836e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 114ms/step - accuracy: 1.0000 - loss: 8.8514e-04 - val_accuracy: 1.0000 - val_loss: 8.7067e-04\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 8.6490e-04 - val_accuracy: 1.0000 - val_loss: 8.5361e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 8.4761e-04 - val_accuracy: 1.0000 - val_loss: 8.3703e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 124ms/step - accuracy: 1.0000 - loss: 8.3317e-04 - val_accuracy: 1.0000 - val_loss: 8.2095e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 8.1908e-04 - val_accuracy: 1.0000 - val_loss: 8.0544e-04\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 8.1020e-04 - val_accuracy: 1.0000 - val_loss: 7.9041e-04\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 1.0000 - loss: 7.8785e-04 - val_accuracy: 1.0000 - val_loss: 7.7585e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 7.7494e-04 - val_accuracy: 1.0000 - val_loss: 7.6168e-04\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 7.5837e-04 - val_accuracy: 1.0000 - val_loss: 7.4788e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 7.3818e-04 - val_accuracy: 1.0000 - val_loss: 7.3451e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 7.3696e-04 - val_accuracy: 1.0000 - val_loss: 7.2145e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 7.1553e-04 - val_accuracy: 1.0000 - val_loss: 7.0887e-04\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 6.9999e-04 - val_accuracy: 1.0000 - val_loss: 6.9655e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 1.0000 - loss: 6.9936e-04 - val_accuracy: 1.0000 - val_loss: 6.8456e-04\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 117ms/step - accuracy: 1.0000 - loss: 6.8349e-04 - val_accuracy: 1.0000 - val_loss: 6.7287e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step - accuracy: 1.0000 - loss: 6.7227e-04 - val_accuracy: 1.0000 - val_loss: 6.6154e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 6.5570e-04 - val_accuracy: 1.0000 - val_loss: 6.5056e-04\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 1.0000 - loss: 6.5163e-04 - val_accuracy: 1.0000 - val_loss: 6.3977e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 1.0000 - loss: 6.3133e-04 - val_accuracy: 1.0000 - val_loss: 6.2927e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c7abeb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(units=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5238 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 2/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4784 - loss: 0.6941 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5317 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4556 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4976 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5276 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 7/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4844 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4757 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 9/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5683 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 10/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4842 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 11/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4816 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 12/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4754 - loss: 0.6941 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 13/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5120 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6935\n",
      "Epoch 14/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5091 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
      "Epoch 15/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4879 - loss: 0.6946 - val_accuracy: 0.5000 - val_loss: 0.6937\n",
      "Epoch 16/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5111 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
      "Epoch 17/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5198 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6936\n",
      "Epoch 18/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4929 - loss: 0.6941 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 19/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5132 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 20/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4654 - loss: 0.6947 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 21/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5283 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 22/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.5068 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 23/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5176 - loss: 0.6927 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 24/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5296 - loss: 0.6925 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 25/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5295 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 26/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4926 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 27/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5348 - loss: 0.6922 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 28/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4976 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 29/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4839 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 30/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5128 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 31/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5368 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 32/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5477 - loss: 0.6926 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 33/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4917 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 34/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5063 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 35/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.4711 - loss: 0.6946 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 36/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5060 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 37/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5261 - loss: 0.6923 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 38/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4855 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 39/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4945 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 40/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4783 - loss: 0.6938 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 41/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4803 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 42/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5350 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 43/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5089 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 44/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5405 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 45/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5144 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 46/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5051 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 47/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4672 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 48/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4535 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 49/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5165 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 50/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4429 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 51/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4785 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 52/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5194 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 53/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4821 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 54/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4777 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 55/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4883 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 56/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4517 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 57/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5086 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 58/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4893 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 59/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5445 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 60/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5025 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 61/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4001 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 62/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5445 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 63/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5005 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 64/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4752 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 65/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5248 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 66/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5128 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 67/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.5244 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 68/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5252 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 69/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.5258 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 70/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5024 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 71/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5081 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 72/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5268 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 73/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4759 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 74/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5137 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931\n",
      "Epoch 75/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4687 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 76/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.4928 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 77/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5007 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 78/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4660 - loss: 0.6942 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 79/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4713 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 80/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5075 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 81/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5202 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 82/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5151 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 83/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5160 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 84/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4919 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 85/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4857 - loss: 0.6937 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 86/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5103 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6934\n",
      "Epoch 87/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4977 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6933\n",
      "Epoch 88/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5064 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 89/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5096 - loss: 0.6930 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 90/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5359 - loss: 0.6928 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 91/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4958 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 92/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5031 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 93/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5294 - loss: 0.6929 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 94/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4825 - loss: 0.6934 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 95/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4619 - loss: 0.6935 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 96/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.5081 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 97/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5009 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 98/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4475 - loss: 0.6943 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 99/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.4764 - loss: 0.6936 - val_accuracy: 0.5000 - val_loss: 0.6932\n",
      "Epoch 100/100\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4925 - loss: 0.6933 - val_accuracy: 0.5000 - val_loss: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16c8713c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    CustomRecurrentUnit(input_dim=1, hidden_dim=32),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "9a3e4c2e84c041f7a18f34c6fb35cdb5",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Recap\n",
    "\n",
    "**Question #11.** Come back to the \"Trace\" dataset used above and design a fair comparison between several convolutional and recurrent architectures to decide which one to choose for the problem at hand (feel free to play with the depth of the nets, as well as hidden representation dimensionality, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "3020b8693ec140de8384108efb3d753e",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5825 - loss: 0.7341\n",
      "Conv_1layer [0.7195982336997986, 0.6100000143051147]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5555 - loss: 0.7507\n",
      "Conv_2layers [0.7200766205787659, 0.6100000143051147]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5172 - loss: 0.7825\n",
      "Conv_3layers [0.7569155097007751, 0.5299999713897705]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 134ms/step - accuracy: 0.6169 - loss: 0.6739\n",
      "LSTM_1layer [0.6849170923233032, 0.6100000143051147]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 257ms/step - accuracy: 0.4785 - loss: 0.7337\n",
      "LSTM_2layers [0.7400521039962769, 0.47999998927116394]\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 394ms/step - accuracy: 0.5115 - loss: 0.8703\n",
      "LSTM_3layers [0.8561785817146301, 0.5]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.load(\"Trace.npz\")\n",
    "X_train, y_train = dataset[\"x_train\"], dataset[\"y_train\"]\n",
    "X_test,  y_test  = dataset[\"x_test\"],  dataset[\"y_test\"]\n",
    "\n",
    "\n",
    "feature_extractors = {\n",
    "    \"Conv_1layer\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\")\n",
    "    ]),\n",
    "    \"Conv_2layers\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "    ]),\n",
    "    \"Conv_3layers\": Sequential([\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "        Conv1D(filters=25, kernel_size=5, activation=\"relu\"),\n",
    "    ]),\n",
    "    \"LSTM_1layer\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True)\n",
    "    ]),\n",
    "    \"LSTM_2layers\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "    ]),\n",
    "    \"LSTM_3layers\": Sequential([\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True),\n",
    "        LSTM(units=25, return_sequences=True)\n",
    "    ]),\n",
    "}\n",
    "\n",
    "for name, f in feature_extractors.items():\n",
    "    model = Sequential([\n",
    "        f,\n",
    "        Flatten(),\n",
    "        Dense(units=4, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    h = model.fit(X_train, y_train, epochs=10, verbose=False)\n",
    "    print(name, model.evaluate(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "25ccbef48c0041259097a232f5d6522e",
  "kernelspec": {
   "display_name": "py38_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "25f9a3951446179f6c2016b22a60b44495fe90f43bda7f3caedfe2c1a9cd31f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

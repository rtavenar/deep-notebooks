{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-a1adc4b1-4149-4f25-83f8-faabc945a92c",
    "deepnote_cell_type": "markdown",
    "id": "MTDStjAJrLT-",
    "tags": []
   },
   "outputs": "",
   "source": [
    "# Images and convolutional networks\n",
    "\n",
    "In this notebook, we will dig deeper into convolutional neural networks for image classification.\n",
    "\n",
    "## Filter visualization\n",
    "\n",
    "We will first try to visualize what these networks learn, _i.e._ what kind of local patterns their convolution blocks typically detect.\n",
    "For this exercise, we will focus on the first layer of these models to keep the maths simple.\n",
    "\n",
    "**Question 1.** Suppose a model has learned a convolution filter (_aka_ kernel) $W$ and a bias $b$.\n",
    "What is (theoretically) the unit-norm image patch $P$ that maximizes the ouput activation for \n",
    "this specific configuration:\n",
    "\n",
    "$$\\max_{P} \\varphi(W \\cdot P + b)) \\text{ such that } \\|P\\| = 1$$\n",
    "\n",
    "where $\\varphi$ is the activation function, for which our only assumption will be that it is an non-decreasing function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-716925eb-afb4-4200-b267-0ceaa591c3ca",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "Write your (text) answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-432ef628-e939-4322-829b-40a0658c80e2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 2.** Given your answer above, and the model fit below, visualize, for each filter of the first convolutional \n",
    "layer, the input patch that would correspond to maximum activation.\n",
    "See [`keras` docs](https://keras.io/api/layers/) for more information on how to access weights of \n",
    "a given layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00003-21e8f66a-2713-45dc-87fa-c88e1a44caad",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2149,
    "execution_start": 1614771639461,
    "id": "eZHk0xOhqUH6",
    "outputId": "39552619-cae6-44e7-bbc4-acaf800af98f",
    "output_cleared": false,
    "source_hash": "ffa07d02",
    "tags": []
   },
   "outputs": "",
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def prepare_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train / 255.\n",
    "    x_test = x_test / 255.\n",
    "    x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "    x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "    \n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00004-8ae61253-9ea8-4e40-bab1-7031326481c7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 124121,
    "execution_start": 1614771645224,
    "id": "ug40MwR-uD0X",
    "outputId": "0683554f-22d6-4b3d-c5f0-ba80a33b13ef",
    "output_cleared": false,
    "source_hash": "b8f76da2",
    "tags": []
   },
   "outputs": "",
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "first_conv_layer = Conv2D(filters=5, kernel_size=4, padding='valid', activation=\"relu\")\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=(28, 28, 1)),\n",
    "    first_conv_layer,\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Conv2D(filters=10, kernel_size=5, padding='valid', activation=\"relu\"),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=100, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00005-8b52665c-a14e-49b0-aed8-314f1da3fd1c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 228,
    "execution_start": 1614771788343,
    "output_cleared": true,
    "source_hash": "fd189b5a",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-1cf6b102-550a-43fd-a591-dc8f44048c0a",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 3.** Repeat this process for the pre-trained ResNet50 model you used in the previous\n",
    "lab session.\n",
    "Visualize the first 16 filters of the first convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00007-7c42c15f-ed4e-475e-8ee7-9e4b0c284bfc",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-30462a62-6e73-4e35-b07f-a45ae67d1b04",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "# Adversarial examples\n",
    "\n",
    "In this section, we will illustrate the concept of adversarial examples and implement a simple \n",
    "[fast-sign-gradient method](https://arxiv.org/abs/1412.6572) to generate such examples.\n",
    "The idea of this method is the following:\n",
    "\n",
    "Suppose we denote by $\\mathcal{L}(x, y; \\theta)$ the loss function (typically categorical cross-entropy) evaluated for\n",
    "the current parameters $\\theta$ of a model on a single example $(x, y)$.\n",
    "If we compute the gradient of $\\mathcal{L}$ **with respect to $x$**, it will give us the direction of \n",
    "steepest increase \n",
    "of $\\mathcal{L}$, hence the the direction that is most likely to increase $\\mathcal{L}$ if we perform a small modification on $x$ (not on model parameters, as we usually do when our goal is to fit a model).\n",
    "Hence if we push $x$ (which is an image here) in that direction, we will perform a gradient ascent on $x$, \n",
    "which means we will change its pixel content in order to fool the \n",
    "classifier.\n",
    "If we are able to fool the classifier even with small changes, we have successfully generated an adversarial example: an \n",
    "example that is generated on purpose to look easy to classify for a human eye, but still fool the classifier.\n",
    "\n",
    "More precisely the update rule for the fast-sign-gradient method is:\n",
    "\n",
    "$$x^{(t+1)} = x^{(t)}+ \\eta \\, \\text{sign}(\\nabla_x\\mathcal{L}(x^{(t)}, y; \\theta))$$\n",
    "\n",
    "where $\\eta$ is a gradient step (or learning rate).\n",
    "\n",
    "Note that an alternative way to use this fast-sign-gradient method would be to perform a gradient descent (not ascent, this time)\n",
    "on the quantity $\\mathcal{L}(x, y^\\prime; \\theta)$ where $y^\\prime$ is a target class that we want the classifier to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00009-6e6d0711-b1a6-449e-adc0-de08e606fcc5",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 206,
    "execution_start": 1614771791687,
    "source_hash": "3d7fee32",
    "tags": []
   },
   "outputs": "",
   "source": [
    "img = x_test[0]\n",
    "\n",
    "plt.imshow(img, cmap='gray')\n",
    "label = y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-5fdaa36f-d5ac-45fc-85cd-221129dc7cb8",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 3.** For the first sample in the MNIST test set (plotted just above ⬆️), what is the probability assigned by\n",
    "the simple model (made of 2 convolutional layers) defined above to **the correct class**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00011-5c8a881e-0bbf-4cf8-8f51-83d8c7cb339c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1614771794790,
    "output_cleared": false,
    "source_hash": "85f5147d",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-52869203-fdc6-4707-9250-ec8315960ec6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 4.** The code below adds white noise to the image. See how this impacts (or not) the prediction quality of \n",
    "the model on this sample. You can play with the level of white noise to better visualize the robustness of the model to this \n",
    "kind of content modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "noisy_image = img + .1 * np.random.randn(*img.shape)\n",
    "plt.imshow(noisy_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00013-e188da28-1400-46b9-a0dc-7a3903734287",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.199996948242188,
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 116,
    "execution_start": 1614771797978,
    "output_cleared": false,
    "source_hash": "7a8c18f3",
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00014-8ebccdf8-ada4-49dd-8b54-bce9a0b6573d",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 5.** The function `sign_grad` below computes the quantity $\\text{sign}(\\nabla_x\\mathcal{L}(x^{(t)}, y; \\theta))$.\n",
    "Using calls to this function, iteratively change the content of the non-noisy image to generate an adversarial example.\n",
    "You can use a gradient step of .1 and 5 iterations should be sufficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00015-0ce89e7d-6f58-40b9-b51f-43918dbf4f9a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1614771800982,
    "output_cleared": true,
    "source_hash": "7c661f81",
    "tags": []
   },
   "outputs": "",
   "source": [
    "import tensorflow as tf\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "def sign_grad(model, image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "\n",
    "    image_batch = image[None]\n",
    "    label_batch = label[None]\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(image_batch)\n",
    "        prediction = model(image_batch)\n",
    "        loss = CategoricalCrossentropy()(label_batch, prediction)\n",
    "    \n",
    "    gradient = tape.gradient(loss, image_batch)\n",
    "    \n",
    "    signed_grad = tf.sign(gradient)\n",
    "    \n",
    "    return signed_grad[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-3d4aa88d-b20c-4e2b-a03a-71537a64af1b",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 6.** Adapt your code above to push the model towards classifying the image into a 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "00017-1222c7f3-8b52-44e1-9560-07f295415c39",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 93,
    "execution_start": 1614771991443,
    "output_cleared": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": "",
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Images & ConvNets.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "303bba85-4d53-440b-942d-6eadc6d91c15",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of automatic differentiation in PyTorch\n",
    "\n",
    "In this notebook, you will go through the basic notions of automatic differentiation (aka autodiff) in PyTorch.\n",
    "\n",
    "## 1. Manual differentiation in pure Python\n",
    "\n",
    "Before starting with `pytorch` and its automatic differentiation features, let us have a look at how to do manual differentiation in Python.\n",
    "\n",
    "To do so, we will use a very basic example in 1D: let $x$ be a scalar and let $y$ be defined as:\n",
    "\n",
    "$$y = (x - .5)^2$$\n",
    "\n",
    "Our goal will be to tune $x$ in order to minimize $y$.\n",
    "\n",
    "**Question 1.1.** Define a function `f` that takes `x` as input and returns `y` as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x - .5) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to minimize, we will use a strategy called gradient descent.\n",
    "The idea of gradient descent is to iteratively update $x$ by moving it in the opposite direction of the gradient $\\frac{\\partial y}{\\partial x}$.\n",
    "We hence need to be able to compute $\\frac{\\partial y}{\\partial x}$.\n",
    "Since we do not rely on autodiff for now, we need to provide the explicit formula for this derivative.\n",
    "\n",
    "**Question 1.2.** Define a function `grad_f` that takes `x` as input and returns $\\frac{\\partial y}{\\partial x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr",
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def grad_f(x):\n",
    "    return 2 * (x - .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea behind gradient descent is to iteratively update $x$ using the following update rule:\n",
    "\n",
    "$$x \\leftarrow x - \\eta \\frac{\\partial y}{\\partial x}$$\n",
    "\n",
    "**Question 1.3.** Define a starting value for `x` and a step size `eta` and apply gradient descent for 30 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.2\n",
      "0.26\n",
      "0.308\n",
      "0.3464\n",
      "0.37712\n",
      "0.401696\n",
      "0.4213568\n",
      "0.43708544\n",
      "0.449668352\n",
      "0.4597346816\n",
      "0.46778774528\n",
      "0.474230196224\n",
      "0.4793841569792\n",
      "0.48350732558336\n",
      "0.486805860466688\n",
      "0.4894446883733504\n",
      "0.49155575069868035\n",
      "0.49324460055894426\n",
      "0.4945956804471554\n",
      "0.49567654435772435\n",
      "0.49654123548617946\n",
      "0.4972329883889436\n",
      "0.4977863907111549\n",
      "0.4982291125689239\n",
      "0.49858329005513913\n",
      "0.4988666320441113\n",
      "0.49909330563528903\n",
      "0.4992746445082312\n",
      "0.499419715606585\n"
     ]
    }
   ],
   "source": [
    "x = 0.125\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 30\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(x)\n",
    "    y = f(x)\n",
    "    x -= stepsize * grad_f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.4.** Is the resulting value for `x` close to the value you would expect as a minimizer for $y = f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PyTorch and the automatic computation of gradients\n",
    "\n",
    "PyTorch is very similar to numpy in practice. One main difference is that one can ask, at any moment, for the automatic computation of gradients.\n",
    "\n",
    "To do so, if one wants to trigger the computation of $\\frac{\\partial a}{\\partial b}$ for any $b$, she should write:\n",
    "\n",
    "```python\n",
    "a.backward()\n",
    "```\n",
    "\n",
    "This will trigger the computation of the gradient of `a` with respect to any tensor that was involved in the computation of `a`.\n",
    "\n",
    "And the gradient $\\frac{\\partial a}{\\partial b}$ will be stored in `b.grad`.\n",
    "\n",
    "**Question 2.1.** Fill the code below to check what the gradient of `x` is before calling `backward()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def f(x):\n",
    "    return (x - .5) ** 2\n",
    "\n",
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def f(x):\n",
    "    return (x - .5) ** 2\n",
    "\n",
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "# Fill the code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Now, trigger the computation of gradients $\\frac{\\partial y}{\\partial x}$ and print this gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "tensor(-0.7500)\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gradient descent in PyTorch\n",
    "\n",
    "**Question 3.1.** Try to implement the gradient descent from Section 1 in PyTorch this time. You do not need to use `grad_f` anymore in your computations.\n",
    "Each iteration should consist in:\n",
    "1. computing `y` based on the current value for `x` ;\n",
    "2. explicitly forcing gradient computations ;\n",
    "3. updating `x` (this step needs to be protected in a `with torch.no_grad():` block) ;\n",
    "4. zero-ing out gradients of `x` for future steps not to accumulate gradient computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 30\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # Compute y and force gradient computations\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Update x\n",
    "        pass\n",
    "    # Zero-out gradients (code below is OK, leave it as it is)\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "keep_corr",
     "keep"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, requires_grad=True)\n",
      "tensor(0.2000, requires_grad=True)\n",
      "tensor(0.2600, requires_grad=True)\n",
      "tensor(0.3080, requires_grad=True)\n",
      "tensor(0.3464, requires_grad=True)\n",
      "tensor(0.3771, requires_grad=True)\n",
      "tensor(0.4017, requires_grad=True)\n",
      "tensor(0.4214, requires_grad=True)\n",
      "tensor(0.4371, requires_grad=True)\n",
      "tensor(0.4497, requires_grad=True)\n",
      "tensor(0.4597, requires_grad=True)\n",
      "tensor(0.4678, requires_grad=True)\n",
      "tensor(0.4742, requires_grad=True)\n",
      "tensor(0.4794, requires_grad=True)\n",
      "tensor(0.4835, requires_grad=True)\n",
      "tensor(0.4868, requires_grad=True)\n",
      "tensor(0.4894, requires_grad=True)\n",
      "tensor(0.4916, requires_grad=True)\n",
      "tensor(0.4932, requires_grad=True)\n",
      "tensor(0.4946, requires_grad=True)\n",
      "tensor(0.4957, requires_grad=True)\n",
      "tensor(0.4965, requires_grad=True)\n",
      "tensor(0.4972, requires_grad=True)\n",
      "tensor(0.4978, requires_grad=True)\n",
      "tensor(0.4982, requires_grad=True)\n",
      "tensor(0.4986, requires_grad=True)\n",
      "tensor(0.4989, requires_grad=True)\n",
      "tensor(0.4991, requires_grad=True)\n",
      "tensor(0.4993, requires_grad=True)\n",
      "tensor(0.4994, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 30\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(x)\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x -= stepsize * x.grad\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wrap-up: optimizing parameters of a univariate linear regression model\n",
    "\n",
    "Below is some code to generate (and visualize) the synthetic dataset you will use in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "keep",
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x169a7aad0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = torch.rand(100, 1)\n",
    "# w* = -3, b* = 1.5\n",
    "y = -3. * X + 1.5 + 0.4 * torch.randn(X.size())\n",
    "\n",
    "plt.scatter(X.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will try to fit a linear regression model to this dataset.\n",
    "\n",
    "**Question 4.1.** Given the code that generated the dataset, what should be the ideal values for $w$ and $b$ in your linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3.** Implement a function `mse` that would take `X`, `y`, `w`, `b` as inputs and outputs the mean squared error of the linear model parametrized by `w` and `b` on the dataset $(X, y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [],
   "source": [
    "def mse(X, y, w, b):\n",
    "    y_pred = w * X + b\n",
    "    return torch.mean((y_pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2.** Implement a gradient descent loop to fit `w` and `b` that would minimize the mean squared error criterion based on the provided dataset. Use a step size of 0.1 and perform 1000 iterations of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, requires_grad=True) tensor(-0.1250, requires_grad=True) 0.8617132306098938\n",
      "tensor(0.0788, requires_grad=True) tensor(-0.1221, requires_grad=True) 0.8408882021903992\n",
      "tensor(0.0356, requires_grad=True) tensor(-0.1150, requires_grad=True) 0.8221014142036438\n",
      "tensor(-0.0053, requires_grad=True) tensor(-0.1046, requires_grad=True) 0.8046115636825562\n",
      "tensor(-0.0443, requires_grad=True) tensor(-0.0920, requires_grad=True) 0.788007915019989\n",
      "tensor(-0.0818, requires_grad=True) tensor(-0.0778, requires_grad=True) 0.7720614671707153\n",
      "tensor(-0.1181, requires_grad=True) tensor(-0.0625, requires_grad=True) 0.7566422820091248\n",
      "tensor(-0.1534, requires_grad=True) tensor(-0.0463, requires_grad=True) 0.741675615310669\n",
      "tensor(-0.1879, requires_grad=True) tensor(-0.0297, requires_grad=True) 0.7271159887313843\n",
      "tensor(-0.2216, requires_grad=True) tensor(-0.0127, requires_grad=True) 0.7129348516464233\n",
      "tensor(-0.2547, requires_grad=True) tensor(0.0045, requires_grad=True) 0.6991128325462341\n",
      "tensor(-0.2873, requires_grad=True) tensor(0.0217, requires_grad=True) 0.685635507106781\n",
      "tensor(-0.3193, requires_grad=True) tensor(0.0390, requires_grad=True) 0.6724913716316223\n",
      "tensor(-0.3508, requires_grad=True) tensor(0.0562, requires_grad=True) 0.6596706509590149\n",
      "tensor(-0.3819, requires_grad=True) tensor(0.0733, requires_grad=True) 0.6471644043922424\n",
      "tensor(-0.4126, requires_grad=True) tensor(0.0902, requires_grad=True) 0.6349644660949707\n",
      "tensor(-0.4428, requires_grad=True) tensor(0.1071, requires_grad=True) 0.6230631470680237\n",
      "tensor(-0.4726, requires_grad=True) tensor(0.1237, requires_grad=True) 0.6114529967308044\n",
      "tensor(-0.5021, requires_grad=True) tensor(0.1402, requires_grad=True) 0.6001267433166504\n",
      "tensor(-0.5312, requires_grad=True) tensor(0.1566, requires_grad=True) 0.5890774726867676\n",
      "tensor(-0.5599, requires_grad=True) tensor(0.1727, requires_grad=True) 0.5782983899116516\n",
      "tensor(-0.5882, requires_grad=True) tensor(0.1887, requires_grad=True) 0.5677827596664429\n",
      "tensor(-0.6162, requires_grad=True) tensor(0.2045, requires_grad=True) 0.5575241446495056\n",
      "tensor(-0.6438, requires_grad=True) tensor(0.2201, requires_grad=True) 0.5475164651870728\n",
      "tensor(-0.6711, requires_grad=True) tensor(0.2355, requires_grad=True) 0.5377533435821533\n",
      "tensor(-0.6981, requires_grad=True) tensor(0.2507, requires_grad=True) 0.5282289981842041\n",
      "tensor(-0.7247, requires_grad=True) tensor(0.2657, requires_grad=True) 0.5189374685287476\n",
      "tensor(-0.7510, requires_grad=True) tensor(0.2806, requires_grad=True) 0.5098730325698853\n",
      "tensor(-0.7770, requires_grad=True) tensor(0.2952, requires_grad=True) 0.5010302066802979\n",
      "tensor(-0.8026, requires_grad=True) tensor(0.3097, requires_grad=True) 0.4924035668373108\n",
      "tensor(-0.8280, requires_grad=True) tensor(0.3240, requires_grad=True) 0.48398783802986145\n",
      "tensor(-0.8530, requires_grad=True) tensor(0.3382, requires_grad=True) 0.47577786445617676\n",
      "tensor(-0.8777, requires_grad=True) tensor(0.3521, requires_grad=True) 0.4677685499191284\n",
      "tensor(-0.9021, requires_grad=True) tensor(0.3659, requires_grad=True) 0.4599550664424896\n",
      "tensor(-0.9262, requires_grad=True) tensor(0.3796, requires_grad=True) 0.45233261585235596\n",
      "tensor(-0.9500, requires_grad=True) tensor(0.3930, requires_grad=True) 0.4448964297771454\n",
      "tensor(-0.9736, requires_grad=True) tensor(0.4063, requires_grad=True) 0.4376421272754669\n",
      "tensor(-0.9968, requires_grad=True) tensor(0.4194, requires_grad=True) 0.43056511878967285\n",
      "tensor(-1.0197, requires_grad=True) tensor(0.4324, requires_grad=True) 0.4236612021923065\n",
      "tensor(-1.0424, requires_grad=True) tensor(0.4452, requires_grad=True) 0.41692596673965454\n",
      "tensor(-1.0648, requires_grad=True) tensor(0.4579, requires_grad=True) 0.41035541892051697\n",
      "tensor(-1.0869, requires_grad=True) tensor(0.4704, requires_grad=True) 0.40394553542137146\n",
      "tensor(-1.1087, requires_grad=True) tensor(0.4827, requires_grad=True) 0.3976922631263733\n",
      "tensor(-1.1303, requires_grad=True) tensor(0.4949, requires_grad=True) 0.3915919363498688\n",
      "tensor(-1.1516, requires_grad=True) tensor(0.5069, requires_grad=True) 0.3856407105922699\n",
      "tensor(-1.1726, requires_grad=True) tensor(0.5188, requires_grad=True) 0.37983500957489014\n",
      "tensor(-1.1934, requires_grad=True) tensor(0.5306, requires_grad=True) 0.3741712272167206\n",
      "tensor(-1.2140, requires_grad=True) tensor(0.5422, requires_grad=True) 0.3686458468437195\n",
      "tensor(-1.2342, requires_grad=True) tensor(0.5536, requires_grad=True) 0.36325564980506897\n",
      "tensor(-1.2543, requires_grad=True) tensor(0.5650, requires_grad=True) 0.35799717903137207\n",
      "tensor(-1.2740, requires_grad=True) tensor(0.5761, requires_grad=True) 0.3528672754764557\n",
      "tensor(-1.2936, requires_grad=True) tensor(0.5872, requires_grad=True) 0.34786269068717957\n",
      "tensor(-1.3129, requires_grad=True) tensor(0.5981, requires_grad=True) 0.3429805636405945\n",
      "tensor(-1.3319, requires_grad=True) tensor(0.6088, requires_grad=True) 0.33821773529052734\n",
      "tensor(-1.3507, requires_grad=True) tensor(0.6195, requires_grad=True) 0.3335714042186737\n",
      "tensor(-1.3693, requires_grad=True) tensor(0.6300, requires_grad=True) 0.3290385901927948\n",
      "tensor(-1.3877, requires_grad=True) tensor(0.6404, requires_grad=True) 0.32461661100387573\n",
      "tensor(-1.4058, requires_grad=True) tensor(0.6506, requires_grad=True) 0.32030269503593445\n",
      "tensor(-1.4238, requires_grad=True) tensor(0.6607, requires_grad=True) 0.316094309091568\n",
      "tensor(-1.4415, requires_grad=True) tensor(0.6707, requires_grad=True) 0.31198880076408386\n",
      "tensor(-1.4589, requires_grad=True) tensor(0.6806, requires_grad=True) 0.3079835772514343\n",
      "tensor(-1.4762, requires_grad=True) tensor(0.6904, requires_grad=True) 0.30407634377479553\n",
      "tensor(-1.4932, requires_grad=True) tensor(0.7000, requires_grad=True) 0.3002645969390869\n",
      "tensor(-1.5101, requires_grad=True) tensor(0.7095, requires_grad=True) 0.296546071767807\n",
      "tensor(-1.5267, requires_grad=True) tensor(0.7189, requires_grad=True) 0.2929183840751648\n",
      "tensor(-1.5431, requires_grad=True) tensor(0.7282, requires_grad=True) 0.2893794775009155\n",
      "tensor(-1.5594, requires_grad=True) tensor(0.7374, requires_grad=True) 0.2859269976615906\n",
      "tensor(-1.5754, requires_grad=True) tensor(0.7464, requires_grad=True) 0.28255900740623474\n",
      "tensor(-1.5912, requires_grad=True) tensor(0.7554, requires_grad=True) 0.27927327156066895\n",
      "tensor(-1.6069, requires_grad=True) tensor(0.7642, requires_grad=True) 0.2760678827762604\n",
      "tensor(-1.6223, requires_grad=True) tensor(0.7730, requires_grad=True) 0.27294087409973145\n",
      "tensor(-1.6376, requires_grad=True) tensor(0.7816, requires_grad=True) 0.26989033818244934\n",
      "tensor(-1.6526, requires_grad=True) tensor(0.7901, requires_grad=True) 0.2669143080711365\n",
      "tensor(-1.6675, requires_grad=True) tensor(0.7985, requires_grad=True) 0.26401111483573914\n",
      "tensor(-1.6822, requires_grad=True) tensor(0.8068, requires_grad=True) 0.26117879152297974\n",
      "tensor(-1.6967, requires_grad=True) tensor(0.8150, requires_grad=True) 0.25841575860977173\n",
      "tensor(-1.7110, requires_grad=True) tensor(0.8231, requires_grad=True) 0.2557202875614166\n",
      "tensor(-1.7252, requires_grad=True) tensor(0.8311, requires_grad=True) 0.2530907392501831\n",
      "tensor(-1.7392, requires_grad=True) tensor(0.8390, requires_grad=True) 0.25052544474601746\n",
      "tensor(-1.7530, requires_grad=True) tensor(0.8468, requires_grad=True) 0.24802283942699432\n",
      "tensor(-1.7667, requires_grad=True) tensor(0.8545, requires_grad=True) 0.24558143317699432\n",
      "tensor(-1.7801, requires_grad=True) tensor(0.8622, requires_grad=True) 0.24319975078105927\n",
      "tensor(-1.7934, requires_grad=True) tensor(0.8697, requires_grad=True) 0.24087625741958618\n",
      "tensor(-1.8066, requires_grad=True) tensor(0.8771, requires_grad=True) 0.23860956728458405\n",
      "tensor(-1.8196, requires_grad=True) tensor(0.8845, requires_grad=True) 0.23639827966690063\n",
      "tensor(-1.8324, requires_grad=True) tensor(0.8917, requires_grad=True) 0.2342410832643509\n",
      "tensor(-1.8451, requires_grad=True) tensor(0.8989, requires_grad=True) 0.2321365922689438\n",
      "tensor(-1.8576, requires_grad=True) tensor(0.9059, requires_grad=True) 0.23008358478546143\n",
      "tensor(-1.8699, requires_grad=True) tensor(0.9129, requires_grad=True) 0.22808068990707397\n",
      "tensor(-1.8821, requires_grad=True) tensor(0.9198, requires_grad=True) 0.22612686455249786\n",
      "tensor(-1.8942, requires_grad=True) tensor(0.9266, requires_grad=True) 0.22422073781490326\n",
      "tensor(-1.9061, requires_grad=True) tensor(0.9334, requires_grad=True) 0.222361221909523\n",
      "tensor(-1.9179, requires_grad=True) tensor(0.9400, requires_grad=True) 0.2205471396446228\n",
      "tensor(-1.9295, requires_grad=True) tensor(0.9466, requires_grad=True) 0.21877743303775787\n",
      "tensor(-1.9410, requires_grad=True) tensor(0.9531, requires_grad=True) 0.21705102920532227\n",
      "tensor(-1.9523, requires_grad=True) tensor(0.9595, requires_grad=True) 0.21536678075790405\n",
      "tensor(-1.9635, requires_grad=True) tensor(0.9658, requires_grad=True) 0.21372371912002563\n",
      "tensor(-1.9745, requires_grad=True) tensor(0.9720, requires_grad=True) 0.21212080121040344\n",
      "tensor(-1.9855, requires_grad=True) tensor(0.9782, requires_grad=True) 0.21055710315704346\n",
      "tensor(-1.9963, requires_grad=True) tensor(0.9843, requires_grad=True) 0.2090316265821457\n",
      "tensor(-2.0069, requires_grad=True) tensor(0.9903, requires_grad=True) 0.20754341781139374\n",
      "tensor(-2.0174, requires_grad=True) tensor(0.9963, requires_grad=True) 0.20609161257743835\n",
      "tensor(-2.0278, requires_grad=True) tensor(1.0021, requires_grad=True) 0.20467528700828552\n",
      "tensor(-2.0381, requires_grad=True) tensor(1.0079, requires_grad=True) 0.2032935917377472\n",
      "tensor(-2.0482, requires_grad=True) tensor(1.0137, requires_grad=True) 0.20194566249847412\n",
      "tensor(-2.0582, requires_grad=True) tensor(1.0193, requires_grad=True) 0.20063072443008423\n",
      "tensor(-2.0681, requires_grad=True) tensor(1.0249, requires_grad=True) 0.19934788346290588\n",
      "tensor(-2.0779, requires_grad=True) tensor(1.0304, requires_grad=True) 0.19809642434120178\n",
      "tensor(-2.0875, requires_grad=True) tensor(1.0359, requires_grad=True) 0.19687557220458984\n",
      "tensor(-2.0971, requires_grad=True) tensor(1.0413, requires_grad=True) 0.195684552192688\n",
      "tensor(-2.1065, requires_grad=True) tensor(1.0466, requires_grad=True) 0.1945226788520813\n",
      "tensor(-2.1158, requires_grad=True) tensor(1.0519, requires_grad=True) 0.1933891922235489\n",
      "tensor(-2.1250, requires_grad=True) tensor(1.0571, requires_grad=True) 0.19228340685367584\n",
      "tensor(-2.1340, requires_grad=True) tensor(1.0622, requires_grad=True) 0.19120466709136963\n",
      "tensor(-2.1430, requires_grad=True) tensor(1.0672, requires_grad=True) 0.19015228748321533\n",
      "tensor(-2.1518, requires_grad=True) tensor(1.0722, requires_grad=True) 0.189125657081604\n",
      "tensor(-2.1606, requires_grad=True) tensor(1.0772, requires_grad=True) 0.18812409043312073\n",
      "tensor(-2.1692, requires_grad=True) tensor(1.0821, requires_grad=True) 0.18714702129364014\n",
      "tensor(-2.1777, requires_grad=True) tensor(1.0869, requires_grad=True) 0.18619385361671448\n",
      "tensor(-2.1862, requires_grad=True) tensor(1.0916, requires_grad=True) 0.1852639615535736\n",
      "tensor(-2.1945, requires_grad=True) tensor(1.0963, requires_grad=True) 0.18435680866241455\n",
      "tensor(-2.2027, requires_grad=True) tensor(1.1010, requires_grad=True) 0.18347182869911194\n",
      "tensor(-2.2108, requires_grad=True) tensor(1.1056, requires_grad=True) 0.18260851502418518\n",
      "tensor(-2.2188, requires_grad=True) tensor(1.1101, requires_grad=True) 0.18176628649234772\n",
      "tensor(-2.2267, requires_grad=True) tensor(1.1146, requires_grad=True) 0.18094465136528015\n",
      "tensor(-2.2346, requires_grad=True) tensor(1.1190, requires_grad=True) 0.1801430881023407\n",
      "tensor(-2.2423, requires_grad=True) tensor(1.1234, requires_grad=True) 0.17936114966869354\n",
      "tensor(-2.2499, requires_grad=True) tensor(1.1277, requires_grad=True) 0.1785982847213745\n",
      "tensor(-2.2574, requires_grad=True) tensor(1.1319, requires_grad=True) 0.17785412073135376\n",
      "tensor(-2.2649, requires_grad=True) tensor(1.1361, requires_grad=True) 0.17712810635566711\n",
      "tensor(-2.2722, requires_grad=True) tensor(1.1403, requires_grad=True) 0.17641986906528473\n",
      "tensor(-2.2795, requires_grad=True) tensor(1.1444, requires_grad=True) 0.1757289171218872\n",
      "tensor(-2.2867, requires_grad=True) tensor(1.1484, requires_grad=True) 0.1750548928976059\n",
      "tensor(-2.2937, requires_grad=True) tensor(1.1524, requires_grad=True) 0.1743973195552826\n",
      "tensor(-2.3007, requires_grad=True) tensor(1.1564, requires_grad=True) 0.17375582456588745\n",
      "tensor(-2.3076, requires_grad=True) tensor(1.1603, requires_grad=True) 0.17313002049922943\n",
      "tensor(-2.3145, requires_grad=True) tensor(1.1642, requires_grad=True) 0.1725195050239563\n",
      "tensor(-2.3212, requires_grad=True) tensor(1.1680, requires_grad=True) 0.1719239354133606\n",
      "tensor(-2.3279, requires_grad=True) tensor(1.1717, requires_grad=True) 0.1713429093360901\n",
      "tensor(-2.3344, requires_grad=True) tensor(1.1754, requires_grad=True) 0.1707760989665985\n",
      "tensor(-2.3409, requires_grad=True) tensor(1.1791, requires_grad=True) 0.17022311687469482\n",
      "tensor(-2.3473, requires_grad=True) tensor(1.1827, requires_grad=True) 0.16968367993831635\n",
      "tensor(-2.3537, requires_grad=True) tensor(1.1863, requires_grad=True) 0.16915743052959442\n",
      "tensor(-2.3599, requires_grad=True) tensor(1.1899, requires_grad=True) 0.1686440259218216\n",
      "tensor(-2.3661, requires_grad=True) tensor(1.1933, requires_grad=True) 0.16814321279525757\n",
      "tensor(-2.3722, requires_grad=True) tensor(1.1968, requires_grad=True) 0.1676546037197113\n",
      "tensor(-2.3783, requires_grad=True) tensor(1.2002, requires_grad=True) 0.1671779453754425\n",
      "tensor(-2.3842, requires_grad=True) tensor(1.2036, requires_grad=True) 0.1667129099369049\n",
      "tensor(-2.3901, requires_grad=True) tensor(1.2069, requires_grad=True) 0.166259303689003\n",
      "tensor(-2.3959, requires_grad=True) tensor(1.2102, requires_grad=True) 0.1658167690038681\n",
      "tensor(-2.4016, requires_grad=True) tensor(1.2134, requires_grad=True) 0.16538503766059875\n",
      "tensor(-2.4073, requires_grad=True) tensor(1.2166, requires_grad=True) 0.16496387124061584\n",
      "tensor(-2.4129, requires_grad=True) tensor(1.2198, requires_grad=True) 0.16455301642417908\n",
      "tensor(-2.4184, requires_grad=True) tensor(1.2229, requires_grad=True) 0.16415220499038696\n",
      "tensor(-2.4239, requires_grad=True) tensor(1.2260, requires_grad=True) 0.1637611836194992\n",
      "tensor(-2.4293, requires_grad=True) tensor(1.2290, requires_grad=True) 0.16337968409061432\n",
      "tensor(-2.4346, requires_grad=True) tensor(1.2321, requires_grad=True) 0.16300754249095917\n",
      "tensor(-2.4399, requires_grad=True) tensor(1.2350, requires_grad=True) 0.16264452040195465\n",
      "tensor(-2.4451, requires_grad=True) tensor(1.2380, requires_grad=True) 0.16229034960269928\n",
      "tensor(-2.4502, requires_grad=True) tensor(1.2409, requires_grad=True) 0.16194482147693634\n",
      "tensor(-2.4553, requires_grad=True) tensor(1.2437, requires_grad=True) 0.1616077870130539\n",
      "tensor(-2.4603, requires_grad=True) tensor(1.2466, requires_grad=True) 0.16127891838550568\n",
      "tensor(-2.4652, requires_grad=True) tensor(1.2494, requires_grad=True) 0.1609581559896469\n",
      "tensor(-2.4701, requires_grad=True) tensor(1.2521, requires_grad=True) 0.16064520180225372\n",
      "tensor(-2.4749, requires_grad=True) tensor(1.2548, requires_grad=True) 0.16033990681171417\n",
      "tensor(-2.4797, requires_grad=True) tensor(1.2575, requires_grad=True) 0.16004207730293274\n",
      "tensor(-2.4844, requires_grad=True) tensor(1.2602, requires_grad=True) 0.1597515344619751\n",
      "tensor(-2.4891, requires_grad=True) tensor(1.2628, requires_grad=True) 0.15946808457374573\n",
      "tensor(-2.4937, requires_grad=True) tensor(1.2654, requires_grad=True) 0.1591915637254715\n",
      "tensor(-2.4982, requires_grad=True) tensor(1.2680, requires_grad=True) 0.15892179310321808\n",
      "tensor(-2.5027, requires_grad=True) tensor(1.2705, requires_grad=True) 0.15865863859653473\n",
      "tensor(-2.5071, requires_grad=True) tensor(1.2730, requires_grad=True) 0.15840190649032593\n",
      "tensor(-2.5115, requires_grad=True) tensor(1.2755, requires_grad=True) 0.15815143287181854\n",
      "tensor(-2.5158, requires_grad=True) tensor(1.2779, requires_grad=True) 0.15790711343288422\n",
      "tensor(-2.5200, requires_grad=True) tensor(1.2803, requires_grad=True) 0.15766876935958862\n",
      "tensor(-2.5243, requires_grad=True) tensor(1.2827, requires_grad=True) 0.15743623673915863\n",
      "tensor(-2.5284, requires_grad=True) tensor(1.2851, requires_grad=True) 0.1572093963623047\n",
      "tensor(-2.5325, requires_grad=True) tensor(1.2874, requires_grad=True) 0.15698808431625366\n",
      "tensor(-2.5366, requires_grad=True) tensor(1.2897, requires_grad=True) 0.1567722111940384\n",
      "tensor(-2.5406, requires_grad=True) tensor(1.2919, requires_grad=True) 0.15656158328056335\n",
      "tensor(-2.5445, requires_grad=True) tensor(1.2942, requires_grad=True) 0.1563561111688614\n",
      "tensor(-2.5485, requires_grad=True) tensor(1.2964, requires_grad=True) 0.15615567564964294\n",
      "tensor(-2.5523, requires_grad=True) tensor(1.2986, requires_grad=True) 0.15596014261245728\n",
      "tensor(-2.5561, requires_grad=True) tensor(1.3007, requires_grad=True) 0.15576940774917603\n",
      "tensor(-2.5599, requires_grad=True) tensor(1.3029, requires_grad=True) 0.15558329224586487\n",
      "tensor(-2.5636, requires_grad=True) tensor(1.3050, requires_grad=True) 0.15540175139904022\n",
      "tensor(-2.5673, requires_grad=True) tensor(1.3070, requires_grad=True) 0.15522462129592896\n",
      "tensor(-2.5709, requires_grad=True) tensor(1.3091, requires_grad=True) 0.15505185723304749\n",
      "tensor(-2.5745, requires_grad=True) tensor(1.3111, requires_grad=True) 0.15488331019878387\n",
      "tensor(-2.5780, requires_grad=True) tensor(1.3131, requires_grad=True) 0.15471886098384857\n",
      "tensor(-2.5815, requires_grad=True) tensor(1.3151, requires_grad=True) 0.154558464884758\n",
      "tensor(-2.5850, requires_grad=True) tensor(1.3170, requires_grad=True) 0.154401957988739\n",
      "tensor(-2.5884, requires_grad=True) tensor(1.3190, requires_grad=True) 0.15424929559230804\n",
      "tensor(-2.5918, requires_grad=True) tensor(1.3209, requires_grad=True) 0.15410035848617554\n",
      "tensor(-2.5951, requires_grad=True) tensor(1.3228, requires_grad=True) 0.15395505726337433\n",
      "tensor(-2.5984, requires_grad=True) tensor(1.3246, requires_grad=True) 0.15381330251693726\n",
      "tensor(-2.6016, requires_grad=True) tensor(1.3265, requires_grad=True) 0.15367503464221954\n",
      "tensor(-2.6049, requires_grad=True) tensor(1.3283, requires_grad=True) 0.15354014933109283\n",
      "tensor(-2.6080, requires_grad=True) tensor(1.3301, requires_grad=True) 0.15340854227542877\n",
      "tensor(-2.6112, requires_grad=True) tensor(1.3318, requires_grad=True) 0.15328018367290497\n",
      "tensor(-2.6142, requires_grad=True) tensor(1.3336, requires_grad=True) 0.15315492451190948\n",
      "tensor(-2.6173, requires_grad=True) tensor(1.3353, requires_grad=True) 0.15303274989128113\n",
      "tensor(-2.6203, requires_grad=True) tensor(1.3370, requires_grad=True) 0.15291352570056915\n",
      "tensor(-2.6233, requires_grad=True) tensor(1.3387, requires_grad=True) 0.15279726684093475\n",
      "tensor(-2.6262, requires_grad=True) tensor(1.3403, requires_grad=True) 0.152683824300766\n",
      "tensor(-2.6291, requires_grad=True) tensor(1.3420, requires_grad=True) 0.15257318317890167\n",
      "tensor(-2.6320, requires_grad=True) tensor(1.3436, requires_grad=True) 0.15246520936489105\n",
      "tensor(-2.6348, requires_grad=True) tensor(1.3452, requires_grad=True) 0.15235987305641174\n",
      "tensor(-2.6376, requires_grad=True) tensor(1.3468, requires_grad=True) 0.15225714445114136\n",
      "tensor(-2.6404, requires_grad=True) tensor(1.3484, requires_grad=True) 0.15215690433979034\n",
      "tensor(-2.6431, requires_grad=True) tensor(1.3499, requires_grad=True) 0.15205912292003632\n",
      "tensor(-2.6458, requires_grad=True) tensor(1.3514, requires_grad=True) 0.1519637256860733\n",
      "tensor(-2.6485, requires_grad=True) tensor(1.3529, requires_grad=True) 0.15187066793441772\n",
      "tensor(-2.6511, requires_grad=True) tensor(1.3544, requires_grad=True) 0.1517798751592636\n",
      "tensor(-2.6537, requires_grad=True) tensor(1.3559, requires_grad=True) 0.15169131755828857\n",
      "tensor(-2.6563, requires_grad=True) tensor(1.3573, requires_grad=True) 0.15160492062568665\n",
      "tensor(-2.6588, requires_grad=True) tensor(1.3588, requires_grad=True) 0.15152063965797424\n",
      "tensor(-2.6613, requires_grad=True) tensor(1.3602, requires_grad=True) 0.1514384150505066\n",
      "tensor(-2.6638, requires_grad=True) tensor(1.3616, requires_grad=True) 0.15135818719863892\n",
      "tensor(-2.6662, requires_grad=True) tensor(1.3630, requires_grad=True) 0.15127994120121002\n",
      "tensor(-2.6687, requires_grad=True) tensor(1.3643, requires_grad=True) 0.15120358765125275\n",
      "tensor(-2.6710, requires_grad=True) tensor(1.3657, requires_grad=True) 0.1511290967464447\n",
      "tensor(-2.6734, requires_grad=True) tensor(1.3670, requires_grad=True) 0.1510564535856247\n",
      "tensor(-2.6757, requires_grad=True) tensor(1.3683, requires_grad=True) 0.15098556876182556\n",
      "tensor(-2.6780, requires_grad=True) tensor(1.3696, requires_grad=True) 0.1509164273738861\n",
      "tensor(-2.6803, requires_grad=True) tensor(1.3709, requires_grad=True) 0.15084896981716156\n",
      "tensor(-2.6825, requires_grad=True) tensor(1.3722, requires_grad=True) 0.15078315138816833\n",
      "tensor(-2.6847, requires_grad=True) tensor(1.3734, requires_grad=True) 0.15071897208690643\n",
      "tensor(-2.6869, requires_grad=True) tensor(1.3747, requires_grad=True) 0.1506563425064087\n",
      "tensor(-2.6891, requires_grad=True) tensor(1.3759, requires_grad=True) 0.15059524774551392\n",
      "tensor(-2.6912, requires_grad=True) tensor(1.3771, requires_grad=True) 0.15053562819957733\n",
      "tensor(-2.6933, requires_grad=True) tensor(1.3783, requires_grad=True) 0.15047746896743774\n",
      "tensor(-2.6954, requires_grad=True) tensor(1.3794, requires_grad=True) 0.15042074024677277\n",
      "tensor(-2.6975, requires_grad=True) tensor(1.3806, requires_grad=True) 0.1503654271364212\n",
      "tensor(-2.6995, requires_grad=True) tensor(1.3817, requires_grad=True) 0.1503114253282547\n",
      "tensor(-2.7015, requires_grad=True) tensor(1.3829, requires_grad=True) 0.15025876462459564\n",
      "tensor(-2.7035, requires_grad=True) tensor(1.3840, requires_grad=True) 0.15020738542079926\n",
      "tensor(-2.7054, requires_grad=True) tensor(1.3851, requires_grad=True) 0.15015727281570435\n",
      "tensor(-2.7074, requires_grad=True) tensor(1.3862, requires_grad=True) 0.15010836720466614\n",
      "tensor(-2.7093, requires_grad=True) tensor(1.3873, requires_grad=True) 0.15006066858768463\n",
      "tensor(-2.7111, requires_grad=True) tensor(1.3883, requires_grad=True) 0.15001411736011505\n",
      "tensor(-2.7130, requires_grad=True) tensor(1.3894, requires_grad=True) 0.1499687284231186\n",
      "tensor(-2.7148, requires_grad=True) tensor(1.3904, requires_grad=True) 0.14992445707321167\n",
      "tensor(-2.7167, requires_grad=True) tensor(1.3915, requires_grad=True) 0.1498812586069107\n",
      "tensor(-2.7184, requires_grad=True) tensor(1.3925, requires_grad=True) 0.1498391032218933\n",
      "tensor(-2.7202, requires_grad=True) tensor(1.3935, requires_grad=True) 0.1497979760169983\n",
      "tensor(-2.7220, requires_grad=True) tensor(1.3945, requires_grad=True) 0.14975786209106445\n",
      "tensor(-2.7237, requires_grad=True) tensor(1.3954, requires_grad=True) 0.1497187316417694\n",
      "tensor(-2.7254, requires_grad=True) tensor(1.3964, requires_grad=True) 0.14968055486679077\n",
      "tensor(-2.7271, requires_grad=True) tensor(1.3974, requires_grad=True) 0.14964330196380615\n",
      "tensor(-2.7288, requires_grad=True) tensor(1.3983, requires_grad=True) 0.14960695803165436\n",
      "tensor(-2.7304, requires_grad=True) tensor(1.3992, requires_grad=True) 0.14957153797149658\n",
      "tensor(-2.7320, requires_grad=True) tensor(1.4001, requires_grad=True) 0.14953693747520447\n",
      "tensor(-2.7336, requires_grad=True) tensor(1.4010, requires_grad=True) 0.1495032161474228\n",
      "tensor(-2.7352, requires_grad=True) tensor(1.4019, requires_grad=True) 0.14947029948234558\n",
      "tensor(-2.7368, requires_grad=True) tensor(1.4028, requires_grad=True) 0.14943818747997284\n",
      "tensor(-2.7383, requires_grad=True) tensor(1.4037, requires_grad=True) 0.14940689504146576\n",
      "tensor(-2.7398, requires_grad=True) tensor(1.4046, requires_grad=True) 0.14937633275985718\n",
      "tensor(-2.7414, requires_grad=True) tensor(1.4054, requires_grad=True) 0.14934653043746948\n",
      "tensor(-2.7428, requires_grad=True) tensor(1.4063, requires_grad=True) 0.14931745827198029\n",
      "tensor(-2.7443, requires_grad=True) tensor(1.4071, requires_grad=True) 0.1492890864610672\n",
      "tensor(-2.7458, requires_grad=True) tensor(1.4079, requires_grad=True) 0.14926141500473022\n",
      "tensor(-2.7472, requires_grad=True) tensor(1.4087, requires_grad=True) 0.14923439919948578\n",
      "tensor(-2.7486, requires_grad=True) tensor(1.4095, requires_grad=True) 0.14920806884765625\n",
      "tensor(-2.7500, requires_grad=True) tensor(1.4103, requires_grad=True) 0.14918239414691925\n",
      "tensor(-2.7514, requires_grad=True) tensor(1.4111, requires_grad=True) 0.1491573303937912\n",
      "tensor(-2.7528, requires_grad=True) tensor(1.4119, requires_grad=True) 0.1491328626871109\n",
      "tensor(-2.7541, requires_grad=True) tensor(1.4126, requires_grad=True) 0.14910900592803955\n",
      "tensor(-2.7554, requires_grad=True) tensor(1.4134, requires_grad=True) 0.14908574521541595\n",
      "tensor(-2.7568, requires_grad=True) tensor(1.4141, requires_grad=True) 0.14906302094459534\n",
      "tensor(-2.7581, requires_grad=True) tensor(1.4149, requires_grad=True) 0.14904089272022247\n",
      "tensor(-2.7593, requires_grad=True) tensor(1.4156, requires_grad=True) 0.1490192711353302\n",
      "tensor(-2.7606, requires_grad=True) tensor(1.4163, requires_grad=True) 0.1489982008934021\n",
      "tensor(-2.7619, requires_grad=True) tensor(1.4170, requires_grad=True) 0.1489776223897934\n",
      "tensor(-2.7631, requires_grad=True) tensor(1.4177, requires_grad=True) 0.14895756542682648\n",
      "tensor(-2.7643, requires_grad=True) tensor(1.4184, requires_grad=True) 0.14893800020217896\n",
      "tensor(-2.7655, requires_grad=True) tensor(1.4191, requires_grad=True) 0.14891891181468964\n",
      "tensor(-2.7667, requires_grad=True) tensor(1.4198, requires_grad=True) 0.14890030026435852\n",
      "tensor(-2.7679, requires_grad=True) tensor(1.4204, requires_grad=True) 0.14888210594654083\n",
      "tensor(-2.7691, requires_grad=True) tensor(1.4211, requires_grad=True) 0.14886438846588135\n",
      "tensor(-2.7702, requires_grad=True) tensor(1.4217, requires_grad=True) 0.14884711802005768\n",
      "tensor(-2.7713, requires_grad=True) tensor(1.4224, requires_grad=True) 0.14883023500442505\n",
      "tensor(-2.7725, requires_grad=True) tensor(1.4230, requires_grad=True) 0.14881378412246704\n",
      "tensor(-2.7736, requires_grad=True) tensor(1.4236, requires_grad=True) 0.14879772067070007\n",
      "tensor(-2.7747, requires_grad=True) tensor(1.4242, requires_grad=True) 0.14878205955028534\n",
      "tensor(-2.7757, requires_grad=True) tensor(1.4248, requires_grad=True) 0.14876680076122284\n",
      "tensor(-2.7768, requires_grad=True) tensor(1.4255, requires_grad=True) 0.148751899600029\n",
      "tensor(-2.7779, requires_grad=True) tensor(1.4260, requires_grad=True) 0.1487373560667038\n",
      "tensor(-2.7789, requires_grad=True) tensor(1.4266, requires_grad=True) 0.14872317016124725\n",
      "tensor(-2.7799, requires_grad=True) tensor(1.4272, requires_grad=True) 0.14870931208133698\n",
      "tensor(-2.7809, requires_grad=True) tensor(1.4278, requires_grad=True) 0.14869581162929535\n",
      "tensor(-2.7819, requires_grad=True) tensor(1.4284, requires_grad=True) 0.1486826390028\n",
      "tensor(-2.7829, requires_grad=True) tensor(1.4289, requires_grad=True) 0.1486697942018509\n",
      "tensor(-2.7839, requires_grad=True) tensor(1.4295, requires_grad=True) 0.14865726232528687\n",
      "tensor(-2.7849, requires_grad=True) tensor(1.4300, requires_grad=True) 0.1486450433731079\n",
      "tensor(-2.7858, requires_grad=True) tensor(1.4306, requires_grad=True) 0.14863310754299164\n",
      "tensor(-2.7868, requires_grad=True) tensor(1.4311, requires_grad=True) 0.14862146973609924\n",
      "tensor(-2.7877, requires_grad=True) tensor(1.4316, requires_grad=True) 0.14861012995243073\n",
      "tensor(-2.7886, requires_grad=True) tensor(1.4321, requires_grad=True) 0.1485990583896637\n",
      "tensor(-2.7895, requires_grad=True) tensor(1.4326, requires_grad=True) 0.14858824014663696\n",
      "tensor(-2.7904, requires_grad=True) tensor(1.4331, requires_grad=True) 0.14857769012451172\n",
      "tensor(-2.7913, requires_grad=True) tensor(1.4337, requires_grad=True) 0.14856742322444916\n",
      "tensor(-2.7922, requires_grad=True) tensor(1.4341, requires_grad=True) 0.1485573947429657\n",
      "tensor(-2.7931, requires_grad=True) tensor(1.4346, requires_grad=True) 0.14854758977890015\n",
      "tensor(-2.7939, requires_grad=True) tensor(1.4351, requires_grad=True) 0.14853805303573608\n",
      "tensor(-2.7947, requires_grad=True) tensor(1.4356, requires_grad=True) 0.14852875471115112\n",
      "tensor(-2.7956, requires_grad=True) tensor(1.4361, requires_grad=True) 0.14851966500282288\n",
      "tensor(-2.7964, requires_grad=True) tensor(1.4365, requires_grad=True) 0.14851078391075134\n",
      "tensor(-2.7972, requires_grad=True) tensor(1.4370, requires_grad=True) 0.1485021412372589\n",
      "tensor(-2.7980, requires_grad=True) tensor(1.4374, requires_grad=True) 0.1484937071800232\n",
      "tensor(-2.7988, requires_grad=True) tensor(1.4379, requires_grad=True) 0.14848549664020538\n",
      "tensor(-2.7996, requires_grad=True) tensor(1.4383, requires_grad=True) 0.1484774649143219\n",
      "tensor(-2.8004, requires_grad=True) tensor(1.4388, requires_grad=True) 0.14846961200237274\n",
      "tensor(-2.8011, requires_grad=True) tensor(1.4392, requires_grad=True) 0.1484619677066803\n",
      "tensor(-2.8019, requires_grad=True) tensor(1.4396, requires_grad=True) 0.14845453202724457\n",
      "tensor(-2.8026, requires_grad=True) tensor(1.4400, requires_grad=True) 0.14844726026058197\n",
      "tensor(-2.8034, requires_grad=True) tensor(1.4405, requires_grad=True) 0.1484401673078537\n",
      "tensor(-2.8041, requires_grad=True) tensor(1.4409, requires_grad=True) 0.14843325316905975\n",
      "tensor(-2.8048, requires_grad=True) tensor(1.4413, requires_grad=True) 0.14842648804187775\n",
      "tensor(-2.8055, requires_grad=True) tensor(1.4417, requires_grad=True) 0.14841991662979126\n",
      "tensor(-2.8062, requires_grad=True) tensor(1.4421, requires_grad=True) 0.14841347932815552\n",
      "tensor(-2.8069, requires_grad=True) tensor(1.4425, requires_grad=True) 0.1484072059392929\n",
      "tensor(-2.8076, requires_grad=True) tensor(1.4428, requires_grad=True) 0.14840109646320343\n",
      "tensor(-2.8083, requires_grad=True) tensor(1.4432, requires_grad=True) 0.1483951359987259\n",
      "tensor(-2.8089, requires_grad=True) tensor(1.4436, requires_grad=True) 0.1483892947435379\n",
      "tensor(-2.8096, requires_grad=True) tensor(1.4440, requires_grad=True) 0.14838363230228424\n",
      "tensor(-2.8102, requires_grad=True) tensor(1.4443, requires_grad=True) 0.14837808907032013\n",
      "tensor(-2.8109, requires_grad=True) tensor(1.4447, requires_grad=True) 0.14837270975112915\n",
      "tensor(-2.8115, requires_grad=True) tensor(1.4451, requires_grad=True) 0.14836741983890533\n",
      "tensor(-2.8121, requires_grad=True) tensor(1.4454, requires_grad=True) 0.14836227893829346\n",
      "tensor(-2.8128, requires_grad=True) tensor(1.4458, requires_grad=True) 0.14835727214813232\n",
      "tensor(-2.8134, requires_grad=True) tensor(1.4461, requires_grad=True) 0.14835238456726074\n",
      "tensor(-2.8140, requires_grad=True) tensor(1.4465, requires_grad=True) 0.14834760129451752\n",
      "tensor(-2.8146, requires_grad=True) tensor(1.4468, requires_grad=True) 0.14834295213222504\n",
      "tensor(-2.8152, requires_grad=True) tensor(1.4471, requires_grad=True) 0.1483384072780609\n",
      "tensor(-2.8157, requires_grad=True) tensor(1.4475, requires_grad=True) 0.14833395183086395\n",
      "tensor(-2.8163, requires_grad=True) tensor(1.4478, requires_grad=True) 0.14832964539527893\n",
      "tensor(-2.8169, requires_grad=True) tensor(1.4481, requires_grad=True) 0.14832542836666107\n",
      "tensor(-2.8174, requires_grad=True) tensor(1.4484, requires_grad=True) 0.14832131564617157\n",
      "tensor(-2.8180, requires_grad=True) tensor(1.4487, requires_grad=True) 0.14831729233264923\n",
      "tensor(-2.8185, requires_grad=True) tensor(1.4490, requires_grad=True) 0.14831338822841644\n",
      "tensor(-2.8191, requires_grad=True) tensor(1.4493, requires_grad=True) 0.14830955862998962\n",
      "tensor(-2.8196, requires_grad=True) tensor(1.4496, requires_grad=True) 0.14830583333969116\n",
      "tensor(-2.8201, requires_grad=True) tensor(1.4499, requires_grad=True) 0.14830219745635986\n",
      "tensor(-2.8207, requires_grad=True) tensor(1.4502, requires_grad=True) 0.14829865097999573\n",
      "tensor(-2.8212, requires_grad=True) tensor(1.4505, requires_grad=True) 0.14829519391059875\n",
      "tensor(-2.8217, requires_grad=True) tensor(1.4508, requires_grad=True) 0.14829179644584656\n",
      "tensor(-2.8222, requires_grad=True) tensor(1.4511, requires_grad=True) 0.1482885330915451\n",
      "tensor(-2.8227, requires_grad=True) tensor(1.4514, requires_grad=True) 0.14828529953956604\n",
      "tensor(-2.8232, requires_grad=True) tensor(1.4517, requires_grad=True) 0.14828217029571533\n",
      "tensor(-2.8236, requires_grad=True) tensor(1.4519, requires_grad=True) 0.1482791155576706\n",
      "tensor(-2.8241, requires_grad=True) tensor(1.4522, requires_grad=True) 0.14827613532543182\n",
      "tensor(-2.8246, requires_grad=True) tensor(1.4525, requires_grad=True) 0.14827322959899902\n",
      "tensor(-2.8251, requires_grad=True) tensor(1.4527, requires_grad=True) 0.1482703685760498\n",
      "tensor(-2.8255, requires_grad=True) tensor(1.4530, requires_grad=True) 0.14826761186122894\n",
      "tensor(-2.8260, requires_grad=True) tensor(1.4532, requires_grad=True) 0.14826489984989166\n",
      "tensor(-2.8264, requires_grad=True) tensor(1.4535, requires_grad=True) 0.14826226234436035\n",
      "tensor(-2.8269, requires_grad=True) tensor(1.4537, requires_grad=True) 0.1482597142457962\n",
      "tensor(-2.8273, requires_grad=True) tensor(1.4540, requires_grad=True) 0.14825719594955444\n",
      "tensor(-2.8277, requires_grad=True) tensor(1.4542, requires_grad=True) 0.14825475215911865\n",
      "tensor(-2.8282, requires_grad=True) tensor(1.4545, requires_grad=True) 0.14825236797332764\n",
      "tensor(-2.8286, requires_grad=True) tensor(1.4547, requires_grad=True) 0.1482500284910202\n",
      "tensor(-2.8290, requires_grad=True) tensor(1.4549, requires_grad=True) 0.14824776351451874\n",
      "tensor(-2.8294, requires_grad=True) tensor(1.4552, requires_grad=True) 0.14824554324150085\n",
      "tensor(-2.8298, requires_grad=True) tensor(1.4554, requires_grad=True) 0.14824338257312775\n",
      "tensor(-2.8302, requires_grad=True) tensor(1.4556, requires_grad=True) 0.14824126660823822\n",
      "tensor(-2.8306, requires_grad=True) tensor(1.4559, requires_grad=True) 0.14823922514915466\n",
      "tensor(-2.8310, requires_grad=True) tensor(1.4561, requires_grad=True) 0.1482372134923935\n",
      "tensor(-2.8314, requires_grad=True) tensor(1.4563, requires_grad=True) 0.1482352465391159\n",
      "tensor(-2.8318, requires_grad=True) tensor(1.4565, requires_grad=True) 0.1482333391904831\n",
      "tensor(-2.8322, requires_grad=True) tensor(1.4567, requires_grad=True) 0.14823149144649506\n",
      "tensor(-2.8325, requires_grad=True) tensor(1.4569, requires_grad=True) 0.1482296586036682\n",
      "tensor(-2.8329, requires_grad=True) tensor(1.4571, requires_grad=True) 0.14822787046432495\n",
      "tensor(-2.8333, requires_grad=True) tensor(1.4574, requires_grad=True) 0.14822614192962646\n",
      "tensor(-2.8336, requires_grad=True) tensor(1.4576, requires_grad=True) 0.14822447299957275\n",
      "tensor(-2.8340, requires_grad=True) tensor(1.4578, requires_grad=True) 0.14822281897068024\n",
      "tensor(-2.8343, requires_grad=True) tensor(1.4580, requires_grad=True) 0.1482212096452713\n",
      "tensor(-2.8347, requires_grad=True) tensor(1.4581, requires_grad=True) 0.14821964502334595\n",
      "tensor(-2.8350, requires_grad=True) tensor(1.4583, requires_grad=True) 0.14821811020374298\n",
      "tensor(-2.8353, requires_grad=True) tensor(1.4585, requires_grad=True) 0.1482166200876236\n",
      "tensor(-2.8357, requires_grad=True) tensor(1.4587, requires_grad=True) 0.1482151597738266\n",
      "tensor(-2.8360, requires_grad=True) tensor(1.4589, requires_grad=True) 0.14821374416351318\n",
      "tensor(-2.8363, requires_grad=True) tensor(1.4591, requires_grad=True) 0.14821237325668335\n",
      "tensor(-2.8367, requires_grad=True) tensor(1.4593, requires_grad=True) 0.14821100234985352\n",
      "tensor(-2.8370, requires_grad=True) tensor(1.4595, requires_grad=True) 0.14820970594882965\n",
      "tensor(-2.8373, requires_grad=True) tensor(1.4596, requires_grad=True) 0.1482083946466446\n",
      "tensor(-2.8376, requires_grad=True) tensor(1.4598, requires_grad=True) 0.1482071727514267\n",
      "tensor(-2.8379, requires_grad=True) tensor(1.4600, requires_grad=True) 0.1482059359550476\n",
      "tensor(-2.8382, requires_grad=True) tensor(1.4601, requires_grad=True) 0.1482047438621521\n",
      "tensor(-2.8385, requires_grad=True) tensor(1.4603, requires_grad=True) 0.14820356667041779\n",
      "tensor(-2.8388, requires_grad=True) tensor(1.4605, requires_grad=True) 0.14820243418216705\n",
      "tensor(-2.8391, requires_grad=True) tensor(1.4606, requires_grad=True) 0.14820131659507751\n",
      "tensor(-2.8394, requires_grad=True) tensor(1.4608, requires_grad=True) 0.14820024371147156\n",
      "tensor(-2.8397, requires_grad=True) tensor(1.4610, requires_grad=True) 0.1481991857290268\n",
      "tensor(-2.8399, requires_grad=True) tensor(1.4611, requires_grad=True) 0.1481981724500656\n",
      "tensor(-2.8402, requires_grad=True) tensor(1.4613, requires_grad=True) 0.14819717407226562\n",
      "tensor(-2.8405, requires_grad=True) tensor(1.4614, requires_grad=True) 0.14819617569446564\n",
      "tensor(-2.8408, requires_grad=True) tensor(1.4616, requires_grad=True) 0.14819522202014923\n",
      "tensor(-2.8410, requires_grad=True) tensor(1.4617, requires_grad=True) 0.1481942981481552\n",
      "tensor(-2.8413, requires_grad=True) tensor(1.4619, requires_grad=True) 0.1481933891773224\n",
      "tensor(-2.8415, requires_grad=True) tensor(1.4620, requires_grad=True) 0.14819249510765076\n",
      "tensor(-2.8418, requires_grad=True) tensor(1.4622, requires_grad=True) 0.1481916308403015\n",
      "tensor(-2.8421, requires_grad=True) tensor(1.4623, requires_grad=True) 0.14819078147411346\n",
      "tensor(-2.8423, requires_grad=True) tensor(1.4625, requires_grad=True) 0.1481899619102478\n",
      "tensor(-2.8426, requires_grad=True) tensor(1.4626, requires_grad=True) 0.14818915724754333\n",
      "tensor(-2.8428, requires_grad=True) tensor(1.4627, requires_grad=True) 0.14818836748600006\n",
      "tensor(-2.8430, requires_grad=True) tensor(1.4629, requires_grad=True) 0.14818762242794037\n",
      "tensor(-2.8433, requires_grad=True) tensor(1.4630, requires_grad=True) 0.14818686246871948\n",
      "tensor(-2.8435, requires_grad=True) tensor(1.4631, requires_grad=True) 0.14818614721298218\n",
      "tensor(-2.8437, requires_grad=True) tensor(1.4633, requires_grad=True) 0.14818543195724487\n",
      "tensor(-2.8440, requires_grad=True) tensor(1.4634, requires_grad=True) 0.14818473160266876\n",
      "tensor(-2.8442, requires_grad=True) tensor(1.4635, requires_grad=True) 0.14818404614925385\n",
      "tensor(-2.8444, requires_grad=True) tensor(1.4637, requires_grad=True) 0.1481834053993225\n",
      "tensor(-2.8446, requires_grad=True) tensor(1.4638, requires_grad=True) 0.14818274974822998\n",
      "tensor(-2.8449, requires_grad=True) tensor(1.4639, requires_grad=True) 0.14818213880062103\n",
      "tensor(-2.8451, requires_grad=True) tensor(1.4640, requires_grad=True) 0.1481815129518509\n",
      "tensor(-2.8453, requires_grad=True) tensor(1.4642, requires_grad=True) 0.14818091690540314\n",
      "tensor(-2.8455, requires_grad=True) tensor(1.4643, requires_grad=True) 0.14818035066127777\n",
      "tensor(-2.8457, requires_grad=True) tensor(1.4644, requires_grad=True) 0.14817975461483002\n",
      "tensor(-2.8459, requires_grad=True) tensor(1.4645, requires_grad=True) 0.14817921817302704\n",
      "tensor(-2.8461, requires_grad=True) tensor(1.4646, requires_grad=True) 0.14817866683006287\n",
      "tensor(-2.8463, requires_grad=True) tensor(1.4647, requires_grad=True) 0.14817816019058228\n",
      "tensor(-2.8465, requires_grad=True) tensor(1.4648, requires_grad=True) 0.1481776386499405\n",
      "tensor(-2.8467, requires_grad=True) tensor(1.4650, requires_grad=True) 0.1481771320104599\n",
      "tensor(-2.8469, requires_grad=True) tensor(1.4651, requires_grad=True) 0.1481766551733017\n",
      "tensor(-2.8471, requires_grad=True) tensor(1.4652, requires_grad=True) 0.1481761634349823\n",
      "tensor(-2.8473, requires_grad=True) tensor(1.4653, requires_grad=True) 0.1481756865978241\n",
      "tensor(-2.8475, requires_grad=True) tensor(1.4654, requires_grad=True) 0.14817523956298828\n",
      "tensor(-2.8477, requires_grad=True) tensor(1.4655, requires_grad=True) 0.14817480742931366\n",
      "tensor(-2.8478, requires_grad=True) tensor(1.4656, requires_grad=True) 0.14817437529563904\n",
      "tensor(-2.8480, requires_grad=True) tensor(1.4657, requires_grad=True) 0.1481739580631256\n",
      "tensor(-2.8482, requires_grad=True) tensor(1.4658, requires_grad=True) 0.148173525929451\n",
      "tensor(-2.8484, requires_grad=True) tensor(1.4659, requires_grad=True) 0.14817313849925995\n",
      "tensor(-2.8485, requires_grad=True) tensor(1.4660, requires_grad=True) 0.14817273616790771\n",
      "tensor(-2.8487, requires_grad=True) tensor(1.4661, requires_grad=True) 0.14817234873771667\n",
      "tensor(-2.8489, requires_grad=True) tensor(1.4662, requires_grad=True) 0.14817199110984802\n",
      "tensor(-2.8491, requires_grad=True) tensor(1.4663, requires_grad=True) 0.14817161858081818\n",
      "tensor(-2.8492, requires_grad=True) tensor(1.4664, requires_grad=True) 0.14817126095294952\n",
      "tensor(-2.8494, requires_grad=True) tensor(1.4665, requires_grad=True) 0.14817093312740326\n",
      "tensor(-2.8495, requires_grad=True) tensor(1.4666, requires_grad=True) 0.1481705904006958\n",
      "tensor(-2.8497, requires_grad=True) tensor(1.4666, requires_grad=True) 0.14817026257514954\n",
      "tensor(-2.8499, requires_grad=True) tensor(1.4667, requires_grad=True) 0.14816993474960327\n",
      "tensor(-2.8500, requires_grad=True) tensor(1.4668, requires_grad=True) 0.148169606924057\n",
      "tensor(-2.8502, requires_grad=True) tensor(1.4669, requires_grad=True) 0.14816932380199432\n",
      "tensor(-2.8503, requires_grad=True) tensor(1.4670, requires_grad=True) 0.14816901087760925\n",
      "tensor(-2.8505, requires_grad=True) tensor(1.4671, requires_grad=True) 0.14816872775554657\n",
      "tensor(-2.8506, requires_grad=True) tensor(1.4672, requires_grad=True) 0.1481684446334839\n",
      "tensor(-2.8508, requires_grad=True) tensor(1.4672, requires_grad=True) 0.14816814661026\n",
      "tensor(-2.8509, requires_grad=True) tensor(1.4673, requires_grad=True) 0.14816789329051971\n",
      "tensor(-2.8510, requires_grad=True) tensor(1.4674, requires_grad=True) 0.14816762506961823\n",
      "tensor(-2.8512, requires_grad=True) tensor(1.4675, requires_grad=True) 0.14816737174987793\n",
      "tensor(-2.8513, requires_grad=True) tensor(1.4676, requires_grad=True) 0.14816713333129883\n",
      "tensor(-2.8515, requires_grad=True) tensor(1.4676, requires_grad=True) 0.14816688001155853\n",
      "tensor(-2.8516, requires_grad=True) tensor(1.4677, requires_grad=True) 0.14816661179065704\n",
      "tensor(-2.8517, requires_grad=True) tensor(1.4678, requires_grad=True) 0.14816640317440033\n",
      "tensor(-2.8519, requires_grad=True) tensor(1.4679, requires_grad=True) 0.14816616475582123\n",
      "tensor(-2.8520, requires_grad=True) tensor(1.4679, requires_grad=True) 0.14816595613956451\n",
      "tensor(-2.8521, requires_grad=True) tensor(1.4680, requires_grad=True) 0.1481657475233078\n",
      "tensor(-2.8522, requires_grad=True) tensor(1.4681, requires_grad=True) 0.1481655240058899\n",
      "tensor(-2.8524, requires_grad=True) tensor(1.4682, requires_grad=True) 0.14816531538963318\n",
      "tensor(-2.8525, requires_grad=True) tensor(1.4682, requires_grad=True) 0.14816510677337646\n",
      "tensor(-2.8526, requires_grad=True) tensor(1.4683, requires_grad=True) 0.14816492795944214\n",
      "tensor(-2.8527, requires_grad=True) tensor(1.4684, requires_grad=True) 0.14816473424434662\n",
      "tensor(-2.8529, requires_grad=True) tensor(1.4684, requires_grad=True) 0.1481645554304123\n",
      "tensor(-2.8530, requires_grad=True) tensor(1.4685, requires_grad=True) 0.14816436171531677\n",
      "tensor(-2.8531, requires_grad=True) tensor(1.4686, requires_grad=True) 0.14816418290138245\n",
      "tensor(-2.8532, requires_grad=True) tensor(1.4686, requires_grad=True) 0.14816401898860931\n",
      "tensor(-2.8533, requires_grad=True) tensor(1.4687, requires_grad=True) 0.148163840174675\n",
      "tensor(-2.8534, requires_grad=True) tensor(1.4688, requires_grad=True) 0.14816366136074066\n",
      "tensor(-2.8535, requires_grad=True) tensor(1.4688, requires_grad=True) 0.14816351234912872\n",
      "tensor(-2.8536, requires_grad=True) tensor(1.4689, requires_grad=True) 0.14816336333751678\n",
      "tensor(-2.8538, requires_grad=True) tensor(1.4689, requires_grad=True) 0.14816319942474365\n",
      "tensor(-2.8539, requires_grad=True) tensor(1.4690, requires_grad=True) 0.1481630504131317\n",
      "tensor(-2.8540, requires_grad=True) tensor(1.4691, requires_grad=True) 0.14816290140151978\n",
      "tensor(-2.8541, requires_grad=True) tensor(1.4691, requires_grad=True) 0.14816275238990784\n",
      "tensor(-2.8542, requires_grad=True) tensor(1.4692, requires_grad=True) 0.1481626182794571\n",
      "tensor(-2.8543, requires_grad=True) tensor(1.4692, requires_grad=True) 0.14816249907016754\n",
      "tensor(-2.8544, requires_grad=True) tensor(1.4693, requires_grad=True) 0.1481623649597168\n",
      "tensor(-2.8545, requires_grad=True) tensor(1.4693, requires_grad=True) 0.14816224575042725\n",
      "tensor(-2.8546, requires_grad=True) tensor(1.4694, requires_grad=True) 0.1481621116399765\n",
      "tensor(-2.8547, requires_grad=True) tensor(1.4695, requires_grad=True) 0.14816197752952576\n",
      "tensor(-2.8548, requires_grad=True) tensor(1.4695, requires_grad=True) 0.1481618732213974\n",
      "tensor(-2.8549, requires_grad=True) tensor(1.4696, requires_grad=True) 0.14816175401210785\n",
      "tensor(-2.8550, requires_grad=True) tensor(1.4696, requires_grad=True) 0.1481616348028183\n",
      "tensor(-2.8550, requires_grad=True) tensor(1.4697, requires_grad=True) 0.14816151559352875\n",
      "tensor(-2.8551, requires_grad=True) tensor(1.4697, requires_grad=True) 0.14816142618656158\n",
      "tensor(-2.8552, requires_grad=True) tensor(1.4698, requires_grad=True) 0.14816129207611084\n",
      "tensor(-2.8553, requires_grad=True) tensor(1.4698, requires_grad=True) 0.14816120266914368\n",
      "tensor(-2.8554, requires_grad=True) tensor(1.4699, requires_grad=True) 0.1481611132621765\n",
      "tensor(-2.8555, requires_grad=True) tensor(1.4699, requires_grad=True) 0.14816100895404816\n",
      "tensor(-2.8556, requires_grad=True) tensor(1.4700, requires_grad=True) 0.148160919547081\n",
      "tensor(-2.8557, requires_grad=True) tensor(1.4700, requires_grad=True) 0.14816081523895264\n",
      "tensor(-2.8557, requires_grad=True) tensor(1.4701, requires_grad=True) 0.14816071093082428\n",
      "tensor(-2.8558, requires_grad=True) tensor(1.4701, requires_grad=True) 0.1481606364250183\n",
      "tensor(-2.8559, requires_grad=True) tensor(1.4702, requires_grad=True) 0.14816053211688995\n",
      "tensor(-2.8560, requires_grad=True) tensor(1.4702, requires_grad=True) 0.14816047251224518\n",
      "tensor(-2.8561, requires_grad=True) tensor(1.4702, requires_grad=True) 0.14816038310527802\n",
      "tensor(-2.8561, requires_grad=True) tensor(1.4703, requires_grad=True) 0.14816030859947205\n",
      "tensor(-2.8562, requires_grad=True) tensor(1.4703, requires_grad=True) 0.14816023409366608\n",
      "tensor(-2.8563, requires_grad=True) tensor(1.4704, requires_grad=True) 0.1481601595878601\n",
      "tensor(-2.8564, requires_grad=True) tensor(1.4704, requires_grad=True) 0.14816007018089294\n",
      "tensor(-2.8564, requires_grad=True) tensor(1.4705, requires_grad=True) 0.14815999567508698\n",
      "tensor(-2.8565, requires_grad=True) tensor(1.4705, requires_grad=True) 0.1481599360704422\n",
      "tensor(-2.8566, requires_grad=True) tensor(1.4705, requires_grad=True) 0.14815986156463623\n",
      "tensor(-2.8567, requires_grad=True) tensor(1.4706, requires_grad=True) 0.14815978705883026\n",
      "tensor(-2.8567, requires_grad=True) tensor(1.4706, requires_grad=True) 0.14815972745418549\n",
      "tensor(-2.8568, requires_grad=True) tensor(1.4707, requires_grad=True) 0.14815965294837952\n",
      "tensor(-2.8569, requires_grad=True) tensor(1.4707, requires_grad=True) 0.14815959334373474\n",
      "tensor(-2.8569, requires_grad=True) tensor(1.4707, requires_grad=True) 0.14815954864025116\n",
      "tensor(-2.8570, requires_grad=True) tensor(1.4708, requires_grad=True) 0.1481594741344452\n",
      "tensor(-2.8571, requires_grad=True) tensor(1.4708, requires_grad=True) 0.14815941452980042\n",
      "tensor(-2.8571, requires_grad=True) tensor(1.4709, requires_grad=True) 0.14815935492515564\n",
      "tensor(-2.8572, requires_grad=True) tensor(1.4709, requires_grad=True) 0.14815931022167206\n",
      "tensor(-2.8573, requires_grad=True) tensor(1.4709, requires_grad=True) 0.14815925061702728\n",
      "tensor(-2.8573, requires_grad=True) tensor(1.4710, requires_grad=True) 0.1481592059135437\n",
      "tensor(-2.8574, requires_grad=True) tensor(1.4710, requires_grad=True) 0.14815914630889893\n",
      "tensor(-2.8575, requires_grad=True) tensor(1.4710, requires_grad=True) 0.14815910160541534\n",
      "tensor(-2.8575, requires_grad=True) tensor(1.4711, requires_grad=True) 0.14815905690193176\n",
      "tensor(-2.8576, requires_grad=True) tensor(1.4711, requires_grad=True) 0.14815901219844818\n",
      "tensor(-2.8576, requires_grad=True) tensor(1.4711, requires_grad=True) 0.1481589525938034\n",
      "tensor(-2.8577, requires_grad=True) tensor(1.4712, requires_grad=True) 0.14815890789031982\n",
      "tensor(-2.8578, requires_grad=True) tensor(1.4712, requires_grad=True) 0.14815887808799744\n",
      "tensor(-2.8578, requires_grad=True) tensor(1.4712, requires_grad=True) 0.14815883338451385\n",
      "tensor(-2.8579, requires_grad=True) tensor(1.4713, requires_grad=True) 0.14815877377986908\n",
      "tensor(-2.8579, requires_grad=True) tensor(1.4713, requires_grad=True) 0.1481587439775467\n",
      "tensor(-2.8580, requires_grad=True) tensor(1.4713, requires_grad=True) 0.1481586992740631\n",
      "tensor(-2.8580, requires_grad=True) tensor(1.4714, requires_grad=True) 0.14815865457057953\n",
      "tensor(-2.8581, requires_grad=True) tensor(1.4714, requires_grad=True) 0.14815862476825714\n",
      "tensor(-2.8581, requires_grad=True) tensor(1.4714, requires_grad=True) 0.14815859496593475\n",
      "tensor(-2.8582, requires_grad=True) tensor(1.4714, requires_grad=True) 0.14815855026245117\n",
      "tensor(-2.8582, requires_grad=True) tensor(1.4715, requires_grad=True) 0.1481585055589676\n",
      "tensor(-2.8583, requires_grad=True) tensor(1.4715, requires_grad=True) 0.1481584906578064\n",
      "tensor(-2.8584, requires_grad=True) tensor(1.4715, requires_grad=True) 0.14815844595432281\n",
      "tensor(-2.8584, requires_grad=True) tensor(1.4716, requires_grad=True) 0.14815840125083923\n",
      "tensor(-2.8585, requires_grad=True) tensor(1.4716, requires_grad=True) 0.14815837144851685\n",
      "tensor(-2.8585, requires_grad=True) tensor(1.4716, requires_grad=True) 0.14815834164619446\n",
      "tensor(-2.8585, requires_grad=True) tensor(1.4716, requires_grad=True) 0.14815832674503326\n",
      "tensor(-2.8586, requires_grad=True) tensor(1.4717, requires_grad=True) 0.14815828204154968\n",
      "tensor(-2.8586, requires_grad=True) tensor(1.4717, requires_grad=True) 0.1481582671403885\n",
      "tensor(-2.8587, requires_grad=True) tensor(1.4717, requires_grad=True) 0.1481582224369049\n",
      "tensor(-2.8587, requires_grad=True) tensor(1.4718, requires_grad=True) 0.1481582075357437\n",
      "tensor(-2.8588, requires_grad=True) tensor(1.4718, requires_grad=True) 0.14815817773342133\n",
      "tensor(-2.8588, requires_grad=True) tensor(1.4718, requires_grad=True) 0.14815814793109894\n",
      "tensor(-2.8589, requires_grad=True) tensor(1.4718, requires_grad=True) 0.14815813302993774\n",
      "tensor(-2.8589, requires_grad=True) tensor(1.4719, requires_grad=True) 0.14815810322761536\n",
      "tensor(-2.8590, requires_grad=True) tensor(1.4719, requires_grad=True) 0.14815807342529297\n",
      "tensor(-2.8590, requires_grad=True) tensor(1.4719, requires_grad=True) 0.14815805852413177\n",
      "tensor(-2.8590, requires_grad=True) tensor(1.4719, requires_grad=True) 0.1481580138206482\n",
      "tensor(-2.8591, requires_grad=True) tensor(1.4720, requires_grad=True) 0.1481580138206482\n",
      "tensor(-2.8591, requires_grad=True) tensor(1.4720, requires_grad=True) 0.1481579691171646\n",
      "tensor(-2.8592, requires_grad=True) tensor(1.4720, requires_grad=True) 0.1481579691171646\n",
      "tensor(-2.8592, requires_grad=True) tensor(1.4720, requires_grad=True) 0.14815792441368103\n",
      "tensor(-2.8592, requires_grad=True) tensor(1.4720, requires_grad=True) 0.14815790951251984\n",
      "tensor(-2.8593, requires_grad=True) tensor(1.4721, requires_grad=True) 0.14815789461135864\n",
      "tensor(-2.8593, requires_grad=True) tensor(1.4721, requires_grad=True) 0.14815787971019745\n",
      "tensor(-2.8594, requires_grad=True) tensor(1.4721, requires_grad=True) 0.14815787971019745\n",
      "tensor(-2.8594, requires_grad=True) tensor(1.4721, requires_grad=True) 0.14815784990787506\n",
      "tensor(-2.8594, requires_grad=True) tensor(1.4721, requires_grad=True) 0.14815782010555267\n",
      "tensor(-2.8595, requires_grad=True) tensor(1.4722, requires_grad=True) 0.14815780520439148\n",
      "tensor(-2.8595, requires_grad=True) tensor(1.4722, requires_grad=True) 0.14815779030323029\n",
      "tensor(-2.8595, requires_grad=True) tensor(1.4722, requires_grad=True) 0.1481577754020691\n",
      "tensor(-2.8596, requires_grad=True) tensor(1.4722, requires_grad=True) 0.1481577455997467\n",
      "tensor(-2.8596, requires_grad=True) tensor(1.4723, requires_grad=True) 0.1481577306985855\n",
      "tensor(-2.8596, requires_grad=True) tensor(1.4723, requires_grad=True) 0.1481577306985855\n",
      "tensor(-2.8597, requires_grad=True) tensor(1.4723, requires_grad=True) 0.14815771579742432\n",
      "tensor(-2.8597, requires_grad=True) tensor(1.4723, requires_grad=True) 0.14815768599510193\n",
      "tensor(-2.8598, requires_grad=True) tensor(1.4723, requires_grad=True) 0.14815767109394073\n",
      "tensor(-2.8598, requires_grad=True) tensor(1.4723, requires_grad=True) 0.14815767109394073\n",
      "tensor(-2.8598, requires_grad=True) tensor(1.4724, requires_grad=True) 0.14815765619277954\n",
      "tensor(-2.8598, requires_grad=True) tensor(1.4724, requires_grad=True) 0.14815762639045715\n",
      "tensor(-2.8599, requires_grad=True) tensor(1.4724, requires_grad=True) 0.14815761148929596\n",
      "tensor(-2.8599, requires_grad=True) tensor(1.4724, requires_grad=True) 0.14815761148929596\n",
      "tensor(-2.8599, requires_grad=True) tensor(1.4724, requires_grad=True) 0.14815759658813477\n",
      "tensor(-2.8600, requires_grad=True) tensor(1.4725, requires_grad=True) 0.14815758168697357\n",
      "tensor(-2.8600, requires_grad=True) tensor(1.4725, requires_grad=True) 0.14815755188465118\n",
      "tensor(-2.8600, requires_grad=True) tensor(1.4725, requires_grad=True) 0.14815755188465118\n",
      "tensor(-2.8601, requires_grad=True) tensor(1.4725, requires_grad=True) 0.14815755188465118\n",
      "tensor(-2.8601, requires_grad=True) tensor(1.4725, requires_grad=True) 0.14815753698349\n",
      "tensor(-2.8601, requires_grad=True) tensor(1.4725, requires_grad=True) 0.1481575071811676\n",
      "tensor(-2.8601, requires_grad=True) tensor(1.4726, requires_grad=True) 0.1481575071811676\n",
      "tensor(-2.8602, requires_grad=True) tensor(1.4726, requires_grad=True) 0.1481575220823288\n",
      "tensor(-2.8602, requires_grad=True) tensor(1.4726, requires_grad=True) 0.14815747737884521\n",
      "tensor(-2.8602, requires_grad=True) tensor(1.4726, requires_grad=True) 0.1481575071811676\n",
      "tensor(-2.8603, requires_grad=True) tensor(1.4726, requires_grad=True) 0.14815747737884521\n",
      "tensor(-2.8603, requires_grad=True) tensor(1.4726, requires_grad=True) 0.14815747737884521\n",
      "tensor(-2.8603, requires_grad=True) tensor(1.4726, requires_grad=True) 0.14815746247768402\n",
      "tensor(-2.8603, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815744757652283\n",
      "tensor(-2.8604, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815744757652283\n",
      "tensor(-2.8604, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815743267536163\n",
      "tensor(-2.8604, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815741777420044\n",
      "tensor(-2.8604, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815741777420044\n",
      "tensor(-2.8605, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815740287303925\n",
      "tensor(-2.8605, requires_grad=True) tensor(1.4727, requires_grad=True) 0.14815738797187805\n",
      "tensor(-2.8605, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815740287303925\n",
      "tensor(-2.8605, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815738797187805\n",
      "tensor(-2.8606, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815738797187805\n",
      "tensor(-2.8606, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815740287303925\n",
      "tensor(-2.8606, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815735816955566\n",
      "tensor(-2.8606, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815734326839447\n",
      "tensor(-2.8606, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815735816955566\n",
      "tensor(-2.8607, requires_grad=True) tensor(1.4728, requires_grad=True) 0.14815734326839447\n",
      "tensor(-2.8607, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815734326839447\n",
      "tensor(-2.8607, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815734326839447\n",
      "tensor(-2.8607, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8608, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8608, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8608, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8608, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8608, requires_grad=True) tensor(1.4729, requires_grad=True) 0.14815731346607208\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572985649109\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572985649109\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572985649109\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572985649109\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572687625885\n",
      "tensor(-2.8609, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572687625885\n",
      "tensor(-2.8610, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572687625885\n",
      "tensor(-2.8610, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572687625885\n",
      "tensor(-2.8610, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572538614273\n",
      "tensor(-2.8610, requires_grad=True) tensor(1.4730, requires_grad=True) 0.1481572538614273\n",
      "tensor(-2.8610, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572538614273\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8611, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4731, requires_grad=True) 0.14815722405910492\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4731, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4731, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4731, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4732, requires_grad=True) 0.1481572389602661\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8612, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815720915794373\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8613, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4732, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815719425678253\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8614, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815717935562134\n",
      "tensor(-2.8615, requires_grad=True) tensor(1.4733, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815714955329895\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815714955329895\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8616, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815714955329895\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815716445446014\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815714955329895\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4734, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8617, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4735, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8619, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815713465213776\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8620, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4736, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8621, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815711975097656\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8622, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4737, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8623, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815707504749298\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815710484981537\n",
      "tensor(-2.8624, requires_grad=True) tensor(1.4738, requires_grad=True) 0.14815708994865417\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.125, requires_grad=True)\n",
    "b = torch.tensor(-0.125, requires_grad=True)\n",
    "\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 1000\n",
    "\n",
    "for i in range(n_iter):\n",
    "    err = mse(X, y, w, b)\n",
    "    print(w, b, err.item())\n",
    "    err.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= stepsize * w.grad\n",
    "        b -= stepsize * b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

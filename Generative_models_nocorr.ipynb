{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "47c1de20dc4b4d3dacfb938ee7edb4bb",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "# Auto-encoders and Generative models in `keras`\n",
    "\n",
    "In this session, you will experiment with auto-encoders and then a family of generative models called \n",
    "Generative Adversarial Models (GANs).\n",
    "\n",
    "## Auto-encoders\n",
    "\n",
    "**Question 1.** Implement a shallow auto-encoder (with a single layer from the input to the hidden \n",
    "representation in dimension 16, and a single layer from this hidden representation to the output) and \n",
    "fit it to MNIST training set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "10fe62a3ab264e5493212ecad1434cf5",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.199996948242188
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9416,
    "execution_start": 1641291535026,
    "output_cleared": false,
    "source_hash": "ada34ee5",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "# Represent images as long vectors of pixels in [0, 1]\n",
    "X_train = X_train.reshape((X_train.shape[0], -1)) / 255.\n",
    "X_train = X_train[::2]  # Keep half of the dataset\n",
    "X_test = X_test.reshape((X_test.shape[0], -1)) / 255.\n",
    "X_test = X_test[::2]  # Keep half of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "173aad85cedd4e3f8d88c6b9fbaf56c1",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 2.** Use the code below to visualize the quality of reconstruction on some test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "23bd9e3777c04accad2c550bea0f0153",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     201
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2578,
    "execution_start": 1641291572434,
    "output_cleared": false,
    "source_hash": "33718ea",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_reconstruction(img, reconstruction):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img.reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.title(\"Original image\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(reconstruction.reshape((28, 28)), cmap=\"gray\")\n",
    "    plt.title(\"Reconstructed image\")\n",
    "\n",
    "preds = model(X_test).numpy()\n",
    "plot_reconstruction(X_test[0], preds[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "434f3d592ba340979b3abf08597eb0b6",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 3.** Check if adding more layers (in both the encoder and decoder, trying to keep a mirror \n",
    "structure) helps better reconstructing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "c534c71e7f794dd1a10a9e2812d9db57",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.199996948242188
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 29726,
    "execution_start": 1641291747129,
    "source_hash": "ebc69242",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "3d12e4ff93254284a425a405eb60de4b",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     201
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 418,
    "execution_start": 1641291784716,
    "source_hash": "e284ed8d",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "86847fe07bae432eb016d965b724f10f",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "outputs": "",
   "source": [
    "Auto-encoders are known to be good image denoisers, if trained using noisy images as inputs and clean ones as outputs.\n",
    "\n",
    "**Question 4.** Using the below-defined noisy copies of `X_train` and `X_test`, check the denoising \n",
    "capabilities of a network with the same structure as in the previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "fa1d638a4efc491885d98a3289ed0297",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     21.199996948242188
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 41418,
    "execution_start": 1641291923042,
    "output_cleared": false,
    "source_hash": "f2ed4214",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_noisy = X_train + .1 * np.random.randn(*X_train.shape)\n",
    "X_test_noisy = X_test + .1 * np.random.randn(*X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "f306f34398734e7faa83a4377d9661d6",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     201
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 481,
    "execution_start": 1641291964503,
    "source_hash": "f54894c2",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1692c2ea86b44d6d987ba5251b805d45",
    "deepnote_cell_type": "markdown",
    "id": "eTlBng83h1jC",
    "tags": []
   },
   "outputs": "",
   "source": [
    "## Generative Adversarial Networks (GAN)\n",
    "\n",
    "In this section, you will be invited to play with two types of GAN models to generate MNIST-like data.\n",
    "\n",
    "First, you will find below an almost complete implementation of the original GAN model (widely inspired from <https://github.com/eriklindernoren/Keras-GAN>).\n",
    "\n",
    "**Question 5.** Fill in the blanks (TODO marks in the `train` method) to complete the code and train a model on MNIST for 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "82e9941b47764fd3848e82005ff5b1be",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 161640,
    "execution_start": 1641293221181,
    "id": "VCnwH1NdhuSV",
    "outputId": "7fdd5a3b-5546-41d0-96f8-969de571624f",
    "output_cleared": false,
    "source_hash": "da81c645",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, ZeroPadding2D, LeakyReLU\n",
    "from keras.layers import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.randn(batch_size, self.latent_dim)\n",
    "            \n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, None)  # TODO: change None to a reasonable value\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, None)  # TODO: change None to a reasonable value\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.randn(batch_size, None)  # TODO: change None to a reasonable value\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, None)  # TODO: change None to a reasonable value\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "gan = GAN()\n",
    "gan.train(epochs=10 * 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "8a99b5925edb488ba5f7f8d361834392",
    "deepnote_cell_type": "markdown",
    "id": "DNbMIJvZkfnE",
    "tags": []
   },
   "outputs": "",
   "source": [
    "Now that your model is trained, generate a few images and visualize them with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "b35a1036c0de46458a311a5eb1a433b6",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250,
     250,
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 753,
    "execution_start": 1641293400091,
    "id": "VpCllV8ck07j",
    "outputId": "60ca25fc-5676-4211-ae50-7d27b28b8d7f",
    "output_cleared": false,
    "source_hash": "db7e8ab7",
    "tags": []
   },
   "outputs": "",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_images = 3\n",
    "z = np.random.randn(n_images, None)  # TODO: change None to a reasonable value\n",
    "gen_imgs = gan.generator.predict(z)\n",
    "\n",
    "# Rescale images 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "for i in range(n_images):\n",
    "  plt.imshow(gen_imgs[i, :, :, 0], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "e3b1b048086440418a64b5b1e239897e",
    "deepnote_cell_type": "markdown",
    "id": "J3QMxvO6m37Q",
    "tags": []
   },
   "outputs": "",
   "source": [
    "Code for a Conditional GAN is quite similar (_cf._ below, once again widely inspired from the same GitHub repository).\n",
    "\n",
    "**Question 6.** What is the input fed to the generator to generate a fake sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "4862dab0459244aab3d1e54c21748091",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 246854,
    "execution_start": 1641293561467,
    "id": "mRElk8HAnC6o",
    "outputId": "9ac309b0-9a6a-46c2-a645-359499e2355b",
    "output_cleared": false,
    "source_hash": "fc6f4938",
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "from keras.layers import Multiply, Embedding\n",
    "\n",
    "\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = Multiply()([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.4))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = Multiply()([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs, labels = X_train[idx], y_train[idx]\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Condition on labels\n",
    "            sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            \n",
    "cgan = CGAN()\n",
    "cgan.train(epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "abf1e40c866c4dfaa9dfe3e2c8efd21b",
    "deepnote_cell_type": "markdown",
    "id": "DJRrORUsoSaP",
    "tags": []
   },
   "outputs": "",
   "source": [
    "**Question 7.** Fit the model for 1000 epochs and, once fitted, generate a few fake \"8\" handwritten digits (take inspiration from the code above to show the generated images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "b0d894d14c574211af7f46a699c1291f",
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     250,
     250,
     250
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 969,
    "execution_start": 1641294086427,
    "source_hash": "d3c9a5f4",
    "tags": []
   },
   "outputs": "",
   "source": [
    "from keras.utils import to_categorical\n",
    "n_images = 3\n",
    "z = np.random.randn(n_images, None)  # TODO: change None to a reasonable value\n",
    "labels = np.array([8, 8, 8])\n",
    "gen_imgs = cgan.generator.predict([z, labels])\n",
    "\n",
    "# Rescale images 0 - 1\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "for i in range(n_images):\n",
    "  plt.imshow(gen_imgs[i, :, :, 0], cmap='gray')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "## Diffusion models\n",
    "\n",
    "For this section on Diffusion models, we will not try to implement diffusion models ourselves but rather rely on pre-trained models stored on HuggingFace.\n",
    "To do so, we will use the `diffusers` library provided by HuggingFace, which we first need to install:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "The following code allows to load a pre-trained model hosted at HuggingFace and use it to generate images.\n",
    "HuggingFace-hosted models can be found at: <https://huggingface.co/models>\n",
    "\n",
    "**Question 8.** Use two different models (trained on different training sets) and ask for the generation of 4 different images. Observe the impact of the training set on generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "from diffusers import DDPMPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_images(model_id, n_images, n_steps=1000):\n",
    "  # load model and scheduler\n",
    "  pipe = DDPMPipeline.from_pretrained(model_id)\n",
    "  # pipe.to(\"cuda\")\n",
    "\n",
    "  # run pipeline in inference (sample random noise and denoise)\n",
    "  return pipe(batch_size=n_images, num_inference_steps=n_steps).images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "outputs": "",
   "source": [
    "Stable Diffusion is a diffusion model that allows one to generate images from a text prompt. \n",
    "The idea behind Stable Diffusion is that the diffusion process at each step is conditioned by a high-dimensional representation of the text prompt, forcing the model to generate images that are related to the said prompt.\n",
    "\n",
    "**Question 9.** Use Stable Diffusion v1-5 available [there](https://huggingface.co/runwayml/stable-diffusion-v1-5) to generate an image from a text of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "keep_corr"
    ]
   },
   "outputs": "",
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "# pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of a computer science teacher surfing a gigantic wave\"\n",
    "image = pipe(prompt).images[0]\n",
    "image"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Generative models.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e6d1d921000d4075a1bb81def5fbf9ce",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

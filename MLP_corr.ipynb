{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00000-4e5bf590-09bc-42f5-a318-08994a30bfd4",
    "deepnote_cell_type": "markdown",
    "id": "NjCKi8REqlN6"
   },
   "source": [
    "# Multi-Layer Perceptron in `keras`\n",
    "\n",
    "In this series of lab sessions, you will use a Python library called `keras` (that is in fact embedded inside a larger library called `tensorflow`, but we will not discuss `tensorflow` in this course).\n",
    "You should visit [`keras` webpage](https://www.tensorflow.org/guide/keras/overview) to get access to more information about this library, including a comprehensive documentation.\n",
    "\n",
    "## The `Sequential` model in `keras`\n",
    "\n",
    "This library offers two ways to define neural network models. \n",
    "We will start with the `Sequential` class of `keras` models.\n",
    "Below is an example of how to define a `Sequential` model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00001-e7a9d101-f83a-49f2-ae43-deb55009fadf",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1216,
    "execution_start": 1613342071585,
    "id": "PRKkYealqiiG",
    "output_cleared": false,
    "source_hash": "b851176a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import keras_core as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-fddb7023-3fe5-422a-ab01-7974d23883a6",
    "deepnote_cell_type": "markdown",
    "id": "1UdkphfnspbR"
   },
   "source": [
    "**1. Define layers, and add them one by one to the model**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00003-3e192e55-740f-4e3e-9969-016701af86a1",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 57,
    "execution_start": 1613342072806,
    "id": "JD54PuqWsp4Y",
    "source_hash": "e4cce2c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:04:52.751766: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2023-07-18 15:04:52.751785: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-07-18 15:04:52.751789: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-07-18 15:04:52.751822: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-07-18 15:04:52.751837: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "input_layer = InputLayer(input_shape=(24,))\n",
    "hidden_layer1 = Dense(units=12, activation=\"relu\")\n",
    "hidden_layer2 = Dense(units=12, activation=\"sigmoid\")\n",
    "#[...]\n",
    "output_layer = Dense(units=3, activation=\"linear\")\n",
    "\n",
    "model = Sequential([\n",
    "    input_layer,\n",
    "    hidden_layer1,\n",
    "    hidden_layer2,\n",
    "    # ...\n",
    "    output_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-607dbfcd-c789-4071-98bf-f51e230e647f",
    "deepnote_cell_type": "markdown",
    "id": "FTQLjyUoszDq"
   },
   "source": [
    "**2. Pick an optimization algorithm (optimizer) and a loss function to be optimized**\n",
    "\n",
    "Usual loss functions are:\n",
    "* `\"mse\"` for regression,\n",
    "* `\"categorical_crossentropy\"` for multiclass classification (when the `y` array fed to `fit` is of shape $(n, n_\\text{classes})$)\n",
    "* `\"binary_crossentropy\"` for binary classification (when the model is fed with `y` array of shape $(n, 1)$)\n",
    "\n",
    "One can also specify additional metrics to be printed during training (correct classification rate here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00005-29ab32a8-52eb-40c1-9c63-1e8b8943cbdd",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 9,
    "execution_start": 1613342072870,
    "id": "A_21M9Jqs3eJ",
    "source_hash": "63a93405"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-1084a597-d5d5-4e2e-96ba-bf42d51d64c7",
    "deepnote_cell_type": "markdown",
    "id": "ykI4bexvs5x-"
   },
   "source": [
    "**3. Fit the model**\n",
    "\n",
    "NB: do not try to execute the following line of code: variables `X_train` and `y_train` do not exist yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00007-8516017c-c628-4ef3-ac0f-d80ca5f74a93",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1613342072879,
    "id": "rt89yAdWs688",
    "source_hash": "fd94a07d"
   },
   "outputs": [],
   "source": [
    "#model.fit(X_train, y_train, verbose=2, epochs=10, batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-79f8d9f3-2a42-42bb-8bcc-fc2f1f47eecd",
    "deepnote_cell_type": "markdown",
    "id": "nHhJosslvDRY"
   },
   "source": [
    "## Data pre-processing\n",
    "\n",
    "Have a look at the `prepare_mnist` and `prepare_boston` functions defined below.\n",
    "\n",
    "**Question #1.** What do these functions do? What are the shapes of returned arrays? Does the returned data correpond to classification or regression problems?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00009-c7c58fdf-b6f1-4f92-b82b-8ade1f4f44ca",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1636,
    "execution_start": 1613342072885,
    "id": "7l-s71YRwTRA",
    "output_cleared": false,
    "source_hash": "1615ed07"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.datasets import mnist, boston_housing\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def prepare_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "    x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(x_train)\n",
    "    x_train = scaler.transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def prepare_boston():\n",
    "    (x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
    "    scaler_x = MinMaxScaler()\n",
    "    scaler_x.fit(x_train)\n",
    "    x_train = scaler_x.transform(x_train)\n",
    "    x_test = scaler_x.transform(x_test)\n",
    "    scaler_y = MinMaxScaler()\n",
    "    scaler_y.fit(y_train.reshape((-1, 1)))\n",
    "    y_train = scaler_y.transform(y_train.reshape((-1, 1)))\n",
    "    y_test = scaler_y.transform(y_test.reshape((-1, 1)))\n",
    "    return x_train, x_test, y_train, y_test\n",
    "  \n",
    "x_train, x_test, y_train, y_test = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00010-3c1481af-a4d7-424b-a59e-3a2745234530",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 64,
    "execution_start": 1613342074525,
    "id": "CGlUHH6KFpj3",
    "output_cleared": false,
    "source_hash": "7facd6d8"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13) (404, 1)\n",
      "[[0.22666667]\n",
      " [0.82888889]\n",
      " [1.        ]\n",
      " [0.35777778]\n",
      " [0.28222222]\n",
      " [0.3       ]\n",
      " [0.14      ]\n",
      " [0.23555556]\n",
      " [0.23555556]\n",
      " [0.20888889]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00011-1ecdf9c5-01c3-4a0d-a9c6-cfd28e6be23d",
    "deepnote_cell_type": "markdown",
    "id": "VRA_Ec2-yIGA"
   },
   "source": [
    "## Building your first models\n",
    "\n",
    "In the following, when fitting models, restrict the training to 10 epochs (which is not realistic, but training for more epochs takes time...)\n",
    "\n",
    "**Question #2.** Following the guidelines provided above, implement a linear regression model for the `boston` dataset that would optimize on a least squares objective using Stochastic Gradient Descent and fit your model to the corresponding training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "00013-2e740cd6-9a8b-4a74-b85f-c7a66127d510",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1613342074582,
    "output_cleared": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 - 0s - loss: 0.1185 - 198ms/epoch - 40ms/step\n",
      "Epoch 2/10\n",
      "5/5 - 0s - loss: 0.0845 - 15ms/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "5/5 - 0s - loss: 0.0691 - 22ms/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "5/5 - 0s - loss: 0.0626 - 16ms/epoch - 3ms/step\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:04:53.581667: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: 0.0568 - 24ms/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "5/5 - 0s - loss: 0.0553 - 18ms/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "5/5 - 0s - loss: 0.0540 - 18ms/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "5/5 - 0s - loss: 0.0529 - 16ms/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "5/5 - 0s - loss: 0.0517 - 18ms/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "5/5 - 0s - loss: 0.0515 - 27ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dc439e40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_layer = InputLayer(input_shape=(13,))\n",
    "output_layer = Dense(units=1, activation=\"linear\")\n",
    "\n",
    "model = Sequential([\n",
    "    input_layer,\n",
    "    output_layer\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-c40decce-b6c2-4f3e-af55-6dc6b2eb29cd",
    "deepnote_cell_type": "markdown",
    "id": "Gqt1yH9Gzfuh"
   },
   "source": [
    "**Question #3.** Similarly, define a logistic regression model for the `mnist` dataset and print its training accuracy during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "00014-fa195760-a859-4672-bd64-7911ece3c703",
    "deepnote_cell_type": "code",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:04:54.439331: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.6327 - accuracy: 0.8415 - 4s/epoch - 6ms/step\n",
      "Epoch 2/10\n",
      "600/600 - 4s - loss: 0.3484 - accuracy: 0.9045 - 4s/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 4s - loss: 0.3107 - accuracy: 0.9143 - 4s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 4s - loss: 0.2932 - accuracy: 0.9182 - 4s/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 4s - loss: 0.2828 - accuracy: 0.9213 - 4s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 4s - loss: 0.2756 - accuracy: 0.9228 - 4s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 4s - loss: 0.2695 - accuracy: 0.9249 - 4s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 4s - loss: 0.2659 - accuracy: 0.9257 - 4s/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 4s - loss: 0.2621 - accuracy: 0.9273 - 4s/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 4s - loss: 0.2596 - accuracy: 0.9280 - 4s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ff8ec4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_train, x_test, y_train, y_test = prepare_mnist()\n",
    "\n",
    "input_layer = InputLayer(input_shape=x_train.shape[1:])\n",
    "output_layer = Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "\n",
    "model = Sequential([\n",
    "    input_layer,\n",
    "    output_layer\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00018-cfad4bc9-a1de-43a4-bb43-d74840d9869d",
    "deepnote_cell_type": "markdown",
    "id": "6SGA-CdS0vwW"
   },
   "source": [
    "**Question #4.** Compare performance (in terms of training accuracy, we will come back to better ways to compare models afterwards) of this logistic regression model with that of a neural network with respectively 1, 2, and 3 hidden layers of 128 neurons each.\n",
    "You will use the `\"relu\"` activation function for hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "00016-667b31d2-ee2e-4a34-9a88-33c19a38522a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:05:31.437644: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.3999 - accuracy: 0.8867 - 4s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "600/600 - 4s - loss: 0.2925 - accuracy: 0.9185 - 4s/epoch - 6ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 4s - loss: 0.2873 - accuracy: 0.9197 - 4s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 4s - loss: 0.2870 - accuracy: 0.9207 - 4s/epoch - 6ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 4s - loss: 0.2850 - accuracy: 0.9218 - 4s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 4s - loss: 0.2856 - accuracy: 0.9208 - 4s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 4s - loss: 0.2900 - accuracy: 0.9201 - 4s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 4s - loss: 0.2907 - accuracy: 0.9197 - 4s/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 4s - loss: 0.2949 - accuracy: 0.9194 - 4s/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 4s - loss: 0.2946 - accuracy: 0.9192 - 4s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x333105d50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:06:09.346241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.4101 - accuracy: 0.8843 - 4s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "600/600 - 4s - loss: 0.7182 - accuracy: 0.8594 - 4s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 4s - loss: 1.7705 - accuracy: 0.8257 - 4s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 4s - loss: 3.3533 - accuracy: 0.8096 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 4s - loss: 4.5909 - accuracy: 0.8097 - 4s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 4s - loss: 5.1832 - accuracy: 0.8193 - 4s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 4s - loss: 7.4762 - accuracy: 0.8089 - 4s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 4s - loss: 8.9257 - accuracy: 0.8101 - 4s/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 4s - loss: 10.8633 - accuracy: 0.8069 - 4s/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 4s - loss: 12.5151 - accuracy: 0.8060 - 4s/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x357360070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:06:47.956243: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 3.2867 - accuracy: 0.7675 - 4s/epoch - 7ms/step\n",
      "Epoch 2/10\n",
      "600/600 - 4s - loss: 61.4468 - accuracy: 0.5022 - 4s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 4s - loss: 240.2776 - accuracy: 0.4256 - 4s/epoch - 6ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 4s - loss: 470.2189 - accuracy: 0.4033 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 4s - loss: 861.1790 - accuracy: 0.3809 - 4s/epoch - 6ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 4s - loss: 1317.3137 - accuracy: 0.3826 - 4s/epoch - 6ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 4s - loss: 1902.0969 - accuracy: 0.3650 - 4s/epoch - 6ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 4s - loss: 2200.2087 - accuracy: 0.3810 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 4s - loss: 3314.5220 - accuracy: 0.3549 - 4s/epoch - 6ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 7s - loss: 3921.3835 - accuracy: 0.3596 - 7s/epoch - 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x37bea5ff0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134794 (526.54 KB)\n",
      "Trainable params: 134794 (526.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-a024cc10-c7b4-4021-89d9-0ed7447b2b9e",
    "deepnote_cell_type": "markdown",
    "id": "tC9EB0vs363m"
   },
   "source": [
    "**Question #5.** `keras` models offer a `count_params()` method to get the number of parameters to be learned in the model. Use this facility to get the number of parameters of your 3-hidden-layer model and build a new one-hidden-layer model with an equivalent number of parameters. Compare performance of these two models with similar number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "00018-d3f7b59d-095f-43d8-903e-2b92eb43619f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134365\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:07:32.972700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 20s - loss: 0.3844 - accuracy: 0.8917 - 20s/epoch - 33ms/step\n",
      "Epoch 2/10\n",
      "600/600 - 15s - loss: 0.2969 - accuracy: 0.9171 - 15s/epoch - 24ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 16s - loss: 0.2886 - accuracy: 0.9197 - 16s/epoch - 26ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 12s - loss: 0.2909 - accuracy: 0.9196 - 12s/epoch - 20ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 14s - loss: 0.2893 - accuracy: 0.9202 - 14s/epoch - 24ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 14s - loss: 0.2959 - accuracy: 0.9182 - 14s/epoch - 23ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 12s - loss: 0.2974 - accuracy: 0.9181 - 12s/epoch - 20ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 14s - loss: 0.2997 - accuracy: 0.9186 - 14s/epoch - 24ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 11s - loss: 0.3065 - accuracy: 0.9175 - 11s/epoch - 18ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 9s - loss: 0.3106 - accuracy: 0.9160 - 9s/epoch - 15ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2dde4cfd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = 134794 / 794\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=units, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "print(model.count_params())\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-1bdd65e7-515d-4064-882a-54c651abfd3d",
    "deepnote_cell_type": "markdown",
    "id": "iXxTGmUw5ppd"
   },
   "source": [
    "## A better way to compare models\n",
    "\n",
    "Comparing models based on training accuracy (resp. loss) is a \"great\" way to overfit your model to the training data.\n",
    "A better way to compare models is to use hold out data (aka validation set).\n",
    "\n",
    "To do so, `keras` allows to pass, at `fit` time, a fraction of the training data to be used as validation set. Have a look [there](https://www.tensorflow.org/guide/keras/train_and_evaluate#automatically_setting_apart_a_validation_holdout_set) for more details about how validation samples are selected.\n",
    "\n",
    "**Question #6.** Repeat model comparisons above (relying on validation scores) using 30% of training data as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:09:49.040656: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:09:53.885325: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 7s - loss: 0.5627 - accuracy: 0.8530 - val_loss: 1.1184 - val_accuracy: 0.8121 - 7s/epoch - 16ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 11s - loss: 12.4700 - accuracy: 0.6704 - val_loss: 26.5088 - val_accuracy: 0.6374 - 11s/epoch - 27ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 7s - loss: 61.6038 - accuracy: 0.5824 - val_loss: 63.4268 - val_accuracy: 0.6259 - 7s/epoch - 17ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 10s - loss: 147.6133 - accuracy: 0.5255 - val_loss: 279.4104 - val_accuracy: 0.5297 - 10s/epoch - 24ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 6s - loss: 301.8796 - accuracy: 0.4909 - val_loss: 478.7811 - val_accuracy: 0.4696 - 6s/epoch - 14ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 9s - loss: 470.1780 - accuracy: 0.4727 - val_loss: 469.8425 - val_accuracy: 0.4704 - 9s/epoch - 21ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 11s - loss: 775.1038 - accuracy: 0.4475 - val_loss: 611.5872 - val_accuracy: 0.5075 - 11s/epoch - 25ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 8s - loss: 1190.0272 - accuracy: 0.4348 - val_loss: 1314.6913 - val_accuracy: 0.4464 - 8s/epoch - 20ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 16s - loss: 1340.1887 - accuracy: 0.4382 - val_loss: 859.8641 - val_accuracy: 0.5125 - 16s/epoch - 39ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 10s - loss: 1661.8307 - accuracy: 0.4293 - val_loss: 2348.0039 - val_accuracy: 0.3435 - 10s/epoch - 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3c5059c90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134365\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:11:24.452838: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:11:28.802255: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 6s - loss: 0.4158 - accuracy: 0.8830 - val_loss: 0.3160 - val_accuracy: 0.9119 - 6s/epoch - 15ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 8s - loss: 0.2992 - accuracy: 0.9162 - val_loss: 0.2908 - val_accuracy: 0.9213 - 8s/epoch - 20ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 10s - loss: 0.2880 - accuracy: 0.9198 - val_loss: 0.2979 - val_accuracy: 0.9191 - 10s/epoch - 25ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 10s - loss: 0.2836 - accuracy: 0.9210 - val_loss: 0.3029 - val_accuracy: 0.9176 - 10s/epoch - 25ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 11s - loss: 0.2808 - accuracy: 0.9214 - val_loss: 0.3123 - val_accuracy: 0.9140 - 11s/epoch - 26ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 9s - loss: 0.2853 - accuracy: 0.9205 - val_loss: 0.3017 - val_accuracy: 0.9202 - 9s/epoch - 21ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 6s - loss: 0.2834 - accuracy: 0.9222 - val_loss: 0.3265 - val_accuracy: 0.9143 - 6s/epoch - 14ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 5s - loss: 0.2868 - accuracy: 0.9195 - val_loss: 0.3221 - val_accuracy: 0.9155 - 5s/epoch - 12ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 5s - loss: 0.2821 - accuracy: 0.9207 - val_loss: 0.3405 - val_accuracy: 0.9111 - 5s/epoch - 12ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 5s - loss: 0.2884 - accuracy: 0.9205 - val_loss: 0.3299 - val_accuracy: 0.9128 - 5s/epoch - 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3dcfc8c40>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "units = 134794 / 794\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=units, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "print(model.count_params())\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00026-77f877a8-a870-4358-a389-6435fd380c88",
    "deepnote_cell_type": "markdown",
    "id": "WehjG92yDMcN"
   },
   "source": [
    "## Optimizers and learning rate\n",
    "\n",
    "**Question #7.** Change the optimizer used for your model. Use an optimizer with momentum and adaptive learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_id": "00021-8889ee1e-48b4-4783-b8e9-fb42783d8d39",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:12:40.268811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:12:44.641712: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 7s - loss: 0.4388 - accuracy: 0.8739 - val_loss: 0.3295 - val_accuracy: 0.9077 - 7s/epoch - 17ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 10s - loss: 0.3978 - accuracy: 0.8942 - val_loss: 0.4355 - val_accuracy: 0.8909 - 10s/epoch - 23ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 6s - loss: 0.7901 - accuracy: 0.8525 - val_loss: 1.0985 - val_accuracy: 0.8367 - 6s/epoch - 15ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 6s - loss: 1.5256 - accuracy: 0.8287 - val_loss: 1.8342 - val_accuracy: 0.8346 - 6s/epoch - 14ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 6s - loss: 2.2124 - accuracy: 0.8213 - val_loss: 3.6359 - val_accuracy: 0.7562 - 6s/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 6s - loss: 3.1481 - accuracy: 0.8100 - val_loss: 3.4864 - val_accuracy: 0.8183 - 6s/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 6s - loss: 4.2253 - accuracy: 0.8088 - val_loss: 3.7300 - val_accuracy: 0.8356 - 6s/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 6s - loss: 5.0158 - accuracy: 0.8107 - val_loss: 5.1326 - val_accuracy: 0.8338 - 6s/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 6s - loss: 6.2721 - accuracy: 0.8027 - val_loss: 5.9839 - val_accuracy: 0.8046 - 6s/epoch - 15ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 5s - loss: 7.9474 - accuracy: 0.7979 - val_loss: 7.9078 - val_accuracy: 0.7982 - 5s/epoch - 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x4033dd060>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:13:43.722798: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:13:49.473591: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 9s - loss: 1.2914 - accuracy: 0.6394 - val_loss: 0.6839 - val_accuracy: 0.8322 - 9s/epoch - 22ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 10s - loss: 0.5714 - accuracy: 0.8498 - val_loss: 0.4660 - val_accuracy: 0.8715 - 10s/epoch - 23ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 5s - loss: 0.4440 - accuracy: 0.8775 - val_loss: 0.4023 - val_accuracy: 0.8866 - 5s/epoch - 12ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 5s - loss: 0.3947 - accuracy: 0.8892 - val_loss: 0.3701 - val_accuracy: 0.8932 - 5s/epoch - 12ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 5s - loss: 0.3685 - accuracy: 0.8967 - val_loss: 0.3524 - val_accuracy: 0.8992 - 5s/epoch - 12ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 5s - loss: 0.3519 - accuracy: 0.9004 - val_loss: 0.3415 - val_accuracy: 0.9012 - 5s/epoch - 12ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 6s - loss: 0.3400 - accuracy: 0.9039 - val_loss: 0.3324 - val_accuracy: 0.9044 - 6s/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 6s - loss: 0.3313 - accuracy: 0.9060 - val_loss: 0.3271 - val_accuracy: 0.9078 - 6s/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 7s - loss: 0.3240 - accuracy: 0.9086 - val_loss: 0.3229 - val_accuracy: 0.9097 - 7s/epoch - 17ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 5s - loss: 0.3185 - accuracy: 0.9096 - val_loss: 0.3184 - val_accuracy: 0.9091 - 5s/epoch - 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x3dcfc9a50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:14:47.751830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:14:52.637360: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 8s - loss: 0.4434 - accuracy: 0.8739 - val_loss: 0.3167 - val_accuracy: 0.9134 - 8s/epoch - 20ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 9s - loss: 0.3776 - accuracy: 0.8965 - val_loss: 0.4251 - val_accuracy: 0.8956 - 9s/epoch - 22ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 6s - loss: 0.6625 - accuracy: 0.8615 - val_loss: 0.7213 - val_accuracy: 0.8737 - 6s/epoch - 15ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 6s - loss: 1.1661 - accuracy: 0.8375 - val_loss: 1.2029 - val_accuracy: 0.8516 - 6s/epoch - 15ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 6s - loss: 1.7896 - accuracy: 0.8262 - val_loss: 1.8919 - val_accuracy: 0.8503 - 6s/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 6s - loss: 2.4814 - accuracy: 0.8244 - val_loss: 2.4888 - val_accuracy: 0.8252 - 6s/epoch - 14ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 7s - loss: 3.3880 - accuracy: 0.8137 - val_loss: 4.4639 - val_accuracy: 0.8011 - 7s/epoch - 17ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 5s - loss: 4.0428 - accuracy: 0.8138 - val_loss: 4.7581 - val_accuracy: 0.8102 - 5s/epoch - 13ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 6s - loss: 5.4440 - accuracy: 0.8037 - val_loss: 4.7501 - val_accuracy: 0.8306 - 6s/epoch - 13ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 9s - loss: 5.3883 - accuracy: 0.8175 - val_loss: 6.8572 - val_accuracy: 0.8062 - 9s/epoch - 22ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x333105ea0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-47912783-f891-416d-9e9d-05d57a819e7c",
    "deepnote_cell_type": "markdown",
    "id": "ot8jiQHuEZxr"
   },
   "source": [
    "**Question #8.** Using [the docs](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), vary the learning rate of your optimizer from a very low value to a much larger one so as to show evidence of:\n",
    "* instability when the learning rate is too large;\n",
    "* slow convergence when the learning rate is too low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "00029-16623cf9-4788-418c-8696-9e61bfe444fb",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 38776,
    "id": "pZfwWRDPEa1g",
    "output_cleared": true,
    "source_hash": "b623e53d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:15:56.609848: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:16:00.771811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 6s - loss: 0.9960 - accuracy: 0.7246 - val_loss: 0.4592 - val_accuracy: 0.8773 - 6s/epoch - 15ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 6s - loss: 0.3992 - accuracy: 0.8900 - val_loss: 0.3511 - val_accuracy: 0.9009 - 6s/epoch - 14ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 6s - loss: 0.3372 - accuracy: 0.9060 - val_loss: 0.3214 - val_accuracy: 0.9084 - 6s/epoch - 13ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 5s - loss: 0.3143 - accuracy: 0.9121 - val_loss: 0.3098 - val_accuracy: 0.9124 - 5s/epoch - 13ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 5s - loss: 0.3019 - accuracy: 0.9161 - val_loss: 0.3062 - val_accuracy: 0.9133 - 5s/epoch - 13ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 5s - loss: 0.2931 - accuracy: 0.9180 - val_loss: 0.3004 - val_accuracy: 0.9165 - 5s/epoch - 13ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 5s - loss: 0.2872 - accuracy: 0.9195 - val_loss: 0.2990 - val_accuracy: 0.9149 - 5s/epoch - 13ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 6s - loss: 0.2830 - accuracy: 0.9214 - val_loss: 0.2949 - val_accuracy: 0.9188 - 6s/epoch - 15ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 5s - loss: 0.2801 - accuracy: 0.9217 - val_loss: 0.2925 - val_accuracy: 0.9203 - 5s/epoch - 11ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 3s - loss: 0.2775 - accuracy: 0.9230 - val_loss: 0.2935 - val_accuracy: 0.9182 - 3s/epoch - 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x431e85e70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.0001), metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00030-f3edc3e5-83b2-4417-99c0-ce99030af441",
    "deepnote_cell_type": "markdown",
    "id": "tyCzy_PNEqwE"
   },
   "source": [
    "## Callbacks\n",
    "\n",
    "Callbacks are tools that, in `keras`, allow one to intervene during the training process of a model. \n",
    "Callbacks can be used to take actions (_ie._ save intermediate model, stop optimization if overfitting occurs, _etc._).\n",
    "\n",
    "A first callback one can play with is the one returned by any call to `fit` on a `keras` model.\n",
    "This callback is an object with an `.history` attribute in the form of a Python dictionnary whose keys are the metrics recorded during training. Each of these keys links to an array containing the consecutive values of the considered quantity (one value per epoch).\n",
    "\n",
    "**Question #9.** Plot correct classification rates on both training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "cell_id": "00031-a30d0556-649b-490f-8b57-f0ac45eb245a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "execution_millis": 67,
    "id": "qA-RPKzaI4-s",
    "output_cleared": true,
    "source_hash": "b623e53d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:16:49.818342: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:16:52.286589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "420/420 - 4s - loss: 0.4340 - accuracy: 0.8737 - val_loss: 0.3232 - val_accuracy: 0.9094 - 4s/epoch - 8ms/step\n",
      "Epoch 2/10\n",
      "420/420 - 3s - loss: 0.3951 - accuracy: 0.8928 - val_loss: 0.4569 - val_accuracy: 0.8856 - 3s/epoch - 8ms/step\n",
      "Epoch 3/10\n",
      "420/420 - 3s - loss: 0.7120 - accuracy: 0.8583 - val_loss: 1.1132 - val_accuracy: 0.8256 - 3s/epoch - 8ms/step\n",
      "Epoch 4/10\n",
      "420/420 - 3s - loss: 1.1761 - accuracy: 0.8379 - val_loss: 1.1128 - val_accuracy: 0.8519 - 3s/epoch - 8ms/step\n",
      "Epoch 5/10\n",
      "420/420 - 3s - loss: 1.8677 - accuracy: 0.8256 - val_loss: 2.0594 - val_accuracy: 0.8442 - 3s/epoch - 8ms/step\n",
      "Epoch 6/10\n",
      "420/420 - 3s - loss: 2.7890 - accuracy: 0.8168 - val_loss: 2.0981 - val_accuracy: 0.8516 - 3s/epoch - 8ms/step\n",
      "Epoch 7/10\n",
      "420/420 - 3s - loss: 3.2955 - accuracy: 0.8180 - val_loss: 3.7898 - val_accuracy: 0.7926 - 3s/epoch - 8ms/step\n",
      "Epoch 8/10\n",
      "420/420 - 3s - loss: 3.9532 - accuracy: 0.8190 - val_loss: 6.2408 - val_accuracy: 0.7931 - 3s/epoch - 8ms/step\n",
      "Epoch 9/10\n",
      "420/420 - 3s - loss: 4.5659 - accuracy: 0.8201 - val_loss: 4.7146 - val_accuracy: 0.8286 - 3s/epoch - 8ms/step\n",
      "Epoch 10/10\n",
      "420/420 - 3s - loss: 6.0788 - accuracy: 0.8042 - val_loss: 6.8826 - val_accuracy: 0.8098 - 3s/epoch - 8ms/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4340144097805023,\n",
       "  0.3950565457344055,\n",
       "  0.7119899392127991,\n",
       "  1.1760776042938232,\n",
       "  1.8676561117172241,\n",
       "  2.789045572280884,\n",
       "  3.295520544052124,\n",
       "  3.9532318115234375,\n",
       "  4.565883159637451,\n",
       "  6.078786373138428],\n",
       " 'accuracy': [0.8736904859542847,\n",
       "  0.8928095102310181,\n",
       "  0.8582857251167297,\n",
       "  0.8379047513008118,\n",
       "  0.8255714178085327,\n",
       "  0.8167856931686401,\n",
       "  0.8180238008499146,\n",
       "  0.8190000057220459,\n",
       "  0.8200713992118835,\n",
       "  0.8042142987251282],\n",
       " 'val_loss': [0.3232044279575348,\n",
       "  0.4568624794483185,\n",
       "  1.1131997108459473,\n",
       "  1.1127514839172363,\n",
       "  2.0594043731689453,\n",
       "  2.0980639457702637,\n",
       "  3.789783477783203,\n",
       "  6.2407684326171875,\n",
       "  4.714596271514893,\n",
       "  6.882626533508301],\n",
       " 'val_accuracy': [0.9094444513320923,\n",
       "  0.8855555653572083,\n",
       "  0.8255555629730225,\n",
       "  0.85188889503479,\n",
       "  0.8442222476005554,\n",
       "  0.8515555262565613,\n",
       "  0.7926111221313477,\n",
       "  0.793055534362793,\n",
       "  0.8286111354827881,\n",
       "  0.8097777962684631]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.plot(np.arange(1, 11), h.history[\"loss\"], label=\"Training loss\")\n",
    "plt.plot(np.arange(1, 11), h.history[\"val_loss\"], label=\"Validation loss\")\n",
    "plt.axvline(x=np.argmin(h.history[\"val_loss\"]) + 1, color='k', linestyle='--')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00032-0b2aa348-08ef-45f0-8984-70863c338c77",
    "deepnote_cell_type": "markdown",
    "id": "l9y1at8qI5cO"
   },
   "source": [
    "Setting up other callbacks must be explicit. This is done by passing a list of callbacks to the `fit` method.\n",
    "\n",
    "When training a model is long, one can wish to record intermediate models (in case of a crash during training, or just for cases when intermediate models were performing better than the final one).\n",
    "The [`ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) callback is designed for that purpose.\n",
    "\n",
    "**Question #10.** Set up recording of intermediate models every epoch. Save the models into a dedicated file `model.hdf5` on your Deepnote project. Only record models if validation loss is lower than for all previous models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "cell_id": "00027-fc377b2f-fe5b-4d0e-94b4-faa235dae4bc",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:17:23.273218: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:17:26.807537: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.4112 - accuracy: 0.8830 - val_loss: 0.3762 - val_accuracy: 0.8969 - 4s/epoch - 7ms/step\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rtavenar/py3.10_ml/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.7539 - accuracy: 0.8554 - val_loss: 1.1140 - val_accuracy: 0.8552 - 4s/epoch - 7ms/step\n",
      "Epoch 3/10\n",
      "600/600 - 4s - loss: 1.6811 - accuracy: 0.8291 - val_loss: 2.1969 - val_accuracy: 0.8292 - 4s/epoch - 7ms/step\n",
      "Epoch 4/10\n",
      "600/600 - 4s - loss: 2.8393 - accuracy: 0.8167 - val_loss: 5.3911 - val_accuracy: 0.7633 - 4s/epoch - 7ms/step\n",
      "Epoch 5/10\n",
      "600/600 - 4s - loss: 4.1086 - accuracy: 0.8154 - val_loss: 3.4884 - val_accuracy: 0.8280 - 4s/epoch - 7ms/step\n",
      "Epoch 6/10\n",
      "600/600 - 4s - loss: 5.5506 - accuracy: 0.8059 - val_loss: 9.3205 - val_accuracy: 0.7605 - 4s/epoch - 7ms/step\n",
      "Epoch 7/10\n",
      "600/600 - 4s - loss: 7.2047 - accuracy: 0.8056 - val_loss: 12.3705 - val_accuracy: 0.7766 - 4s/epoch - 7ms/step\n",
      "Epoch 8/10\n",
      "600/600 - 4s - loss: 8.4527 - accuracy: 0.8127 - val_loss: 10.1331 - val_accuracy: 0.8124 - 4s/epoch - 7ms/step\n",
      "Epoch 9/10\n",
      "600/600 - 4s - loss: 10.7294 - accuracy: 0.8031 - val_loss: 9.7861 - val_accuracy: 0.8164 - 4s/epoch - 7ms/step\n",
      "Epoch 10/10\n",
      "600/600 - 4s - loss: 11.9720 - accuracy: 0.8095 - val_loss: 14.9235 - val_accuracy: 0.8145 - 4s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "cb = ModelCheckpoint(\"model.hdf5\", save_best_only=True)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train, y_train, epochs=10, batch_size=100, verbose=2, validation_data=(x_test, y_test), callbacks=[cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00028-e61b8442-9511-4a89-a53c-9590238e0fd2",
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Use the code below to check that a model has been saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "cell_id": "00034-e0f2a0eb-f551-440e-94fb-2db94f18bde6",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "id": "m0Zqsvh8Bowh",
    "source_hash": "3b41946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--@ 1 rtavenar  staff   1.4M Jul 18 15:17 model.hdf5\n"
     ]
    }
   ],
   "source": [
    "!ls -alh \"model.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/313 [..............................] - ETA: 2s - loss: 11.3925 - accuracy: 0.8507 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:18:03.199180: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 14.9235 - accuracy: 0.8145\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[14.923468589782715, 0.8144999742507935]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.3762 - accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3762185871601105, 0.8968999981880188]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"model.hdf5\")\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00035-1206a01d-7467-4a3e-bbdc-ee72b70366a2",
    "deepnote_cell_type": "markdown",
    "id": "WFehub4rLrZm"
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00041-10a0c691-e01a-451e-807b-594ba76cc1fa",
    "deepnote_cell_type": "markdown",
    "id": "xbOmJKruNYyS"
   },
   "source": [
    "**Question #11.** Set up an [`EarlyStopping`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping) strategy such that training the model will stop in case the validation loss does not decrease for 5 consecutive epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_id": "00033-d7da52c7-7fbf-4f7d-940d-821cbe255b64",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "b623e53d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:19:49.398559: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-07-18 15:19:53.130851: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 - 4s - loss: 0.4254 - accuracy: 0.8785 - val_loss: 0.3535 - val_accuracy: 0.8965 - 4s/epoch - 7ms/step\n",
      "Epoch 2/100\n",
      "600/600 - 4s - loss: 0.6915 - accuracy: 0.8566 - val_loss: 0.9613 - val_accuracy: 0.8579 - 4s/epoch - 7ms/step\n",
      "Epoch 3/100\n",
      "600/600 - 4s - loss: 1.9253 - accuracy: 0.8141 - val_loss: 1.8767 - val_accuracy: 0.8370 - 4s/epoch - 7ms/step\n",
      "Epoch 4/100\n",
      "600/600 - 4s - loss: 2.8833 - accuracy: 0.8126 - val_loss: 2.5009 - val_accuracy: 0.8386 - 4s/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "cb = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "model = Sequential([\n",
    "    InputLayer(input_shape=x_train.shape[1:]),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=128, activation=\"relu\"),\n",
    "    Dense(units=y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "h = model.fit(x_train, y_train, epochs=100, batch_size=100, verbose=2, validation_data=(x_test, y_test), callbacks=[cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/313 [>.............................] - ETA: 2s - loss: 0.3357 - accuracy: 0.8965"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-18 15:20:06.230096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 7ms/step - loss: 0.3535 - accuracy: 0.8965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3535313010215759, 0.8964999914169312]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "35aa3537-3e05-40fa-86f0-1f7ded16df52",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

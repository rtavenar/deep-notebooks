{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Basics of automatic differentiation in PyTorch\n",
    "\n",
    "In this notebook, you will go through the basic notions of automatic differentiation (aka autodiff) in PyTorch.\n",
    "\n",
    "## 1. Manual differentiation in pure Python\n",
    "\n",
    "Before starting with `pytorch` and its automatic differentiation features, let us have a look at how to do manual differentiation in Python.\n",
    "\n",
    "To do so, we will use a very basic example in 1D: let $x$ be a scalar and let $y$ be defined as:\n",
    "\n",
    "$$y = (x - .5)^2$$\n",
    "\n",
    "Our goal will be to tune $x$ in order to minimize $y$.\n",
    "\n",
    "**Question 1.1.** Define a function `f` that takes `x` as input and returns `y` as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return (x - .5) ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "In order to be able to minimize, we will use a strategy called gradient descent.\n",
    "The idea of gradient descent is to iteratively update $x$ by moving it in the opposite direction of the gradient $\\frac{\\partial y}{\\partial x}$.\n",
    "We hence need to be able to compute $\\frac{\\partial y}{\\partial x}$.\n",
    "Since we do not rely on autodiff for now, we need to provide the explicit formula for this derivative.\n",
    "\n",
    "**Question 1.2.** Define a function `grad_f` that takes `x` as input and returns $\\frac{\\partial y}{\\partial x}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": [
    "def grad_f(x):\n",
    "    return 2 * (x - .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The basic idea behind gradient descent is to iteratively update $x$ using the following update rule:\n",
    "\n",
    "$$x \\leftarrow x - \\eta \\frac{\\partial y}{\\partial x}$$\n",
    "\n",
    "**Question 1.3.** Define a starting value for `x` and a step size `eta` and apply gradient descent for 30 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125\n",
      "0.2\n",
      "0.26\n",
      "0.308\n",
      "0.3464\n",
      "0.37712\n",
      "0.401696\n",
      "0.4213568\n",
      "0.43708544\n",
      "0.449668352\n",
      "0.4597346816\n",
      "0.46778774528\n",
      "0.474230196224\n",
      "0.4793841569792\n",
      "0.48350732558336\n",
      "0.486805860466688\n",
      "0.4894446883733504\n",
      "0.49155575069868035\n",
      "0.49324460055894426\n",
      "0.4945956804471554\n",
      "0.49567654435772435\n",
      "0.49654123548617946\n",
      "0.4972329883889436\n",
      "0.4977863907111549\n",
      "0.4982291125689239\n",
      "0.49858329005513913\n",
      "0.4988666320441113\n",
      "0.49909330563528903\n",
      "0.4992746445082312\n",
      "0.499419715606585\n"
     ]
    }
   ],
   "source": [
    "x = 0.125\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 30\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(x)\n",
    "    y = f(x)\n",
    "    x -= stepsize * grad_f(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 1.4.** Is the resulting value for `x` close to the value you would expect as a minimizer for $y = f(x)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. PyTorch and the automatic computation of gradients\n",
    "\n",
    "PyTorch is very similar to numpy in practice. One main difference is that one can ask, at any moment, for the automatic computation of gradients.\n",
    "\n",
    "To do so, if one wants to trigger the computation of $\\frac{\\partial a}{\\partial b}$ for any $b$, she should write:\n",
    "\n",
    "```python\n",
    "a.backward()\n",
    "```\n",
    "\n",
    "This will trigger the computation of the gradient of `a` with respect to any tensor that was involved in the computation of `a`.\n",
    "\n",
    "And the gradient $\\frac{\\partial a}{\\partial b}$ will be stored in `b.grad`.\n",
    "\n",
    "**Question 2.1.** Fill the code below to check what the gradient of `x` is before calling `backward()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def f(x):\n",
    "    return (x - .5) ** 2\n",
    "\n",
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "y = f(x)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 2.2.** Now, trigger the computation of gradients $\\frac{\\partial y}{\\partial x}$ and print this gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.7500)\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Gradient descent in PyTorch\n",
    "\n",
    "**Question 3.1.** Try to implement the gradient descent from Section 1 in PyTorch this time. You do not need to use `grad_f` anymore in your computations.\n",
    "Each iteration should consist in:\n",
    "1. computing `y` based on the current value for `x` ;\n",
    "2. explicitly forcing gradient computations ;\n",
    "3. updating `x` (this step needs to be protected in a `with torch.no_grad():` block) ;\n",
    "4. zero-ing out gradients of `x` for future steps not to accumulate gradient computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, requires_grad=True)\n",
      "tensor(0.2000, requires_grad=True)\n",
      "tensor(0.2600, requires_grad=True)\n",
      "tensor(0.3080, requires_grad=True)\n",
      "tensor(0.3464, requires_grad=True)\n",
      "tensor(0.3771, requires_grad=True)\n",
      "tensor(0.4017, requires_grad=True)\n",
      "tensor(0.4214, requires_grad=True)\n",
      "tensor(0.4371, requires_grad=True)\n",
      "tensor(0.4497, requires_grad=True)\n",
      "tensor(0.4597, requires_grad=True)\n",
      "tensor(0.4678, requires_grad=True)\n",
      "tensor(0.4742, requires_grad=True)\n",
      "tensor(0.4794, requires_grad=True)\n",
      "tensor(0.4835, requires_grad=True)\n",
      "tensor(0.4868, requires_grad=True)\n",
      "tensor(0.4894, requires_grad=True)\n",
      "tensor(0.4916, requires_grad=True)\n",
      "tensor(0.4932, requires_grad=True)\n",
      "tensor(0.4946, requires_grad=True)\n",
      "tensor(0.4957, requires_grad=True)\n",
      "tensor(0.4965, requires_grad=True)\n",
      "tensor(0.4972, requires_grad=True)\n",
      "tensor(0.4978, requires_grad=True)\n",
      "tensor(0.4982, requires_grad=True)\n",
      "tensor(0.4986, requires_grad=True)\n",
      "tensor(0.4989, requires_grad=True)\n",
      "tensor(0.4991, requires_grad=True)\n",
      "tensor(0.4993, requires_grad=True)\n",
      "tensor(0.4994, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(0.125, requires_grad=True)\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 30\n",
    "\n",
    "for i in range(n_iter):\n",
    "    print(x)\n",
    "    y = f(x)\n",
    "    y.backward()\n",
    "    with torch.no_grad():\n",
    "        x -= stepsize * x.grad\n",
    "    x.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Wrap-up: optimizing parameters of a univariate linear regression model\n",
    "\n",
    "Below is some code to generate (and visualize) the synthetic dataset you will use in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "keep"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x14d0d5d50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = torch.rand(100, 1)\n",
    "# w* = -3, b* = 1.5\n",
    "y = -3. * X + 1.5 + 0.4 * torch.randn(X.size())\n",
    "\n",
    "plt.scatter(X.numpy(), y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "You will try to fit a linear regression model to this dataset.\n",
    "\n",
    "**Question 4.1.** Given the code that generated the dataset, what should be the ideal values for $w$ and $b$ in your linear model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_YOUR ANSWER HERE_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 4.3.** Implement a function `mse` that would take `X`, `y`, `w`, `b` as inputs and outputs the mean squared error of the linear model parametrized by `w` and `b` on the dataset $(X, y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mse(X, y, w, b):\n",
    "    y_pred = w * X + b\n",
    "    return torch.mean((y_pred - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 4.2.** Implement a gradient descent loop to fit `w` and `b` that would minimize the mean squared error criterion based on the provided dataset. Use a step size of 0.1 and perform 1000 iterations of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1250, requires_grad=True) tensor(-0.1250, requires_grad=True) 1.0245169401168823\n",
      "tensor(0.0756, requires_grad=True) tensor(-0.1157, requires_grad=True) 0.9997116327285767\n",
      "tensor(0.0285, requires_grad=True) tensor(-0.1035, requires_grad=True) 0.9763141870498657\n",
      "tensor(-0.0168, requires_grad=True) tensor(-0.0891, requires_grad=True) 0.9539542198181152\n",
      "tensor(-0.0606, requires_grad=True) tensor(-0.0732, requires_grad=True) 0.932416558265686\n",
      "tensor(-0.1032, requires_grad=True) tensor(-0.0563, requires_grad=True) 0.9115747213363647\n",
      "tensor(-0.1447, requires_grad=True) tensor(-0.0386, requires_grad=True) 0.8913511037826538\n",
      "tensor(-0.1853, requires_grad=True) tensor(-0.0203, requires_grad=True) 0.8716967105865479\n",
      "tensor(-0.2250, requires_grad=True) tensor(-0.0018, requires_grad=True) 0.8525777459144592\n",
      "tensor(-0.2641, requires_grad=True) tensor(0.0168, requires_grad=True) 0.8339698314666748\n",
      "tensor(-0.3025, requires_grad=True) tensor(0.0356, requires_grad=True) 0.8158539533615112\n",
      "tensor(-0.3402, requires_grad=True) tensor(0.0543, requires_grad=True) 0.7982137203216553\n",
      "tensor(-0.3774, requires_grad=True) tensor(0.0729, requires_grad=True) 0.7810350656509399\n",
      "tensor(-0.4140, requires_grad=True) tensor(0.0915, requires_grad=True) 0.7643049359321594\n",
      "tensor(-0.4501, requires_grad=True) tensor(0.1099, requires_grad=True) 0.7480109930038452\n",
      "tensor(-0.4857, requires_grad=True) tensor(0.1281, requires_grad=True) 0.7321417331695557\n",
      "tensor(-0.5207, requires_grad=True) tensor(0.1461, requires_grad=True) 0.7166856527328491\n",
      "tensor(-0.5553, requires_grad=True) tensor(0.1639, requires_grad=True) 0.7016320824623108\n",
      "tensor(-0.5895, requires_grad=True) tensor(0.1816, requires_grad=True) 0.6869703531265259\n",
      "tensor(-0.6232, requires_grad=True) tensor(0.1990, requires_grad=True) 0.6726903319358826\n",
      "tensor(-0.6564, requires_grad=True) tensor(0.2162, requires_grad=True) 0.6587820649147034\n",
      "tensor(-0.6892, requires_grad=True) tensor(0.2332, requires_grad=True) 0.6452358365058899\n",
      "tensor(-0.7215, requires_grad=True) tensor(0.2500, requires_grad=True) 0.6320422291755676\n",
      "tensor(-0.7534, requires_grad=True) tensor(0.2666, requires_grad=True) 0.6191919445991516\n",
      "tensor(-0.7849, requires_grad=True) tensor(0.2829, requires_grad=True) 0.6066762804985046\n",
      "tensor(-0.8160, requires_grad=True) tensor(0.2991, requires_grad=True) 0.5944862961769104\n",
      "tensor(-0.8467, requires_grad=True) tensor(0.3150, requires_grad=True) 0.5826137065887451\n",
      "tensor(-0.8769, requires_grad=True) tensor(0.3308, requires_grad=True) 0.5710501670837402\n",
      "tensor(-0.9068, requires_grad=True) tensor(0.3463, requires_grad=True) 0.5597875118255615\n",
      "tensor(-0.9363, requires_grad=True) tensor(0.3616, requires_grad=True) 0.5488179922103882\n",
      "tensor(-0.9654, requires_grad=True) tensor(0.3767, requires_grad=True) 0.5381342172622681\n",
      "tensor(-0.9941, requires_grad=True) tensor(0.3917, requires_grad=True) 0.5277283191680908\n",
      "tensor(-1.0225, requires_grad=True) tensor(0.4064, requires_grad=True) 0.5175933837890625\n",
      "tensor(-1.0504, requires_grad=True) tensor(0.4210, requires_grad=True) 0.5077222585678101\n",
      "tensor(-1.0780, requires_grad=True) tensor(0.4353, requires_grad=True) 0.49810802936553955\n",
      "tensor(-1.1053, requires_grad=True) tensor(0.4495, requires_grad=True) 0.4887441396713257\n",
      "tensor(-1.1321, requires_grad=True) tensor(0.4635, requires_grad=True) 0.4796239137649536\n",
      "tensor(-1.1587, requires_grad=True) tensor(0.4773, requires_grad=True) 0.4707410931587219\n",
      "tensor(-1.1848, requires_grad=True) tensor(0.4909, requires_grad=True) 0.4620894193649292\n",
      "tensor(-1.2107, requires_grad=True) tensor(0.5043, requires_grad=True) 0.45366302132606506\n",
      "tensor(-1.2362, requires_grad=True) tensor(0.5176, requires_grad=True) 0.445455938577652\n",
      "tensor(-1.2613, requires_grad=True) tensor(0.5307, requires_grad=True) 0.43746253848075867\n",
      "tensor(-1.2862, requires_grad=True) tensor(0.5436, requires_grad=True) 0.4296771287918091\n",
      "tensor(-1.3107, requires_grad=True) tensor(0.5563, requires_grad=True) 0.4220944344997406\n",
      "tensor(-1.3349, requires_grad=True) tensor(0.5689, requires_grad=True) 0.4147090017795563\n",
      "tensor(-1.3588, requires_grad=True) tensor(0.5813, requires_grad=True) 0.40751591324806213\n",
      "tensor(-1.3823, requires_grad=True) tensor(0.5936, requires_grad=True) 0.4005100131034851\n",
      "tensor(-1.4056, requires_grad=True) tensor(0.6057, requires_grad=True) 0.3936864733695984\n",
      "tensor(-1.4285, requires_grad=True) tensor(0.6176, requires_grad=True) 0.3870405852794647\n",
      "tensor(-1.4512, requires_grad=True) tensor(0.6294, requires_grad=True) 0.38056764006614685\n",
      "tensor(-1.4735, requires_grad=True) tensor(0.6410, requires_grad=True) 0.3742632269859314\n",
      "tensor(-1.4956, requires_grad=True) tensor(0.6525, requires_grad=True) 0.3681229054927826\n",
      "tensor(-1.5173, requires_grad=True) tensor(0.6638, requires_grad=True) 0.3621423840522766\n",
      "tensor(-1.5388, requires_grad=True) tensor(0.6750, requires_grad=True) 0.35631754994392395\n",
      "tensor(-1.5600, requires_grad=True) tensor(0.6860, requires_grad=True) 0.3506442904472351\n",
      "tensor(-1.5809, requires_grad=True) tensor(0.6969, requires_grad=True) 0.34511879086494446\n",
      "tensor(-1.6016, requires_grad=True) tensor(0.7076, requires_grad=True) 0.33973708748817444\n",
      "tensor(-1.6220, requires_grad=True) tensor(0.7182, requires_grad=True) 0.3344954252243042\n",
      "tensor(-1.6421, requires_grad=True) tensor(0.7287, requires_grad=True) 0.3293902575969696\n",
      "tensor(-1.6619, requires_grad=True) tensor(0.7390, requires_grad=True) 0.32441791892051697\n",
      "tensor(-1.6815, requires_grad=True) tensor(0.7492, requires_grad=True) 0.3195750117301941\n",
      "tensor(-1.7008, requires_grad=True) tensor(0.7593, requires_grad=True) 0.31485825777053833\n",
      "tensor(-1.7199, requires_grad=True) tensor(0.7692, requires_grad=True) 0.3102641701698303\n",
      "tensor(-1.7387, requires_grad=True) tensor(0.7790, requires_grad=True) 0.3057897090911865\n",
      "tensor(-1.7573, requires_grad=True) tensor(0.7886, requires_grad=True) 0.30143168568611145\n",
      "tensor(-1.7757, requires_grad=True) tensor(0.7982, requires_grad=True) 0.2971871495246887\n",
      "tensor(-1.7938, requires_grad=True) tensor(0.8076, requires_grad=True) 0.2930530607700348\n",
      "tensor(-1.8116, requires_grad=True) tensor(0.8169, requires_grad=True) 0.2890266180038452\n",
      "tensor(-1.8293, requires_grad=True) tensor(0.8260, requires_grad=True) 0.2851049304008484\n",
      "tensor(-1.8466, requires_grad=True) tensor(0.8351, requires_grad=True) 0.2812853753566742\n",
      "tensor(-1.8638, requires_grad=True) tensor(0.8440, requires_grad=True) 0.27756524085998535\n",
      "tensor(-1.8808, requires_grad=True) tensor(0.8528, requires_grad=True) 0.27394187450408936\n",
      "tensor(-1.8975, requires_grad=True) tensor(0.8615, requires_grad=True) 0.2704128324985504\n",
      "tensor(-1.9140, requires_grad=True) tensor(0.8701, requires_grad=True) 0.2669757008552551\n",
      "tensor(-1.9303, requires_grad=True) tensor(0.8786, requires_grad=True) 0.2636279761791229\n",
      "tensor(-1.9463, requires_grad=True) tensor(0.8869, requires_grad=True) 0.2603674829006195\n",
      "tensor(-1.9622, requires_grad=True) tensor(0.8952, requires_grad=True) 0.2571917474269867\n",
      "tensor(-1.9779, requires_grad=True) tensor(0.9033, requires_grad=True) 0.2540987730026245\n",
      "tensor(-1.9933, requires_grad=True) tensor(0.9114, requires_grad=True) 0.2510862350463867\n",
      "tensor(-2.0085, requires_grad=True) tensor(0.9193, requires_grad=True) 0.24815216660499573\n",
      "tensor(-2.0236, requires_grad=True) tensor(0.9271, requires_grad=True) 0.24529442191123962\n",
      "tensor(-2.0384, requires_grad=True) tensor(0.9349, requires_grad=True) 0.2425110936164856\n",
      "tensor(-2.0531, requires_grad=True) tensor(0.9425, requires_grad=True) 0.23980022966861725\n",
      "tensor(-2.0676, requires_grad=True) tensor(0.9500, requires_grad=True) 0.23715990781784058\n",
      "tensor(-2.0818, requires_grad=True) tensor(0.9574, requires_grad=True) 0.23458828032016754\n",
      "tensor(-2.0959, requires_grad=True) tensor(0.9647, requires_grad=True) 0.23208366334438324\n",
      "tensor(-2.1098, requires_grad=True) tensor(0.9720, requires_grad=True) 0.22964417934417725\n",
      "tensor(-2.1235, requires_grad=True) tensor(0.9791, requires_grad=True) 0.22726820409297943\n",
      "tensor(-2.1371, requires_grad=True) tensor(0.9862, requires_grad=True) 0.22495411336421967\n",
      "tensor(-2.1504, requires_grad=True) tensor(0.9931, requires_grad=True) 0.22270019352436066\n",
      "tensor(-2.1636, requires_grad=True) tensor(1.0000, requires_grad=True) 0.2205049693584442\n",
      "tensor(-2.1767, requires_grad=True) tensor(1.0067, requires_grad=True) 0.21836690604686737\n",
      "tensor(-2.1895, requires_grad=True) tensor(1.0134, requires_grad=True) 0.21628448367118835\n",
      "tensor(-2.2022, requires_grad=True) tensor(1.0200, requires_grad=True) 0.21425627171993256\n",
      "tensor(-2.2147, requires_grad=True) tensor(1.0265, requires_grad=True) 0.21228080987930298\n",
      "tensor(-2.2270, requires_grad=True) tensor(1.0329, requires_grad=True) 0.21035683155059814\n",
      "tensor(-2.2392, requires_grad=True) tensor(1.0393, requires_grad=True) 0.20848292112350464\n",
      "tensor(-2.2512, requires_grad=True) tensor(1.0455, requires_grad=True) 0.2066577672958374\n",
      "tensor(-2.2631, requires_grad=True) tensor(1.0517, requires_grad=True) 0.20488010346889496\n",
      "tensor(-2.2748, requires_grad=True) tensor(1.0578, requires_grad=True) 0.2031487226486206\n",
      "tensor(-2.2864, requires_grad=True) tensor(1.0638, requires_grad=True) 0.20146244764328003\n",
      "tensor(-2.2978, requires_grad=True) tensor(1.0697, requires_grad=True) 0.19982002675533295\n",
      "tensor(-2.3090, requires_grad=True) tensor(1.0756, requires_grad=True) 0.1982203722000122\n",
      "tensor(-2.3202, requires_grad=True) tensor(1.0814, requires_grad=True) 0.19666236639022827\n",
      "tensor(-2.3311, requires_grad=True) tensor(1.0871, requires_grad=True) 0.1951448768377304\n",
      "tensor(-2.3419, requires_grad=True) tensor(1.0927, requires_grad=True) 0.19366693496704102\n",
      "tensor(-2.3526, requires_grad=True) tensor(1.0983, requires_grad=True) 0.19222743809223175\n",
      "tensor(-2.3632, requires_grad=True) tensor(1.1037, requires_grad=True) 0.19082540273666382\n",
      "tensor(-2.3736, requires_grad=True) tensor(1.1092, requires_grad=True) 0.1894598752260208\n",
      "tensor(-2.3838, requires_grad=True) tensor(1.1145, requires_grad=True) 0.18812985718250275\n",
      "tensor(-2.3940, requires_grad=True) tensor(1.1198, requires_grad=True) 0.18683448433876038\n",
      "tensor(-2.4040, requires_grad=True) tensor(1.1250, requires_grad=True) 0.18557284772396088\n",
      "tensor(-2.4138, requires_grad=True) tensor(1.1301, requires_grad=True) 0.1843440681695938\n",
      "tensor(-2.4236, requires_grad=True) tensor(1.1352, requires_grad=True) 0.18314723670482635\n",
      "tensor(-2.4332, requires_grad=True) tensor(1.1402, requires_grad=True) 0.18198156356811523\n",
      "tensor(-2.4426, requires_grad=True) tensor(1.1451, requires_grad=True) 0.1808462291955948\n",
      "tensor(-2.4520, requires_grad=True) tensor(1.1500, requires_grad=True) 0.17974044382572174\n",
      "tensor(-2.4612, requires_grad=True) tensor(1.1548, requires_grad=True) 0.1786634624004364\n",
      "tensor(-2.4704, requires_grad=True) tensor(1.1595, requires_grad=True) 0.1776145100593567\n",
      "tensor(-2.4794, requires_grad=True) tensor(1.1642, requires_grad=True) 0.1765928715467453\n",
      "tensor(-2.4882, requires_grad=True) tensor(1.1688, requires_grad=True) 0.17559780180454254\n",
      "tensor(-2.4970, requires_grad=True) tensor(1.1734, requires_grad=True) 0.17462864518165588\n",
      "tensor(-2.5056, requires_grad=True) tensor(1.1779, requires_grad=True) 0.17368468642234802\n",
      "tensor(-2.5142, requires_grad=True) tensor(1.1823, requires_grad=True) 0.17276531457901\n",
      "tensor(-2.5226, requires_grad=True) tensor(1.1867, requires_grad=True) 0.1718698889017105\n",
      "tensor(-2.5309, requires_grad=True) tensor(1.1910, requires_grad=True) 0.170997753739357\n",
      "tensor(-2.5391, requires_grad=True) tensor(1.1953, requires_grad=True) 0.1701483279466629\n",
      "tensor(-2.5472, requires_grad=True) tensor(1.1995, requires_grad=True) 0.1693210005760193\n",
      "tensor(-2.5552, requires_grad=True) tensor(1.2036, requires_grad=True) 0.16851522028446198\n",
      "tensor(-2.5631, requires_grad=True) tensor(1.2077, requires_grad=True) 0.167730450630188\n",
      "tensor(-2.5709, requires_grad=True) tensor(1.2118, requires_grad=True) 0.16696608066558838\n",
      "tensor(-2.5786, requires_grad=True) tensor(1.2158, requires_grad=True) 0.16622160375118256\n",
      "tensor(-2.5861, requires_grad=True) tensor(1.2197, requires_grad=True) 0.16549648344516754\n",
      "tensor(-2.5936, requires_grad=True) tensor(1.2236, requires_grad=True) 0.16479024291038513\n",
      "tensor(-2.6010, requires_grad=True) tensor(1.2274, requires_grad=True) 0.16410240530967712\n",
      "tensor(-2.6083, requires_grad=True) tensor(1.2312, requires_grad=True) 0.16343246400356293\n",
      "tensor(-2.6155, requires_grad=True) tensor(1.2350, requires_grad=True) 0.16277994215488434\n",
      "tensor(-2.6226, requires_grad=True) tensor(1.2387, requires_grad=True) 0.16214443743228912\n",
      "tensor(-2.6296, requires_grad=True) tensor(1.2423, requires_grad=True) 0.1615254431962967\n",
      "tensor(-2.6365, requires_grad=True) tensor(1.2459, requires_grad=True) 0.160922572016716\n",
      "tensor(-2.6433, requires_grad=True) tensor(1.2495, requires_grad=True) 0.16033540666103363\n",
      "tensor(-2.6500, requires_grad=True) tensor(1.2530, requires_grad=True) 0.15976350009441376\n",
      "tensor(-2.6567, requires_grad=True) tensor(1.2564, requires_grad=True) 0.15920650959014893\n",
      "tensor(-2.6632, requires_grad=True) tensor(1.2598, requires_grad=True) 0.15866400301456451\n",
      "tensor(-2.6697, requires_grad=True) tensor(1.2632, requires_grad=True) 0.15813559293746948\n",
      "tensor(-2.6761, requires_grad=True) tensor(1.2665, requires_grad=True) 0.15762095153331757\n",
      "tensor(-2.6824, requires_grad=True) tensor(1.2698, requires_grad=True) 0.1571197360754013\n",
      "tensor(-2.6886, requires_grad=True) tensor(1.2730, requires_grad=True) 0.15663154423236847\n",
      "tensor(-2.6947, requires_grad=True) tensor(1.2762, requires_grad=True) 0.15615606307983398\n",
      "tensor(-2.7008, requires_grad=True) tensor(1.2794, requires_grad=True) 0.1556929498910904\n",
      "tensor(-2.7068, requires_grad=True) tensor(1.2825, requires_grad=True) 0.15524190664291382\n",
      "tensor(-2.7127, requires_grad=True) tensor(1.2855, requires_grad=True) 0.1548025757074356\n",
      "tensor(-2.7185, requires_grad=True) tensor(1.2886, requires_grad=True) 0.15437471866607666\n",
      "tensor(-2.7242, requires_grad=True) tensor(1.2916, requires_grad=True) 0.15395797789096832\n",
      "tensor(-2.7299, requires_grad=True) tensor(1.2945, requires_grad=True) 0.1535520851612091\n",
      "tensor(-2.7355, requires_grad=True) tensor(1.2974, requires_grad=True) 0.15315677225589752\n",
      "tensor(-2.7410, requires_grad=True) tensor(1.3003, requires_grad=True) 0.1527717262506485\n",
      "tensor(-2.7465, requires_grad=True) tensor(1.3031, requires_grad=True) 0.15239672362804413\n",
      "tensor(-2.7519, requires_grad=True) tensor(1.3059, requires_grad=True) 0.15203146636486053\n",
      "tensor(-2.7572, requires_grad=True) tensor(1.3087, requires_grad=True) 0.15167571604251862\n",
      "tensor(-2.7624, requires_grad=True) tensor(1.3114, requires_grad=True) 0.15132923424243927\n",
      "tensor(-2.7676, requires_grad=True) tensor(1.3141, requires_grad=True) 0.1509917676448822\n",
      "tensor(-2.7727, requires_grad=True) tensor(1.3167, requires_grad=True) 0.1506630927324295\n",
      "tensor(-2.7777, requires_grad=True) tensor(1.3194, requires_grad=True) 0.15034295618534088\n",
      "tensor(-2.7827, requires_grad=True) tensor(1.3220, requires_grad=True) 0.150031179189682\n",
      "tensor(-2.7876, requires_grad=True) tensor(1.3245, requires_grad=True) 0.14972750842571259\n",
      "tensor(-2.7924, requires_grad=True) tensor(1.3270, requires_grad=True) 0.1494317203760147\n",
      "tensor(-2.7972, requires_grad=True) tensor(1.3295, requires_grad=True) 0.14914365112781525\n",
      "tensor(-2.8019, requires_grad=True) tensor(1.3320, requires_grad=True) 0.1488630622625351\n",
      "tensor(-2.8066, requires_grad=True) tensor(1.3344, requires_grad=True) 0.14858980476856232\n",
      "tensor(-2.8112, requires_grad=True) tensor(1.3368, requires_grad=True) 0.1483236402273178\n",
      "tensor(-2.8157, requires_grad=True) tensor(1.3391, requires_grad=True) 0.14806441962718964\n",
      "tensor(-2.8202, requires_grad=True) tensor(1.3415, requires_grad=True) 0.14781193435192108\n",
      "tensor(-2.8246, requires_grad=True) tensor(1.3437, requires_grad=True) 0.1475660353899002\n",
      "tensor(-2.8290, requires_grad=True) tensor(1.3460, requires_grad=True) 0.1473265141248703\n",
      "tensor(-2.8333, requires_grad=True) tensor(1.3482, requires_grad=True) 0.14709323644638062\n",
      "tensor(-2.8375, requires_grad=True) tensor(1.3505, requires_grad=True) 0.14686603844165802\n",
      "tensor(-2.8417, requires_grad=True) tensor(1.3526, requires_grad=True) 0.14664477109909058\n",
      "tensor(-2.8458, requires_grad=True) tensor(1.3548, requires_grad=True) 0.14642924070358276\n",
      "tensor(-2.8499, requires_grad=True) tensor(1.3569, requires_grad=True) 0.14621931314468384\n",
      "tensor(-2.8539, requires_grad=True) tensor(1.3590, requires_grad=True) 0.14601485431194305\n",
      "tensor(-2.8579, requires_grad=True) tensor(1.3611, requires_grad=True) 0.14581570029258728\n",
      "tensor(-2.8618, requires_grad=True) tensor(1.3631, requires_grad=True) 0.14562176167964935\n",
      "tensor(-2.8657, requires_grad=True) tensor(1.3651, requires_grad=True) 0.14543285965919495\n",
      "tensor(-2.8695, requires_grad=True) tensor(1.3671, requires_grad=True) 0.1452488750219345\n",
      "tensor(-2.8733, requires_grad=True) tensor(1.3691, requires_grad=True) 0.1450696885585785\n",
      "tensor(-2.8770, requires_grad=True) tensor(1.3710, requires_grad=True) 0.14489515125751495\n",
      "tensor(-2.8807, requires_grad=True) tensor(1.3729, requires_grad=True) 0.14472515881061554\n",
      "tensor(-2.8843, requires_grad=True) tensor(1.3748, requires_grad=True) 0.1445596069097519\n",
      "tensor(-2.8878, requires_grad=True) tensor(1.3766, requires_grad=True) 0.14439833164215088\n",
      "tensor(-2.8914, requires_grad=True) tensor(1.3785, requires_grad=True) 0.14424128830432892\n",
      "tensor(-2.8949, requires_grad=True) tensor(1.3803, requires_grad=True) 0.14408831298351288\n",
      "tensor(-2.8983, requires_grad=True) tensor(1.3821, requires_grad=True) 0.1439393311738968\n",
      "tensor(-2.9017, requires_grad=True) tensor(1.3838, requires_grad=True) 0.1437942236661911\n",
      "tensor(-2.9050, requires_grad=True) tensor(1.3856, requires_grad=True) 0.14365290105342865\n",
      "tensor(-2.9083, requires_grad=True) tensor(1.3873, requires_grad=True) 0.14351524412631989\n",
      "tensor(-2.9116, requires_grad=True) tensor(1.3890, requires_grad=True) 0.14338116347789764\n",
      "tensor(-2.9148, requires_grad=True) tensor(1.3907, requires_grad=True) 0.14325058460235596\n",
      "tensor(-2.9180, requires_grad=True) tensor(1.3923, requires_grad=True) 0.14312340319156647\n",
      "tensor(-2.9211, requires_grad=True) tensor(1.3939, requires_grad=True) 0.142999529838562\n",
      "tensor(-2.9242, requires_grad=True) tensor(1.3956, requires_grad=True) 0.14287889003753662\n",
      "tensor(-2.9273, requires_grad=True) tensor(1.3971, requires_grad=True) 0.14276136457920074\n",
      "tensor(-2.9303, requires_grad=True) tensor(1.3987, requires_grad=True) 0.142646923661232\n",
      "tensor(-2.9332, requires_grad=True) tensor(1.4003, requires_grad=True) 0.14253546297550201\n",
      "tensor(-2.9362, requires_grad=True) tensor(1.4018, requires_grad=True) 0.14242689311504364\n",
      "tensor(-2.9391, requires_grad=True) tensor(1.4033, requires_grad=True) 0.1423211544752121\n",
      "tensor(-2.9419, requires_grad=True) tensor(1.4048, requires_grad=True) 0.14221815764904022\n",
      "tensor(-2.9447, requires_grad=True) tensor(1.4062, requires_grad=True) 0.14211785793304443\n",
      "tensor(-2.9475, requires_grad=True) tensor(1.4077, requires_grad=True) 0.14202015101909637\n",
      "tensor(-2.9503, requires_grad=True) tensor(1.4091, requires_grad=True) 0.14192500710487366\n",
      "tensor(-2.9530, requires_grad=True) tensor(1.4105, requires_grad=True) 0.14183233678340912\n",
      "tensor(-2.9557, requires_grad=True) tensor(1.4119, requires_grad=True) 0.1417420506477356\n",
      "tensor(-2.9583, requires_grad=True) tensor(1.4133, requires_grad=True) 0.1416541486978531\n",
      "tensor(-2.9609, requires_grad=True) tensor(1.4146, requires_grad=True) 0.14156852662563324\n",
      "tensor(-2.9635, requires_grad=True) tensor(1.4160, requires_grad=True) 0.14148512482643127\n",
      "tensor(-2.9660, requires_grad=True) tensor(1.4173, requires_grad=True) 0.1414038985967636\n",
      "tensor(-2.9685, requires_grad=True) tensor(1.4186, requires_grad=True) 0.14132477343082428\n",
      "tensor(-2.9710, requires_grad=True) tensor(1.4199, requires_grad=True) 0.1412477344274521\n",
      "tensor(-2.9734, requires_grad=True) tensor(1.4212, requires_grad=True) 0.14117269217967987\n",
      "tensor(-2.9758, requires_grad=True) tensor(1.4224, requires_grad=True) 0.14109958708286285\n",
      "tensor(-2.9782, requires_grad=True) tensor(1.4236, requires_grad=True) 0.14102838933467865\n",
      "tensor(-2.9805, requires_grad=True) tensor(1.4249, requires_grad=True) 0.14095905423164368\n",
      "tensor(-2.9829, requires_grad=True) tensor(1.4261, requires_grad=True) 0.14089152216911316\n",
      "tensor(-2.9851, requires_grad=True) tensor(1.4272, requires_grad=True) 0.14082573354244232\n",
      "tensor(-2.9874, requires_grad=True) tensor(1.4284, requires_grad=True) 0.14076167345046997\n",
      "tensor(-2.9896, requires_grad=True) tensor(1.4296, requires_grad=True) 0.14069929718971252\n",
      "tensor(-2.9918, requires_grad=True) tensor(1.4307, requires_grad=True) 0.14063850045204163\n",
      "tensor(-2.9940, requires_grad=True) tensor(1.4318, requires_grad=True) 0.14057931303977966\n",
      "tensor(-2.9961, requires_grad=True) tensor(1.4330, requires_grad=True) 0.14052167534828186\n",
      "tensor(-2.9982, requires_grad=True) tensor(1.4341, requires_grad=True) 0.14046552777290344\n",
      "tensor(-3.0003, requires_grad=True) tensor(1.4351, requires_grad=True) 0.14041084051132202\n",
      "tensor(-3.0024, requires_grad=True) tensor(1.4362, requires_grad=True) 0.14035755395889282\n",
      "tensor(-3.0044, requires_grad=True) tensor(1.4373, requires_grad=True) 0.14030569791793823\n",
      "tensor(-3.0064, requires_grad=True) tensor(1.4383, requires_grad=True) 0.1402551680803299\n",
      "tensor(-3.0084, requires_grad=True) tensor(1.4393, requires_grad=True) 0.14020594954490662\n",
      "tensor(-3.0103, requires_grad=True) tensor(1.4403, requires_grad=True) 0.1401580274105072\n",
      "tensor(-3.0122, requires_grad=True) tensor(1.4413, requires_grad=True) 0.14011134207248688\n",
      "tensor(-3.0141, requires_grad=True) tensor(1.4423, requires_grad=True) 0.14006586372852325\n",
      "tensor(-3.0160, requires_grad=True) tensor(1.4433, requires_grad=True) 0.14002157747745514\n",
      "tensor(-3.0179, requires_grad=True) tensor(1.4443, requires_grad=True) 0.13997845351696014\n",
      "tensor(-3.0197, requires_grad=True) tensor(1.4452, requires_grad=True) 0.1399364322423935\n",
      "tensor(-3.0215, requires_grad=True) tensor(1.4461, requires_grad=True) 0.13989552855491638\n",
      "tensor(-3.0233, requires_grad=True) tensor(1.4471, requires_grad=True) 0.13985565304756165\n",
      "tensor(-3.0250, requires_grad=True) tensor(1.4480, requires_grad=True) 0.13981685042381287\n",
      "tensor(-3.0267, requires_grad=True) tensor(1.4489, requires_grad=True) 0.13977906107902527\n",
      "tensor(-3.0284, requires_grad=True) tensor(1.4498, requires_grad=True) 0.13974222540855408\n",
      "tensor(-3.0301, requires_grad=True) tensor(1.4507, requires_grad=True) 0.13970638811588287\n",
      "tensor(-3.0318, requires_grad=True) tensor(1.4515, requires_grad=True) 0.1396714448928833\n",
      "tensor(-3.0334, requires_grad=True) tensor(1.4524, requires_grad=True) 0.13963741064071655\n",
      "tensor(-3.0351, requires_grad=True) tensor(1.4532, requires_grad=True) 0.13960428535938263\n",
      "tensor(-3.0367, requires_grad=True) tensor(1.4540, requires_grad=True) 0.13957202434539795\n",
      "tensor(-3.0382, requires_grad=True) tensor(1.4549, requires_grad=True) 0.13954058289527893\n",
      "tensor(-3.0398, requires_grad=True) tensor(1.4557, requires_grad=True) 0.13950997591018677\n",
      "tensor(-3.0413, requires_grad=True) tensor(1.4565, requires_grad=True) 0.13948017358779907\n",
      "tensor(-3.0428, requires_grad=True) tensor(1.4573, requires_grad=True) 0.13945111632347107\n",
      "tensor(-3.0443, requires_grad=True) tensor(1.4580, requires_grad=True) 0.13942284882068634\n",
      "tensor(-3.0458, requires_grad=True) tensor(1.4588, requires_grad=True) 0.13939528167247772\n",
      "tensor(-3.0473, requires_grad=True) tensor(1.4596, requires_grad=True) 0.1393684595823288\n",
      "tensor(-3.0487, requires_grad=True) tensor(1.4603, requires_grad=True) 0.13934233784675598\n",
      "tensor(-3.0501, requires_grad=True) tensor(1.4611, requires_grad=True) 0.1393168568611145\n",
      "tensor(-3.0515, requires_grad=True) tensor(1.4618, requires_grad=True) 0.13929209113121033\n",
      "tensor(-3.0529, requires_grad=True) tensor(1.4625, requires_grad=True) 0.1392679363489151\n",
      "tensor(-3.0543, requires_grad=True) tensor(1.4632, requires_grad=True) 0.1392444372177124\n",
      "tensor(-3.0556, requires_grad=True) tensor(1.4639, requires_grad=True) 0.13922151923179626\n",
      "tensor(-3.0570, requires_grad=True) tensor(1.4646, requires_grad=True) 0.13919921219348907\n",
      "tensor(-3.0583, requires_grad=True) tensor(1.4653, requires_grad=True) 0.13917747139930725\n",
      "tensor(-3.0596, requires_grad=True) tensor(1.4660, requires_grad=True) 0.13915632665157318\n",
      "tensor(-3.0608, requires_grad=True) tensor(1.4666, requires_grad=True) 0.1391357183456421\n",
      "tensor(-3.0621, requires_grad=True) tensor(1.4673, requires_grad=True) 0.13911563158035278\n",
      "tensor(-3.0634, requires_grad=True) tensor(1.4679, requires_grad=True) 0.13909609615802765\n",
      "tensor(-3.0646, requires_grad=True) tensor(1.4686, requires_grad=True) 0.13907703757286072\n",
      "tensor(-3.0658, requires_grad=True) tensor(1.4692, requires_grad=True) 0.13905850052833557\n",
      "tensor(-3.0670, requires_grad=True) tensor(1.4698, requires_grad=True) 0.13904042541980743\n",
      "tensor(-3.0682, requires_grad=True) tensor(1.4704, requires_grad=True) 0.1390228420495987\n",
      "tensor(-3.0693, requires_grad=True) tensor(1.4710, requires_grad=True) 0.13900570571422577\n",
      "tensor(-3.0705, requires_grad=True) tensor(1.4716, requires_grad=True) 0.13898901641368866\n",
      "tensor(-3.0716, requires_grad=True) tensor(1.4722, requires_grad=True) 0.13897275924682617\n",
      "tensor(-3.0727, requires_grad=True) tensor(1.4728, requires_grad=True) 0.1389569342136383\n",
      "tensor(-3.0738, requires_grad=True) tensor(1.4734, requires_grad=True) 0.13894151151180267\n",
      "tensor(-3.0749, requires_grad=True) tensor(1.4740, requires_grad=True) 0.13892649114131927\n",
      "tensor(-3.0760, requires_grad=True) tensor(1.4745, requires_grad=True) 0.13891185820102692\n",
      "tensor(-3.0771, requires_grad=True) tensor(1.4751, requires_grad=True) 0.1388976275920868\n",
      "tensor(-3.0781, requires_grad=True) tensor(1.4756, requires_grad=True) 0.13888373970985413\n",
      "tensor(-3.0792, requires_grad=True) tensor(1.4762, requires_grad=True) 0.1388702392578125\n",
      "tensor(-3.0802, requires_grad=True) tensor(1.4767, requires_grad=True) 0.13885706663131714\n",
      "tensor(-3.0812, requires_grad=True) tensor(1.4772, requires_grad=True) 0.13884425163269043\n",
      "tensor(-3.0822, requires_grad=True) tensor(1.4777, requires_grad=True) 0.13883176445960999\n",
      "tensor(-3.0832, requires_grad=True) tensor(1.4782, requires_grad=True) 0.1388196051120758\n",
      "tensor(-3.0841, requires_grad=True) tensor(1.4787, requires_grad=True) 0.1388077586889267\n",
      "tensor(-3.0851, requires_grad=True) tensor(1.4792, requires_grad=True) 0.13879621028900146\n",
      "tensor(-3.0860, requires_grad=True) tensor(1.4797, requires_grad=True) 0.1387849748134613\n",
      "tensor(-3.0870, requires_grad=True) tensor(1.4802, requires_grad=True) 0.13877403736114502\n",
      "tensor(-3.0879, requires_grad=True) tensor(1.4807, requires_grad=True) 0.13876338303089142\n",
      "tensor(-3.0888, requires_grad=True) tensor(1.4812, requires_grad=True) 0.1387529969215393\n",
      "tensor(-3.0897, requires_grad=True) tensor(1.4816, requires_grad=True) 0.13874287903308868\n",
      "tensor(-3.0906, requires_grad=True) tensor(1.4821, requires_grad=True) 0.13873302936553955\n",
      "tensor(-3.0914, requires_grad=True) tensor(1.4825, requires_grad=True) 0.1387234330177307\n",
      "tensor(-3.0923, requires_grad=True) tensor(1.4830, requires_grad=True) 0.13871410489082336\n",
      "tensor(-3.0931, requires_grad=True) tensor(1.4834, requires_grad=True) 0.13870500028133392\n",
      "tensor(-3.0940, requires_grad=True) tensor(1.4839, requires_grad=True) 0.13869613409042358\n",
      "tensor(-3.0948, requires_grad=True) tensor(1.4843, requires_grad=True) 0.13868752121925354\n",
      "tensor(-3.0956, requires_grad=True) tensor(1.4847, requires_grad=True) 0.13867910206317902\n",
      "tensor(-3.0964, requires_grad=True) tensor(1.4851, requires_grad=True) 0.1386709213256836\n",
      "tensor(-3.0972, requires_grad=True) tensor(1.4855, requires_grad=True) 0.1386629343032837\n",
      "tensor(-3.0980, requires_grad=True) tensor(1.4860, requires_grad=True) 0.1386551707983017\n",
      "tensor(-3.0988, requires_grad=True) tensor(1.4864, requires_grad=True) 0.13864760100841522\n",
      "tensor(-3.0996, requires_grad=True) tensor(1.4868, requires_grad=True) 0.13864023983478546\n",
      "tensor(-3.1003, requires_grad=True) tensor(1.4872, requires_grad=True) 0.13863305747509003\n",
      "tensor(-3.1011, requires_grad=True) tensor(1.4875, requires_grad=True) 0.1386260688304901\n",
      "tensor(-3.1018, requires_grad=True) tensor(1.4879, requires_grad=True) 0.13861924409866333\n",
      "tensor(-3.1025, requires_grad=True) tensor(1.4883, requires_grad=True) 0.13861262798309326\n",
      "tensor(-3.1032, requires_grad=True) tensor(1.4887, requires_grad=True) 0.13860617578029633\n",
      "tensor(-3.1039, requires_grad=True) tensor(1.4890, requires_grad=True) 0.13859987258911133\n",
      "tensor(-3.1046, requires_grad=True) tensor(1.4894, requires_grad=True) 0.13859373331069946\n",
      "tensor(-3.1053, requires_grad=True) tensor(1.4898, requires_grad=True) 0.13858777284622192\n",
      "tensor(-3.1060, requires_grad=True) tensor(1.4901, requires_grad=True) 0.13858197629451752\n",
      "tensor(-3.1067, requires_grad=True) tensor(1.4905, requires_grad=True) 0.13857632875442505\n",
      "tensor(-3.1073, requires_grad=True) tensor(1.4908, requires_grad=True) 0.13857080042362213\n",
      "tensor(-3.1080, requires_grad=True) tensor(1.4911, requires_grad=True) 0.13856542110443115\n",
      "tensor(-3.1086, requires_grad=True) tensor(1.4915, requires_grad=True) 0.1385602056980133\n",
      "tensor(-3.1093, requires_grad=True) tensor(1.4918, requires_grad=True) 0.138555109500885\n",
      "tensor(-3.1099, requires_grad=True) tensor(1.4921, requires_grad=True) 0.13855013251304626\n",
      "tensor(-3.1105, requires_grad=True) tensor(1.4925, requires_grad=True) 0.13854531943798065\n",
      "tensor(-3.1111, requires_grad=True) tensor(1.4928, requires_grad=True) 0.1385406106710434\n",
      "tensor(-3.1117, requires_grad=True) tensor(1.4931, requires_grad=True) 0.1385360211133957\n",
      "tensor(-3.1123, requires_grad=True) tensor(1.4934, requires_grad=True) 0.13853156566619873\n",
      "tensor(-3.1129, requires_grad=True) tensor(1.4937, requires_grad=True) 0.13852721452713013\n",
      "tensor(-3.1135, requires_grad=True) tensor(1.4940, requires_grad=True) 0.13852296769618988\n",
      "tensor(-3.1140, requires_grad=True) tensor(1.4943, requires_grad=True) 0.13851885497570038\n",
      "tensor(-3.1146, requires_grad=True) tensor(1.4946, requires_grad=True) 0.13851484656333923\n",
      "tensor(-3.1152, requires_grad=True) tensor(1.4949, requires_grad=True) 0.13851092755794525\n",
      "tensor(-3.1157, requires_grad=True) tensor(1.4952, requires_grad=True) 0.13850711286067963\n",
      "tensor(-3.1163, requires_grad=True) tensor(1.4954, requires_grad=True) 0.13850340247154236\n",
      "tensor(-3.1168, requires_grad=True) tensor(1.4957, requires_grad=True) 0.13849978148937225\n",
      "tensor(-3.1173, requires_grad=True) tensor(1.4960, requires_grad=True) 0.1384962648153305\n",
      "tensor(-3.1178, requires_grad=True) tensor(1.4963, requires_grad=True) 0.13849283754825592\n",
      "tensor(-3.1184, requires_grad=True) tensor(1.4965, requires_grad=True) 0.1384894996881485\n",
      "tensor(-3.1189, requires_grad=True) tensor(1.4968, requires_grad=True) 0.13848623633384705\n",
      "tensor(-3.1194, requires_grad=True) tensor(1.4971, requires_grad=True) 0.13848307728767395\n",
      "tensor(-3.1199, requires_grad=True) tensor(1.4973, requires_grad=True) 0.13847999274730682\n",
      "tensor(-3.1204, requires_grad=True) tensor(1.4976, requires_grad=True) 0.13847698271274567\n",
      "tensor(-3.1208, requires_grad=True) tensor(1.4978, requires_grad=True) 0.13847406208515167\n",
      "tensor(-3.1213, requires_grad=True) tensor(1.4981, requires_grad=True) 0.13847120106220245\n",
      "tensor(-3.1218, requires_grad=True) tensor(1.4983, requires_grad=True) 0.1384684294462204\n",
      "tensor(-3.1222, requires_grad=True) tensor(1.4986, requires_grad=True) 0.1384657323360443\n",
      "tensor(-3.1227, requires_grad=True) tensor(1.4988, requires_grad=True) 0.1384630799293518\n",
      "tensor(-3.1231, requires_grad=True) tensor(1.4990, requires_grad=True) 0.13846051692962646\n",
      "tensor(-3.1236, requires_grad=True) tensor(1.4993, requires_grad=True) 0.1384580433368683\n",
      "tensor(-3.1240, requires_grad=True) tensor(1.4995, requires_grad=True) 0.1384555846452713\n",
      "tensor(-3.1245, requires_grad=True) tensor(1.4997, requires_grad=True) 0.13845321536064148\n",
      "tensor(-3.1249, requires_grad=True) tensor(1.4999, requires_grad=True) 0.13845092058181763\n",
      "tensor(-3.1253, requires_grad=True) tensor(1.5002, requires_grad=True) 0.13844865560531616\n",
      "tensor(-3.1257, requires_grad=True) tensor(1.5004, requires_grad=True) 0.13844648003578186\n",
      "tensor(-3.1261, requires_grad=True) tensor(1.5006, requires_grad=True) 0.13844433426856995\n",
      "tensor(-3.1265, requires_grad=True) tensor(1.5008, requires_grad=True) 0.138442263007164\n",
      "tensor(-3.1269, requires_grad=True) tensor(1.5010, requires_grad=True) 0.13844022154808044\n",
      "tensor(-3.1273, requires_grad=True) tensor(1.5012, requires_grad=True) 0.13843826949596405\n",
      "tensor(-3.1277, requires_grad=True) tensor(1.5014, requires_grad=True) 0.13843636214733124\n",
      "tensor(-3.1281, requires_grad=True) tensor(1.5016, requires_grad=True) 0.1384344846010208\n",
      "tensor(-3.1285, requires_grad=True) tensor(1.5018, requires_grad=True) 0.13843266665935516\n",
      "tensor(-3.1289, requires_grad=True) tensor(1.5020, requires_grad=True) 0.1384308785200119\n",
      "tensor(-3.1292, requires_grad=True) tensor(1.5022, requires_grad=True) 0.13842914998531342\n",
      "tensor(-3.1296, requires_grad=True) tensor(1.5024, requires_grad=True) 0.1384274661540985\n",
      "tensor(-3.1300, requires_grad=True) tensor(1.5026, requires_grad=True) 0.1384258270263672\n",
      "tensor(-3.1303, requires_grad=True) tensor(1.5028, requires_grad=True) 0.13842424750328064\n",
      "tensor(-3.1307, requires_grad=True) tensor(1.5029, requires_grad=True) 0.13842268288135529\n",
      "tensor(-3.1310, requires_grad=True) tensor(1.5031, requires_grad=True) 0.1384211778640747\n",
      "tensor(-3.1314, requires_grad=True) tensor(1.5033, requires_grad=True) 0.13841970264911652\n",
      "tensor(-3.1317, requires_grad=True) tensor(1.5035, requires_grad=True) 0.1384182572364807\n",
      "tensor(-3.1320, requires_grad=True) tensor(1.5037, requires_grad=True) 0.1384168565273285\n",
      "tensor(-3.1324, requires_grad=True) tensor(1.5038, requires_grad=True) 0.13841550052165985\n",
      "tensor(-3.1327, requires_grad=True) tensor(1.5040, requires_grad=True) 0.1384141743183136\n",
      "tensor(-3.1330, requires_grad=True) tensor(1.5042, requires_grad=True) 0.13841287791728973\n",
      "tensor(-3.1333, requires_grad=True) tensor(1.5043, requires_grad=True) 0.13841161131858826\n",
      "tensor(-3.1336, requires_grad=True) tensor(1.5045, requires_grad=True) 0.13841038942337036\n",
      "tensor(-3.1339, requires_grad=True) tensor(1.5046, requires_grad=True) 0.13840919733047485\n",
      "tensor(-3.1342, requires_grad=True) tensor(1.5048, requires_grad=True) 0.13840803503990173\n",
      "tensor(-3.1345, requires_grad=True) tensor(1.5050, requires_grad=True) 0.138406902551651\n",
      "tensor(-3.1348, requires_grad=True) tensor(1.5051, requires_grad=True) 0.13840581476688385\n",
      "tensor(-3.1351, requires_grad=True) tensor(1.5053, requires_grad=True) 0.1384047269821167\n",
      "tensor(-3.1354, requires_grad=True) tensor(1.5054, requires_grad=True) 0.13840369880199432\n",
      "tensor(-3.1357, requires_grad=True) tensor(1.5056, requires_grad=True) 0.13840265572071075\n",
      "tensor(-3.1360, requires_grad=True) tensor(1.5057, requires_grad=True) 0.13840167224407196\n",
      "tensor(-3.1363, requires_grad=True) tensor(1.5059, requires_grad=True) 0.13840070366859436\n",
      "tensor(-3.1365, requires_grad=True) tensor(1.5060, requires_grad=True) 0.13839976489543915\n",
      "tensor(-3.1368, requires_grad=True) tensor(1.5061, requires_grad=True) 0.13839884102344513\n",
      "tensor(-3.1371, requires_grad=True) tensor(1.5063, requires_grad=True) 0.1383979469537735\n",
      "tensor(-3.1373, requires_grad=True) tensor(1.5064, requires_grad=True) 0.13839708268642426\n",
      "tensor(-3.1376, requires_grad=True) tensor(1.5065, requires_grad=True) 0.138396218419075\n",
      "tensor(-3.1378, requires_grad=True) tensor(1.5067, requires_grad=True) 0.13839541375637054\n",
      "tensor(-3.1381, requires_grad=True) tensor(1.5068, requires_grad=True) 0.13839460909366608\n",
      "tensor(-3.1383, requires_grad=True) tensor(1.5069, requires_grad=True) 0.1383938193321228\n",
      "tensor(-3.1386, requires_grad=True) tensor(1.5071, requires_grad=True) 0.13839304447174072\n",
      "tensor(-3.1388, requires_grad=True) tensor(1.5072, requires_grad=True) 0.13839232921600342\n",
      "tensor(-3.1391, requires_grad=True) tensor(1.5073, requires_grad=True) 0.13839158415794373\n",
      "tensor(-3.1393, requires_grad=True) tensor(1.5074, requires_grad=True) 0.1383908987045288\n",
      "tensor(-3.1395, requires_grad=True) tensor(1.5076, requires_grad=True) 0.1383902132511139\n",
      "tensor(-3.1398, requires_grad=True) tensor(1.5077, requires_grad=True) 0.13838952779769897\n",
      "tensor(-3.1400, requires_grad=True) tensor(1.5078, requires_grad=True) 0.13838887214660645\n",
      "tensor(-3.1402, requires_grad=True) tensor(1.5079, requires_grad=True) 0.1383882462978363\n",
      "tensor(-3.1404, requires_grad=True) tensor(1.5080, requires_grad=True) 0.13838762044906616\n",
      "tensor(-3.1407, requires_grad=True) tensor(1.5081, requires_grad=True) 0.1383870244026184\n",
      "tensor(-3.1409, requires_grad=True) tensor(1.5083, requires_grad=True) 0.13838644325733185\n",
      "tensor(-3.1411, requires_grad=True) tensor(1.5084, requires_grad=True) 0.1383858621120453\n",
      "tensor(-3.1413, requires_grad=True) tensor(1.5085, requires_grad=True) 0.13838531076908112\n",
      "tensor(-3.1415, requires_grad=True) tensor(1.5086, requires_grad=True) 0.13838477432727814\n",
      "tensor(-3.1417, requires_grad=True) tensor(1.5087, requires_grad=True) 0.13838425278663635\n",
      "tensor(-3.1419, requires_grad=True) tensor(1.5088, requires_grad=True) 0.13838373124599457\n",
      "tensor(-3.1421, requires_grad=True) tensor(1.5089, requires_grad=True) 0.13838323950767517\n",
      "tensor(-3.1423, requires_grad=True) tensor(1.5090, requires_grad=True) 0.13838276267051697\n",
      "tensor(-3.1425, requires_grad=True) tensor(1.5091, requires_grad=True) 0.13838228583335876\n",
      "tensor(-3.1427, requires_grad=True) tensor(1.5092, requires_grad=True) 0.13838180899620056\n",
      "tensor(-3.1429, requires_grad=True) tensor(1.5093, requires_grad=True) 0.13838136196136475\n",
      "tensor(-3.1431, requires_grad=True) tensor(1.5094, requires_grad=True) 0.13838092982769012\n",
      "tensor(-3.1433, requires_grad=True) tensor(1.5095, requires_grad=True) 0.1383804827928543\n",
      "tensor(-3.1434, requires_grad=True) tensor(1.5096, requires_grad=True) 0.13838008046150208\n",
      "tensor(-3.1436, requires_grad=True) tensor(1.5097, requires_grad=True) 0.13837966322898865\n",
      "tensor(-3.1438, requires_grad=True) tensor(1.5098, requires_grad=True) 0.1383792757987976\n",
      "tensor(-3.1440, requires_grad=True) tensor(1.5099, requires_grad=True) 0.13837890326976776\n",
      "tensor(-3.1441, requires_grad=True) tensor(1.5099, requires_grad=True) 0.13837853074073792\n",
      "tensor(-3.1443, requires_grad=True) tensor(1.5100, requires_grad=True) 0.13837815821170807\n",
      "tensor(-3.1445, requires_grad=True) tensor(1.5101, requires_grad=True) 0.13837780058383942\n",
      "tensor(-3.1446, requires_grad=True) tensor(1.5102, requires_grad=True) 0.13837745785713196\n",
      "tensor(-3.1448, requires_grad=True) tensor(1.5103, requires_grad=True) 0.1383771151304245\n",
      "tensor(-3.1450, requires_grad=True) tensor(1.5104, requires_grad=True) 0.13837678730487823\n",
      "tensor(-3.1451, requires_grad=True) tensor(1.5105, requires_grad=True) 0.13837645947933197\n",
      "tensor(-3.1453, requires_grad=True) tensor(1.5105, requires_grad=True) 0.1383761763572693\n",
      "tensor(-3.1454, requires_grad=True) tensor(1.5106, requires_grad=True) 0.13837586343288422\n",
      "tensor(-3.1456, requires_grad=True) tensor(1.5107, requires_grad=True) 0.13837555050849915\n",
      "tensor(-3.1457, requires_grad=True) tensor(1.5108, requires_grad=True) 0.13837528228759766\n",
      "tensor(-3.1459, requires_grad=True) tensor(1.5109, requires_grad=True) 0.13837499916553497\n",
      "tensor(-3.1460, requires_grad=True) tensor(1.5109, requires_grad=True) 0.13837473094463348\n",
      "tensor(-3.1462, requires_grad=True) tensor(1.5110, requires_grad=True) 0.138374462723732\n",
      "tensor(-3.1463, requires_grad=True) tensor(1.5111, requires_grad=True) 0.1383741945028305\n",
      "tensor(-3.1465, requires_grad=True) tensor(1.5112, requires_grad=True) 0.1383739411830902\n",
      "tensor(-3.1466, requires_grad=True) tensor(1.5112, requires_grad=True) 0.1383737176656723\n",
      "tensor(-3.1467, requires_grad=True) tensor(1.5113, requires_grad=True) 0.138373464345932\n",
      "tensor(-3.1469, requires_grad=True) tensor(1.5114, requires_grad=True) 0.1383732259273529\n",
      "tensor(-3.1470, requires_grad=True) tensor(1.5114, requires_grad=True) 0.138373002409935\n",
      "tensor(-3.1471, requires_grad=True) tensor(1.5115, requires_grad=True) 0.1383727788925171\n",
      "tensor(-3.1473, requires_grad=True) tensor(1.5116, requires_grad=True) 0.13837257027626038\n",
      "tensor(-3.1474, requires_grad=True) tensor(1.5116, requires_grad=True) 0.13837236166000366\n",
      "tensor(-3.1475, requires_grad=True) tensor(1.5117, requires_grad=True) 0.13837215304374695\n",
      "tensor(-3.1477, requires_grad=True) tensor(1.5118, requires_grad=True) 0.13837195932865143\n",
      "tensor(-3.1478, requires_grad=True) tensor(1.5118, requires_grad=True) 0.1383717656135559\n",
      "tensor(-3.1479, requires_grad=True) tensor(1.5119, requires_grad=True) 0.1383715718984604\n",
      "tensor(-3.1480, requires_grad=True) tensor(1.5120, requires_grad=True) 0.13837140798568726\n",
      "tensor(-3.1481, requires_grad=True) tensor(1.5120, requires_grad=True) 0.13837122917175293\n",
      "tensor(-3.1483, requires_grad=True) tensor(1.5121, requires_grad=True) 0.1383710354566574\n",
      "tensor(-3.1484, requires_grad=True) tensor(1.5122, requires_grad=True) 0.13837087154388428\n",
      "tensor(-3.1485, requires_grad=True) tensor(1.5122, requires_grad=True) 0.13837070763111115\n",
      "tensor(-3.1486, requires_grad=True) tensor(1.5123, requires_grad=True) 0.1383705586194992\n",
      "tensor(-3.1487, requires_grad=True) tensor(1.5123, requires_grad=True) 0.13837037980556488\n",
      "tensor(-3.1488, requires_grad=True) tensor(1.5124, requires_grad=True) 0.13837023079395294\n",
      "tensor(-3.1489, requires_grad=True) tensor(1.5124, requires_grad=True) 0.138370081782341\n",
      "tensor(-3.1490, requires_grad=True) tensor(1.5125, requires_grad=True) 0.13836993277072906\n",
      "tensor(-3.1491, requires_grad=True) tensor(1.5126, requires_grad=True) 0.13836978375911713\n",
      "tensor(-3.1493, requires_grad=True) tensor(1.5126, requires_grad=True) 0.13836967945098877\n",
      "tensor(-3.1494, requires_grad=True) tensor(1.5127, requires_grad=True) 0.13836951553821564\n",
      "tensor(-3.1495, requires_grad=True) tensor(1.5127, requires_grad=True) 0.1383693963289261\n",
      "tensor(-3.1496, requires_grad=True) tensor(1.5128, requires_grad=True) 0.13836926221847534\n",
      "tensor(-3.1497, requires_grad=True) tensor(1.5128, requires_grad=True) 0.1383691281080246\n",
      "tensor(-3.1498, requires_grad=True) tensor(1.5129, requires_grad=True) 0.13836903870105743\n",
      "tensor(-3.1499, requires_grad=True) tensor(1.5129, requires_grad=True) 0.1383688896894455\n",
      "tensor(-3.1499, requires_grad=True) tensor(1.5130, requires_grad=True) 0.13836880028247833\n",
      "tensor(-3.1500, requires_grad=True) tensor(1.5130, requires_grad=True) 0.13836868107318878\n",
      "tensor(-3.1501, requires_grad=True) tensor(1.5131, requires_grad=True) 0.13836857676506042\n",
      "tensor(-3.1502, requires_grad=True) tensor(1.5131, requires_grad=True) 0.13836847245693207\n",
      "tensor(-3.1503, requires_grad=True) tensor(1.5132, requires_grad=True) 0.13836835324764252\n",
      "tensor(-3.1504, requires_grad=True) tensor(1.5132, requires_grad=True) 0.13836827874183655\n",
      "tensor(-3.1505, requires_grad=True) tensor(1.5133, requires_grad=True) 0.1383681744337082\n",
      "tensor(-3.1506, requires_grad=True) tensor(1.5133, requires_grad=True) 0.13836808502674103\n",
      "tensor(-3.1507, requires_grad=True) tensor(1.5133, requires_grad=True) 0.13836798071861267\n",
      "tensor(-3.1507, requires_grad=True) tensor(1.5134, requires_grad=True) 0.1383678913116455\n",
      "tensor(-3.1508, requires_grad=True) tensor(1.5134, requires_grad=True) 0.13836780190467834\n",
      "tensor(-3.1509, requires_grad=True) tensor(1.5135, requires_grad=True) 0.13836771249771118\n",
      "tensor(-3.1510, requires_grad=True) tensor(1.5135, requires_grad=True) 0.1383676379919052\n",
      "tensor(-3.1511, requires_grad=True) tensor(1.5136, requires_grad=True) 0.13836756348609924\n",
      "tensor(-3.1512, requires_grad=True) tensor(1.5136, requires_grad=True) 0.13836747407913208\n",
      "tensor(-3.1512, requires_grad=True) tensor(1.5136, requires_grad=True) 0.1383673995733261\n",
      "tensor(-3.1513, requires_grad=True) tensor(1.5137, requires_grad=True) 0.13836732506752014\n",
      "tensor(-3.1514, requires_grad=True) tensor(1.5137, requires_grad=True) 0.13836723566055298\n",
      "tensor(-3.1515, requires_grad=True) tensor(1.5138, requires_grad=True) 0.1383671909570694\n",
      "tensor(-3.1515, requires_grad=True) tensor(1.5138, requires_grad=True) 0.13836711645126343\n",
      "tensor(-3.1516, requires_grad=True) tensor(1.5138, requires_grad=True) 0.13836704194545746\n",
      "tensor(-3.1517, requires_grad=True) tensor(1.5139, requires_grad=True) 0.13836698234081268\n",
      "tensor(-3.1518, requires_grad=True) tensor(1.5139, requires_grad=True) 0.1383669227361679\n",
      "tensor(-3.1518, requires_grad=True) tensor(1.5139, requires_grad=True) 0.13836684823036194\n",
      "tensor(-3.1519, requires_grad=True) tensor(1.5140, requires_grad=True) 0.13836678862571716\n",
      "tensor(-3.1520, requires_grad=True) tensor(1.5140, requires_grad=True) 0.1383667290210724\n",
      "tensor(-3.1520, requires_grad=True) tensor(1.5141, requires_grad=True) 0.1383666843175888\n",
      "tensor(-3.1521, requires_grad=True) tensor(1.5141, requires_grad=True) 0.13836660981178284\n",
      "tensor(-3.1522, requires_grad=True) tensor(1.5141, requires_grad=True) 0.13836656510829926\n",
      "tensor(-3.1522, requires_grad=True) tensor(1.5142, requires_grad=True) 0.13836650550365448\n",
      "tensor(-3.1523, requires_grad=True) tensor(1.5142, requires_grad=True) 0.1383664608001709\n",
      "tensor(-3.1524, requires_grad=True) tensor(1.5142, requires_grad=True) 0.13836641609668732\n",
      "tensor(-3.1524, requires_grad=True) tensor(1.5143, requires_grad=True) 0.13836635649204254\n",
      "tensor(-3.1525, requires_grad=True) tensor(1.5143, requires_grad=True) 0.13836629688739777\n",
      "tensor(-3.1525, requires_grad=True) tensor(1.5143, requires_grad=True) 0.13836626708507538\n",
      "tensor(-3.1526, requires_grad=True) tensor(1.5143, requires_grad=True) 0.1383662074804306\n",
      "tensor(-3.1527, requires_grad=True) tensor(1.5144, requires_grad=True) 0.13836616277694702\n",
      "tensor(-3.1527, requires_grad=True) tensor(1.5144, requires_grad=True) 0.13836613297462463\n",
      "tensor(-3.1528, requires_grad=True) tensor(1.5144, requires_grad=True) 0.13836610317230225\n",
      "tensor(-3.1528, requires_grad=True) tensor(1.5145, requires_grad=True) 0.13836604356765747\n",
      "tensor(-3.1529, requires_grad=True) tensor(1.5145, requires_grad=True) 0.1383659988641739\n",
      "tensor(-3.1529, requires_grad=True) tensor(1.5145, requires_grad=True) 0.1383659839630127\n",
      "tensor(-3.1530, requires_grad=True) tensor(1.5146, requires_grad=True) 0.1383659392595291\n",
      "tensor(-3.1530, requires_grad=True) tensor(1.5146, requires_grad=True) 0.13836589455604553\n",
      "tensor(-3.1531, requires_grad=True) tensor(1.5146, requires_grad=True) 0.13836586475372314\n",
      "tensor(-3.1532, requires_grad=True) tensor(1.5146, requires_grad=True) 0.13836582005023956\n",
      "tensor(-3.1532, requires_grad=True) tensor(1.5147, requires_grad=True) 0.13836579024791718\n",
      "tensor(-3.1533, requires_grad=True) tensor(1.5147, requires_grad=True) 0.1383657604455948\n",
      "tensor(-3.1533, requires_grad=True) tensor(1.5147, requires_grad=True) 0.1383657306432724\n",
      "tensor(-3.1534, requires_grad=True) tensor(1.5147, requires_grad=True) 0.13836568593978882\n",
      "tensor(-3.1534, requires_grad=True) tensor(1.5148, requires_grad=True) 0.13836567103862762\n",
      "tensor(-3.1535, requires_grad=True) tensor(1.5148, requires_grad=True) 0.13836562633514404\n",
      "tensor(-3.1535, requires_grad=True) tensor(1.5148, requires_grad=True) 0.13836559653282166\n",
      "tensor(-3.1535, requires_grad=True) tensor(1.5148, requires_grad=True) 0.13836558163166046\n",
      "tensor(-3.1536, requires_grad=True) tensor(1.5149, requires_grad=True) 0.13836555182933807\n",
      "tensor(-3.1536, requires_grad=True) tensor(1.5149, requires_grad=True) 0.13836552202701569\n",
      "tensor(-3.1537, requires_grad=True) tensor(1.5149, requires_grad=True) 0.1383654922246933\n",
      "tensor(-3.1537, requires_grad=True) tensor(1.5149, requires_grad=True) 0.1383654773235321\n",
      "tensor(-3.1538, requires_grad=True) tensor(1.5150, requires_grad=True) 0.13836544752120972\n",
      "tensor(-3.1538, requires_grad=True) tensor(1.5150, requires_grad=True) 0.13836543262004852\n",
      "tensor(-3.1539, requires_grad=True) tensor(1.5150, requires_grad=True) 0.13836538791656494\n",
      "tensor(-3.1539, requires_grad=True) tensor(1.5150, requires_grad=True) 0.13836535811424255\n",
      "tensor(-3.1539, requires_grad=True) tensor(1.5150, requires_grad=True) 0.13836534321308136\n",
      "tensor(-3.1540, requires_grad=True) tensor(1.5151, requires_grad=True) 0.13836532831192017\n",
      "tensor(-3.1540, requires_grad=True) tensor(1.5151, requires_grad=True) 0.13836531341075897\n",
      "tensor(-3.1541, requires_grad=True) tensor(1.5151, requires_grad=True) 0.13836528360843658\n",
      "tensor(-3.1541, requires_grad=True) tensor(1.5151, requires_grad=True) 0.1383652687072754\n",
      "tensor(-3.1541, requires_grad=True) tensor(1.5152, requires_grad=True) 0.1383652538061142\n",
      "tensor(-3.1542, requires_grad=True) tensor(1.5152, requires_grad=True) 0.1383652240037918\n",
      "tensor(-3.1542, requires_grad=True) tensor(1.5152, requires_grad=True) 0.13836520910263062\n",
      "tensor(-3.1543, requires_grad=True) tensor(1.5152, requires_grad=True) 0.13836519420146942\n",
      "tensor(-3.1543, requires_grad=True) tensor(1.5152, requires_grad=True) 0.13836517930030823\n",
      "tensor(-3.1543, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836516439914703\n",
      "tensor(-3.1544, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836514949798584\n",
      "tensor(-3.1544, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836511969566345\n",
      "tensor(-3.1544, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836510479450226\n",
      "tensor(-3.1545, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836510479450226\n",
      "tensor(-3.1545, requires_grad=True) tensor(1.5153, requires_grad=True) 0.13836507499217987\n",
      "tensor(-3.1545, requires_grad=True) tensor(1.5154, requires_grad=True) 0.13836507499217987\n",
      "tensor(-3.1546, requires_grad=True) tensor(1.5154, requires_grad=True) 0.13836504518985748\n",
      "tensor(-3.1546, requires_grad=True) tensor(1.5154, requires_grad=True) 0.13836504518985748\n",
      "tensor(-3.1546, requires_grad=True) tensor(1.5154, requires_grad=True) 0.1383650153875351\n",
      "tensor(-3.1547, requires_grad=True) tensor(1.5154, requires_grad=True) 0.1383649855852127\n",
      "tensor(-3.1547, requires_grad=True) tensor(1.5154, requires_grad=True) 0.1383650004863739\n",
      "tensor(-3.1547, requires_grad=True) tensor(1.5155, requires_grad=True) 0.1383649855852127\n",
      "tensor(-3.1548, requires_grad=True) tensor(1.5155, requires_grad=True) 0.1383649855852127\n",
      "tensor(-3.1548, requires_grad=True) tensor(1.5155, requires_grad=True) 0.1383649706840515\n",
      "tensor(-3.1548, requires_grad=True) tensor(1.5155, requires_grad=True) 0.13836495578289032\n",
      "tensor(-3.1549, requires_grad=True) tensor(1.5155, requires_grad=True) 0.13836494088172913\n",
      "tensor(-3.1549, requires_grad=True) tensor(1.5155, requires_grad=True) 0.13836492598056793\n",
      "tensor(-3.1549, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836492598056793\n",
      "tensor(-3.1550, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836491107940674\n",
      "tensor(-3.1550, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836489617824554\n",
      "tensor(-3.1550, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836488127708435\n",
      "tensor(-3.1550, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836488127708435\n",
      "tensor(-3.1551, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836488127708435\n",
      "tensor(-3.1551, requires_grad=True) tensor(1.5156, requires_grad=True) 0.13836485147476196\n",
      "tensor(-3.1551, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836485147476196\n",
      "tensor(-3.1551, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836483657360077\n",
      "tensor(-3.1552, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836483657360077\n",
      "tensor(-3.1552, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836483657360077\n",
      "tensor(-3.1552, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836480677127838\n",
      "tensor(-3.1552, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836480677127838\n",
      "tensor(-3.1553, requires_grad=True) tensor(1.5157, requires_grad=True) 0.13836480677127838\n",
      "tensor(-3.1553, requires_grad=True) tensor(1.5157, requires_grad=True) 0.1383647918701172\n",
      "tensor(-3.1553, requires_grad=True) tensor(1.5158, requires_grad=True) 0.13836480677127838\n",
      "tensor(-3.1553, requires_grad=True) tensor(1.5158, requires_grad=True) 0.138364776968956\n",
      "tensor(-3.1554, requires_grad=True) tensor(1.5158, requires_grad=True) 0.138364776968956\n",
      "tensor(-3.1554, requires_grad=True) tensor(1.5158, requires_grad=True) 0.138364776968956\n",
      "tensor(-3.1554, requires_grad=True) tensor(1.5158, requires_grad=True) 0.1383647620677948\n",
      "tensor(-3.1554, requires_grad=True) tensor(1.5158, requires_grad=True) 0.1383647471666336\n",
      "tensor(-3.1555, requires_grad=True) tensor(1.5158, requires_grad=True) 0.1383647471666336\n",
      "tensor(-3.1555, requires_grad=True) tensor(1.5158, requires_grad=True) 0.1383647471666336\n",
      "tensor(-3.1555, requires_grad=True) tensor(1.5159, requires_grad=True) 0.1383647322654724\n",
      "tensor(-3.1555, requires_grad=True) tensor(1.5159, requires_grad=True) 0.1383647322654724\n",
      "tensor(-3.1555, requires_grad=True) tensor(1.5159, requires_grad=True) 0.1383647322654724\n",
      "tensor(-3.1556, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836471736431122\n",
      "tensor(-3.1556, requires_grad=True) tensor(1.5159, requires_grad=True) 0.1383647322654724\n",
      "tensor(-3.1556, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836471736431122\n",
      "tensor(-3.1556, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836471736431122\n",
      "tensor(-3.1556, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836470246315002\n",
      "tensor(-3.1557, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836468756198883\n",
      "tensor(-3.1557, requires_grad=True) tensor(1.5159, requires_grad=True) 0.13836468756198883\n",
      "tensor(-3.1557, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836468756198883\n",
      "tensor(-3.1557, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1557, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836465775966644\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836467266082764\n",
      "tensor(-3.1558, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836465775966644\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5160, requires_grad=True) 0.13836465775966644\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836465775966644\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836464285850525\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836464285850525\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836464285850525\n",
      "tensor(-3.1559, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836462795734406\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836462795734406\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836462795734406\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836462795734406\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836462795734406\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1560, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5161, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836461305618286\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1561, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1562, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5162, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836459815502167\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836458325386047\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1563, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1564, requires_grad=True) tensor(1.5163, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836455345153809\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836455345153809\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836455345153809\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1565, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836455345153809\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.13836456835269928\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5164, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1566, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1567, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5165, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1568, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1569, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5166, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383644938468933\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1570, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645236492157\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645087480545\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n",
      "tensor(-3.1571, requires_grad=True) tensor(1.5167, requires_grad=True) 0.1383645385503769\n"
     ]
    }
   ],
   "source": [
    "w = torch.tensor(0.125, requires_grad=True)\n",
    "b = torch.tensor(-0.125, requires_grad=True)\n",
    "\n",
    "\n",
    "stepsize = 0.1\n",
    "n_iter = 1000\n",
    "\n",
    "for i in range(n_iter):\n",
    "    err = mse(X, y, w, b)\n",
    "    print(w, b, err.item())\n",
    "    err.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= stepsize * w.grad\n",
    "        b -= stepsize * b.grad\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.10_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
